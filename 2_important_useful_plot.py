# -*- coding: utf-8 -*-
"""2_important_useful_plot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ymvLjvP3gnlvz0fHrJMXOCCRCisYAIlU
"""

# Impact of Weather Patterns on Public Transit Ridership:
# A Comprehensive Analysis of Philadelphia's Transportation System

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from matplotlib.ticker import MultipleLocator
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.dates as mdates
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Set publication-quality plot parameters
# Replace the font settings at the beginning of the notebook with these lines:
plt.rcParams['font.family'] = 'serif'
# Use a serif font that's available in Google Colab
plt.rcParams['font.serif'] = ['DejaVu Serif', 'Bitstream Vera Serif', 'Computer Modern Roman', 'New Century Schoolbook', 'Century Schoolbook L', 'Utopia', 'ITC Bookman', 'Bookman', 'Nimbus Roman No9 L', 'Times New Roman', 'Times', 'Palatino', 'Charter', 'serif']
plt.rcParams['font.size'] = 16
plt.rcParams['axes.linewidth'] = 1.2
plt.rcParams['axes.labelsize'] = 16
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['xtick.labelsize'] = 14
plt.rcParams['ytick.labelsize'] = 14
plt.rcParams['legend.fontsize'] = 14
plt.rcParams['figure.titlesize'] = 18
plt.rcParams['figure.dpi'] = 600



"""***1. Introduction and Data Loading***"""

# Research Objective
# This study investigates the relationship between weather conditions (temperature extremes
# and precipitation) and public transit ridership in Philadelphia across different modes of
# transportation. The analysis aims to identify how extreme weather events impact
# transportation usage patterns, with implications for transit planning and climate resilience.

# Load the datasets
print("Loading datasets...")
weather_data = pd.read_csv('/content/weather_data.csv')
ridership_data = pd.read_csv('/content/Jan19_to_2024.csv')
socioeconomic_data = pd.read_csv('/content/social_economic_data_rideship.csv')

# Display basic information
print(f"Weather data dimensions: {weather_data.shape}")
print(f"Ridership data dimensions: {ridership_data.shape}")
print(f"Socioeconomic data dimensions: {socioeconomic_data.shape}")

# Preview each dataset
fig, axes = plt.subplots(3, 1, figsize=(12, 18))
fig.suptitle('Dataset Preview', fontsize=20, y=0.95)

# Weather data
axes[0].axis('off')
axes[0].set_title('Weather Data Sample', fontsize=16)
weather_info = weather_data[['STATION', 'NAME', 'DATE', 'PRCP', 'SNWD', 'TMAX', 'TMIN']].head(5).to_string()
axes[0].text(0.01, 0.99, f"Weather data shape: {weather_data.shape}\n\n{weather_info}",
             transform=axes[0].transAxes, fontsize=12, verticalalignment='top',
             family='monospace')

# Ridership data
axes[1].axis('off')
axes[1].set_title('Ridership Data Sample', fontsize=16)
ridership_info = ridership_data.head(5).to_string()
axes[1].text(0.01, 0.99, f"Ridership data shape: {ridership_data.shape}\n\n{ridership_info}",
             transform=axes[1].transAxes, fontsize=12, verticalalignment='top',
             family='monospace')

# Socioeconomic data
axes[2].axis('off')
axes[2].set_title('Socioeconomic Data Sample', fontsize=16)
socio_info = socioeconomic_data[['CTFIPS', 'Total_Population', 'Median_income', 'Rent_to_Income']].head(5).to_string()
axes[2].text(0.01, 0.99, f"Socioeconomic data shape: {socioeconomic_data.shape}\n\n{socio_info}",
             transform=axes[2].transAxes, fontsize=12, verticalalignment='top',
             family='monospace')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure1_data_preview.png', dpi=300, bbox_inches='tight')
plt.show()

"""***2. Data Preprocessing and Weather Event Classification***"""

# 2.1 Data Preprocessing
print("Processing weather data...")
weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])
weather_data['Year'] = weather_data['DATE'].dt.year
weather_data['Month'] = weather_data['DATE'].dt.month
weather_data['Month_Name'] = weather_data['DATE'].dt.strftime('%B')
weather_data['Season'] = pd.cut(
    weather_data['Month'],
    bins=[0, 3, 6, 9, 12],
    labels=['Winter', 'Spring', 'Summer', 'Fall'],
    ordered=True
)

# Check for missing values
print("\nMissing values in critical columns:")
print(weather_data[['DATE', 'PRCP', 'TMAX', 'TMIN']].isnull().sum())

# Check if SNWD column exists in the data
if 'SNWD' in weather_data.columns:
    print(f"Snow Depth (SNWD): {weather_data['SNWD'].isnull().sum()} missing values")
else:
    print("Warning: SNWD (Snow Depth) column not found in data")

# 2.2 Define Extreme Weather Events (Including Snow)
def define_extreme_weather_events(df, hot_percentile=90, cold_percentile=10, precip_percentile=90, snow_percentile=90):
    """
    Define extreme weather events based on percentile thresholds, including snow events.

    Parameters:
    -----------
    df : pandas.DataFrame
        Weather data with columns 'TMAX', 'TMIN', 'PRCP', 'DATE', and optionally 'SNWD'
    hot_percentile : float
        Percentile threshold for defining extremely hot days (default: 90)
    cold_percentile : float
        Percentile threshold for defining extremely cold days (default: 10)
    precip_percentile : float
        Percentile threshold for defining heavy precipitation days (default: 90)
    snow_percentile : float
        Percentile threshold for defining heavy snow days (default: 90)

    Returns:
    --------
    pandas.DataFrame
        Weather data with added extreme event indicators
    dict
        Thresholds used for defining extreme events
    """
    # Create a copy to avoid modifying the original
    df_extremes = df.copy()

    # Check if SNWD column exists and handle accordingly
    has_snow_data = 'SNWD' in df_extremes.columns
    if has_snow_data:
        # Fill NaN values in SNWD with 0 (assuming no snow depth when missing)
        df_extremes['SNWD'] = df_extremes['SNWD'].fillna(0)

    # Calculate thresholds
    tmax_threshold = np.percentile(df_extremes['TMAX'], hot_percentile)
    tmin_threshold = np.percentile(df_extremes['TMAX'], cold_percentile)

    # Heavy precipitation threshold (non-zero precipitation days)
    prcp_non_zero = df_extremes.loc[df_extremes['PRCP'] > 0, 'PRCP']
    prcp_threshold = np.percentile(prcp_non_zero, precip_percentile)

    # Heavy snow threshold (only if snow data exists)
    snow_threshold = 0
    if has_snow_data:
        snow_non_zero = df_extremes.loc[df_extremes['SNWD'] > 0, 'SNWD']
        if len(snow_non_zero) > 0:
            snow_threshold = np.percentile(snow_non_zero, snow_percentile)
        else:
            print("Warning: No snow depth data found in dataset")

    # Create indicator variables
    df_extremes['VERY_HOT'] = (df_extremes['TMAX'] >= tmax_threshold).astype(int)
    df_extremes['VERY_COLD'] = (df_extremes['TMAX'] <= tmin_threshold).astype(int)
    df_extremes['HEAVY_PRECIP'] = (df_extremes['PRCP'] >= prcp_threshold).astype(int)

    if has_snow_data:
        df_extremes['HEAVY_SNOW'] = (df_extremes['SNWD'] >= snow_threshold).astype(int)

    # Identify consecutive extreme days
    df_extremes['CONSEC_HOT'] = ((df_extremes['VERY_HOT'] == 1) &
                               (df_extremes['VERY_HOT'].shift(1) == 1)).astype(int)
    df_extremes['CONSEC_COLD'] = ((df_extremes['VERY_COLD'] == 1) &
                                (df_extremes['VERY_COLD'].shift(1) == 1)).astype(int)
    df_extremes['CONSEC_PRECIP'] = ((df_extremes['HEAVY_PRECIP'] == 1) &
                                  (df_extremes['HEAVY_PRECIP'].shift(1) == 1)).astype(int)

    # Create wave indicators
    df_extremes['HEATWAVE'] = 0
    df_extremes['COLDWAVE'] = 0

    # Find sequences of consecutive extreme days
    hot_count = 0
    cold_count = 0

    for i in range(len(df_extremes)):
        # Count consecutive hot days
        if df_extremes.iloc[i]['VERY_HOT'] == 1:
            hot_count += 1
        else:
            hot_count = 0

        # Count consecutive cold days
        if df_extremes.iloc[i]['VERY_COLD'] == 1:
            cold_count += 1
        else:
            cold_count = 0

        # Mark wave events
        if hot_count >= 3:
            df_extremes.iloc[i, df_extremes.columns.get_loc('HEATWAVE')] = 1

        if cold_count >= 3:
            df_extremes.iloc[i, df_extremes.columns.get_loc('COLDWAVE')] = 1

    # Initialize wave columns with zeros
    df_extremes['PRECIPWAVE'] = 0
    if has_snow_data:
        df_extremes['SNOWWAVE'] = 0

    # Count heavy precipitation days by month and year
    monthly_precip_counts = df_extremes.groupby(['Year', 'Month'])['HEAVY_PRECIP'].sum().reset_index()

    # Identify months with 3 or more heavy precipitation days
    precip_wave_months = monthly_precip_counts[monthly_precip_counts['HEAVY_PRECIP'] >= 3][['Year', 'Month']]

    # Mark only heavy precipitation days in those qualifying months as PRECIPWAVE
    if not precip_wave_months.empty:
        for _, row in precip_wave_months.iterrows():
            year, month = row['Year'], row['Month']
            mask = ((df_extremes['Year'] == year) &
                   (df_extremes['Month'] == month) &
                   (df_extremes['HEAVY_PRECIP'] == 1))
            df_extremes.loc[mask, 'PRECIPWAVE'] = 1

    # Snow wave logic (if snow data exists)
    if has_snow_data:
        # Count heavy snow days by month and year
        monthly_snow_counts = df_extremes.groupby(['Year', 'Month'])['HEAVY_SNOW'].sum().reset_index()

        # Identify months with 3 or more heavy snow days
        snow_wave_months = monthly_snow_counts[monthly_snow_counts['HEAVY_SNOW'] >= 1][['Year', 'Month']]

        # Mark only heavy snow days in those qualifying months as SNOWWAVE
        if not snow_wave_months.empty:
            for _, row in snow_wave_months.iterrows():
                year, month = row['Year'], row['Month']
                mask = ((df_extremes['Year'] == year) &
                       (df_extremes['Month'] == month) &
                       (df_extremes['HEAVY_SNOW'] == 1))
                df_extremes.loc[mask, 'SNOWWAVE'] = 1

    # Create combined winter storm indicator (if snow data exists)
    if has_snow_data:
        df_extremes['WINTER_STORM'] = ((df_extremes['HEAVY_SNOW'] == 1) &
                                      ((df_extremes['VERY_COLD'] == 1) |
                                       (df_extremes['HEAVY_PRECIP'] == 1))).astype(int)

    # Create compound extreme events
    # 1. Heat wave months with heavy precipitation (dangerous flooding potential)
    monthly_heat_counts = df_extremes.groupby(['Year', 'Month'])['HEATWAVE'].sum().reset_index()
    heat_wave_months = monthly_heat_counts[monthly_heat_counts['HEATWAVE'] >= 1][['Year', 'Month']]

    df_extremes['HEAT_PRECIP_COMPOUND'] = 0
    if not heat_wave_months.empty:
        for _, row in heat_wave_months.iterrows():
            year, month = row['Year'], row['Month']
            # Mark only heavy precipitation days that occur in heat wave months
            mask = ((df_extremes['Year'] == year) &
                   (df_extremes['Month'] == month) &
                   (df_extremes['HEAVY_PRECIP'] == 1))
            df_extremes.loc[mask, 'HEAT_PRECIP_COMPOUND'] = 1

    # Document the thresholds used
    thresholds = {
        'hot_threshold': tmax_threshold,
        'cold_threshold': tmin_threshold,
        'precipitation': prcp_threshold
    }

    if has_snow_data:
        thresholds['snow_depth'] = snow_threshold

    print("\nExtreme Weather Thresholds:")
    print(f"Hot Day Threshold (≥ {hot_percentile}th percentile): {thresholds['hot_threshold']:.1f}°F")
    print(f"Cold Day Threshold (≤ {cold_percentile}th percentile): {thresholds['cold_threshold']:.1f}°F")
    print(f"Heavy Precipitation Threshold (≥ {precip_percentile}th percentile of rainy days): {thresholds['precipitation']:.2f} inches")

    if has_snow_data:
        print(f"Heavy Snow Threshold (≥ {snow_percentile}th percentile of snowy days): {thresholds['snow_depth']:.1f} inches")

    print("\nExtreme Weather Event Statistics:")
    print(f"Very Hot Days: {df_extremes['VERY_HOT'].sum()} ({df_extremes['VERY_HOT'].mean()*100:.1f}% of days)")
    print(f"Very Cold Days: {df_extremes['VERY_COLD'].sum()} ({df_extremes['VERY_COLD'].mean()*100:.1f}% of days)")
    print(f"Heavy Precipitation Days: {df_extremes['HEAVY_PRECIP'].sum()} ({df_extremes['HEAVY_PRECIP'].mean()*100:.1f}% of days)")
    print(f"Heat Wave Days (3+ consecutive hot days): {df_extremes['HEATWAVE'].sum()} ({df_extremes['HEATWAVE'].mean()*100:.1f}% of days)")
    print(f"Cold Wave Days (3+ consecutive cold days): {df_extremes['COLDWAVE'].sum()} ({df_extremes['COLDWAVE'].mean()*100:.1f}% of days)")
    print(f"Precipitation Wave Days (heavy precip days in months with 3+ heavy precip days): {df_extremes['PRECIPWAVE'].sum()} ({df_extremes['PRECIPWAVE'].mean()*100:.1f}% of days)")

    if has_snow_data:
        print(f"Heavy Snow Days: {df_extremes['HEAVY_SNOW'].sum()} ({df_extremes['HEAVY_SNOW'].mean()*100:.1f}% of days)")
        print(f"Snow Wave Days (heavy snow days in months with 3+ heavy snow days): {df_extremes['SNOWWAVE'].sum()} ({df_extremes['SNOWWAVE'].mean()*100:.1f}% of days)")
        print(f"Winter Storm Days (heavy snow + cold/precip): {df_extremes['WINTER_STORM'].sum()} ({df_extremes['WINTER_STORM'].mean()*100:.1f}% of days)")

    # Compound events statistics
    print(f"\nCompound Extreme Events:")
    print(f"Heat-Precipitation Compound Days (heavy precip days during heat wave months): {df_extremes['HEAT_PRECIP_COMPOUND'].sum()} ({df_extremes['HEAT_PRECIP_COMPOUND'].mean()*100:.1f}% of days)")

    return df_extremes, thresholds


# Apply extreme weather definition including snow events
weather_with_extremes, weather_thresholds = define_extreme_weather_events(
    weather_data,
    hot_percentile=90,
    cold_percentile=10,
    precip_percentile=90,
    snow_percentile=90
)

# Optional: Additional snow-specific analysis (only runs if snow data is available)
def analyze_snow_patterns(df):
    """
    Provide additional analysis of snow patterns in the data.
    """
    if 'SNWD' not in df.columns:
        print("\nSNWD (Snow Depth) column not available - skipping snow analysis")
        return

    print("\n" + "="*50)
    print("DETAILED SNOW ANALYSIS")
    print("="*50)

    # Basic snow statistics
    snow_days = df[df['SNWD'] > 0]
    if len(snow_days) > 0:
        print(f"Total days with snow on ground: {len(snow_days)}")
        print(f"Average snow depth on snowy days: {snow_days['SNWD'].mean():.1f} inches")
        print(f"Maximum snow depth recorded: {df['SNWD'].max():.1f} inches")
        print(f"Date of maximum snow depth: {df.loc[df['SNWD'].idxmax(), 'DATE'].strftime('%Y-%m-%d')}")

        # Snow by month (only for months with snow)
        snow_by_month = snow_days.groupby('Month_Name')['SNWD'].agg(['count', 'mean', 'max']).round(1)
        print("\nSnow statistics by month:")
        print(snow_by_month)

        # Snow by year (only for years with snow)
        if 'Year' in df.columns:
            snow_by_year = df[df['SNWD'] > 0].groupby('Year').agg({
                'SNWD': ['count', 'mean', 'max']
            }).round(1)
            snow_by_year.columns = ['Snow_Days', 'Avg_Depth', 'Max_Depth']
            print("\nSnow statistics by year:")
            print(snow_by_year)
    else:
        print("No snow depth data found in the dataset.")

# Run the analysis
analyze_snow_patterns(weather_with_extremes)

# Add this after applying the extreme weather definition
import calendar
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import numpy as np
from matplotlib.gridspec import GridSpec

# Set academic-quality plotting styles
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.serif'] = ['DejaVu Serif', 'Bitstream Vera Serif', 'Computer Modern Roman', 'New Century Schoolbook', 'Century Schoolbook L', 'Utopia', 'ITC Bookman', 'Bookman', 'Nimbus Roman No9 L', 'Times New Roman', 'Times', 'Palatino', 'Charter', 'serif']
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 16

# Function to count event days and distinct events by month
def count_wave_events(weather_data, wave_column):
    event_months = []

    for year in weather_data['Year'].unique():
        for month in range(1, 13):
            # Filter data for this month and year
            month_data = weather_data[(weather_data['Year'] == year) &
                                      (weather_data['Month'] == month)]

            if len(month_data) == 0:
                continue

            # Count days that are part of a wave in this month
            days_count = month_data[wave_column].sum()

            # Skip months with fewer than 3 wave days
            if days_count < 3:
                continue

            # Count separate wave events
            event_count = 0
            in_event = False

            for i, row in month_data.iterrows():
                if row[wave_column] == 1:
                    if not in_event:  # Start of a new event
                        event_count += 1
                        in_event = True
                else:
                    in_event = False

            # Only add months with at least one event
            if event_count > 0:
                event_months.append({
                    'Year': year,
                    'Month': month,
                    'Month_Name': calendar.month_name[month],
                    'days_count': days_count,
                    'events_count': event_count
                })

    return pd.DataFrame(event_months) if event_months else pd.DataFrame()

# ----- HEAT WAVE ANALYSIS -----
heat_wave_stats = count_wave_events(weather_with_extremes, 'HEATWAVE')

# ----- COLD WAVE ANALYSIS -----
cold_wave_stats = count_wave_events(weather_with_extremes, 'COLDWAVE')

# ----- PRECIPITATION WAVE ANALYSIS -----
# Extract months with Precipitation Waves and count heavy precipitation days
precip_wave_months = []

for year in weather_with_extremes['Year'].unique():
    for month in range(1, 13):
        # Filter data for this year and month
        month_data = weather_with_extremes[(weather_with_extremes['Year'] == year) &
                                          (weather_with_extremes['Month'] == month)]

        if len(month_data) == 0:
            continue

        # Count heavy precipitation days in this month
        heavy_precip_count = month_data['HEAVY_PRECIP'].sum()

        # Only include months with 3+ heavy precipitation days
        if heavy_precip_count >= 3:
            precip_wave_months.append({
                'Year': year,
                'Month': month,
                'Month_Name': calendar.month_name[month],
                'days_count': heavy_precip_count,
                'events_count': 1  # Each month with 3+ heavy precip days is one event
            })

# Convert to DataFrame
precip_wave_stats = pd.DataFrame(precip_wave_months)

# ----- SNOW WAVE ANALYSIS (if snow data exists) -----
snow_wave_stats = pd.DataFrame()
has_snow_data = 'SNWD' in weather_with_extremes.columns

if has_snow_data:
    snow_wave_months = []

    for year in weather_with_extremes['Year'].unique():
        for month in range(1, 13):
            # Filter data for this year and month
            month_data = weather_with_extremes[(weather_with_extremes['Year'] == year) &
                                              (weather_with_extremes['Month'] == month)]

            if len(month_data) == 0:
                continue

            # Count heavy snow days in this month
            heavy_snow_count = month_data['HEAVY_SNOW'].sum()

            # Only include months with 3+ heavy snow days
            if heavy_snow_count >= 1:
                snow_wave_months.append({
                    'Year': year,
                    'Month': month,
                    'Month_Name': calendar.month_name[month],
                    'days_count': heavy_snow_count,
                    'events_count': 1  # Each month with 3+ heavy snow days is one event
                })

    # Convert to DataFrame
    snow_wave_stats = pd.DataFrame(snow_wave_months)

# Print summary
print("\nMonths with Heat Waves (showing both days and events):")
print(heat_wave_stats)

print("\nMonths with Cold Waves (showing both days and events):")
print(cold_wave_stats)

print("\nMonths with Precipitation Waves (showing days and events):")
print(precip_wave_stats)

if has_snow_data:
    print("\nMonths with Snow Waves (showing days and events):")
    print(snow_wave_stats)

# Find months with all types of extreme events
print("\nMonths with multiple types of extreme events:")

# Create sets of (year, month) tuples for each event type
heat_wave_set = set(zip(heat_wave_stats['Year'], heat_wave_stats['Month'])) if not heat_wave_stats.empty else set()
cold_wave_set = set(zip(cold_wave_stats['Year'], cold_wave_stats['Month'])) if not cold_wave_stats.empty else set()
precip_wave_set = set(zip(precip_wave_stats['Year'], precip_wave_stats['Month'])) if not precip_wave_stats.empty else set()

if has_snow_data:
    snow_wave_set = set(zip(snow_wave_stats['Year'], snow_wave_stats['Month'])) if not snow_wave_stats.empty else set()

    # Find all combinations
    all_four_events = heat_wave_set.intersection(cold_wave_set, precip_wave_set, snow_wave_set)
    winter_events = cold_wave_set.intersection(precip_wave_set, snow_wave_set)
    summer_events = heat_wave_set.intersection(precip_wave_set)
    cold_snow_events = cold_wave_set.intersection(snow_wave_set)

    if all_four_events:
        print("Months with ALL FOUR extreme events (Heat, Cold, Precipitation, Snow):")
        for year, month in sorted(all_four_events):
            print(f"  {calendar.month_name[month]} {year}")
    else:
        print("No months had all four types of extreme events.")

    if winter_events:
        print("Months with Winter Triple Events (Cold + Precipitation + Snow):")
        for year, month in sorted(winter_events):
            print(f"  {calendar.month_name[month]} {year}")
    else:
        print("No months had Winter Triple Events.")

    if cold_snow_events:
        print("Months with Cold + Snow Events:")
        for year, month in sorted(cold_snow_events):
            print(f"  {calendar.month_name[month]} {year}")
    else:
        print("No months had Cold + Snow Events.")

    if summer_events:
        print("Months with Summer Compound Events (Heat + Precipitation):")
        for year, month in sorted(summer_events):
            print(f"  {calendar.month_name[month]} {year}")
    else:
        print("No months had Summer Compound Events.")
else:
    # Original analysis without snow
    all_extreme_months = heat_wave_set.intersection(cold_wave_set, precip_wave_set)
    if all_extreme_months:
        print("Months with all three types of extreme events (Heat Wave, Cold Wave, and Precipitation Wave):")
        for year, month in sorted(all_extreme_months):
            print(f"  {calendar.month_name[month]} {year}")
    else:
        print("No months had all three types of extreme events.")

# ===== ACADEMIC PLOTS =====

# Create date columns for better time series plotting
def add_date_column(df):
    if df.empty:
        return df
    df = df.copy()
    df['Date'] = pd.to_datetime([f"{year}-{month:02d}-15" for year, month in zip(df['Year'], df['Month'])])
    return df

heat_wave_stats = add_date_column(heat_wave_stats)
cold_wave_stats = add_date_column(cold_wave_stats)
precip_wave_stats = add_date_column(precip_wave_stats)
if has_snow_data:
    snow_wave_stats = add_date_column(snow_wave_stats)

# Determine subplot layout based on snow data availability
if has_snow_data:
    # 4x2 layout for heat, cold, precipitation, and snow
    plt.figure(figsize=(15, 16))
    gs = GridSpec(4, 2, figure=plt.gcf())

    # Time series of event counts (left panels)
    ax1 = plt.subplot(gs[0, 0])
    ax2 = plt.subplot(gs[1, 0])
    ax3 = plt.subplot(gs[2, 0])
    ax4 = plt.subplot(gs[3, 0])

    # Distribution of events by month (right panels)
    ax5 = plt.subplot(gs[0, 1])
    ax6 = plt.subplot(gs[1, 1])
    ax7 = plt.subplot(gs[2, 1])
    ax8 = plt.subplot(gs[3, 1])
else:
    # 3x2 layout for heat, cold, and precipitation only
    plt.figure(figsize=(15, 12))
    gs = GridSpec(3, 2, figure=plt.gcf())

    # Time series of event counts (left panels)
    ax1 = plt.subplot(gs[0, 0])
    ax2 = plt.subplot(gs[1, 0])
    ax3 = plt.subplot(gs[2, 0])

    # Distribution of events by month (right panels)
    ax5 = plt.subplot(gs[0, 1])
    ax6 = plt.subplot(gs[1, 1])
    ax7 = plt.subplot(gs[2, 1])

# Time series of heat wave events
if not heat_wave_stats.empty:
    ax1.plot(heat_wave_stats['Date'], heat_wave_stats['events_count'], 'r-', marker='o', linewidth=1.5)
    ax1.set_ylabel('Number of Heat Wave\nEvents')
    ax1.set_title('Heat Wave Events Over Time')
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    ax1.xaxis.set_major_locator(mdates.YearLocator(2))  # Every 2 years
    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')
else:
    ax1.text(0.5, 0.5, 'No heat wave data available', horizontalalignment='center', transform=ax1.transAxes)

# Time series of cold wave events
if not cold_wave_stats.empty:
    ax2.plot(cold_wave_stats['Date'], cold_wave_stats['events_count'], 'b-', marker='o', linewidth=1.5)
    ax2.set_ylabel('Number of Cold Wave\nEvents')
    ax2.set_title('Cold Wave Events Over Time')
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    ax2.xaxis.set_major_locator(mdates.YearLocator(2))
    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
else:
    ax2.text(0.5, 0.5, 'No cold wave data available', horizontalalignment='center', transform=ax2.transAxes)

# Time series of precipitation wave events
if not precip_wave_stats.empty:
    ax3.plot(precip_wave_stats['Date'], precip_wave_stats['events_count'], 'g-', marker='o', linewidth=1.5)
    ax3.set_ylabel('Number of Precipitation Wave\nEvents')
    ax3.set_title('Precipitation Wave Events Over Time')
    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    ax3.xaxis.set_major_locator(mdates.YearLocator(2))
    plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')
    if not has_snow_data:
        ax3.set_xlabel('Year')
else:
    ax3.text(0.5, 0.5, 'No precipitation wave data available', horizontalalignment='center', transform=ax3.transAxes)

# Time series of snow wave events (if snow data exists)
if has_snow_data:
    if not snow_wave_stats.empty:
        ax4.plot(snow_wave_stats['Date'], snow_wave_stats['events_count'], 'purple', marker='o', linewidth=1.5)
        ax4.set_ylabel('Number of Snow Wave\nEvents')
        ax4.set_title('Snow Wave Events Over Time')
        ax4.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        ax4.xaxis.set_major_locator(mdates.YearLocator(2))
        plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
        ax4.set_xlabel('Year')
    else:
        ax4.text(0.5, 0.5, 'No snow wave data available', horizontalalignment='center', transform=ax4.transAxes)

# Monthly distribution of heat waves
if not heat_wave_stats.empty:
    monthly_heat = heat_wave_stats.groupby('Month')['events_count'].sum()
    ax5.bar(monthly_heat.index, monthly_heat.values, color='red', alpha=0.7)
    ax5.set_ylabel('Total Number of\nHeat Wave Events')
    ax5.set_title('Heat Wave Events by Month')
    ax5.set_xticks(range(1, 13))
    ax5.set_xticklabels([calendar.month_abbr[i] for i in range(1, 13)])
else:
    ax5.text(0.5, 0.5, 'No heat wave data available', horizontalalignment='center', transform=ax5.transAxes)

# Monthly distribution of cold waves
if not cold_wave_stats.empty:
    monthly_cold = cold_wave_stats.groupby('Month')['events_count'].sum()
    ax6.bar(monthly_cold.index, monthly_cold.values, color='blue', alpha=0.7)
    ax6.set_ylabel('Total Number of\nCold Wave Events')
    ax6.set_title('Cold Wave Events by Month')
    ax6.set_xticks(range(1, 13))
    ax6.set_xticklabels([calendar.month_abbr[i] for i in range(1, 13)])
else:
    ax6.text(0.5, 0.5, 'No cold wave data available', horizontalalignment='center', transform=ax6.transAxes)

# Monthly distribution of precipitation waves
if not precip_wave_stats.empty:
    monthly_precip = precip_wave_stats.groupby('Month')['events_count'].sum()
    ax7.bar(monthly_precip.index, monthly_precip.values, color='green', alpha=0.7)
    ax7.set_ylabel('Total Number of\nPrecipitation Wave Events')
    ax7.set_title('Precipitation Wave Events by Month')
    ax7.set_xticks(range(1, 13))
    ax7.set_xticklabels([calendar.month_abbr[i] for i in range(1, 13)])
    if not has_snow_data:
        ax7.set_xlabel('Month')
else:
    ax7.text(0.5, 0.5, 'No precipitation wave data available', horizontalalignment='center', transform=ax7.transAxes)

# Monthly distribution of snow waves (if snow data exists)
if has_snow_data:
    if not snow_wave_stats.empty:
        monthly_snow = snow_wave_stats.groupby('Month')['events_count'].sum()
        ax8.bar(monthly_snow.index, monthly_snow.values, color='purple', alpha=0.7)
        ax8.set_ylabel('Total Number of\nSnow Wave Events')
        ax8.set_title('Snow Wave Events by Month')
        ax8.set_xticks(range(1, 13))
        ax8.set_xticklabels([calendar.month_abbr[i] for i in range(1, 13)])
        ax8.set_xlabel('Month')
    else:
        ax8.text(0.5, 0.5, 'No snow wave data available', horizontalalignment='center', transform=ax8.transAxes)

plt.suptitle('Extreme Weather Events Analysis', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.subplots_adjust(top=0.93)
plt.savefig('extreme_weather_events.png', dpi=300, bbox_inches='tight')
plt.savefig('extreme_weather_events.pdf', bbox_inches='tight')
plt.show()

# Create a second figure showing the relationship between days and events
if has_snow_data:
    # 4x3 layout for all four event types
    plt.figure(figsize=(18, 16))
    subplot_rows = 4
else:
    # 3x3 layout for three event types
    plt.figure(figsize=(15, 12))
    subplot_rows = 3

# First row: Heat Waves
if not heat_wave_stats.empty:
    ax1 = plt.subplot(subplot_rows, 3, 1)
    sns.scatterplot(x='days_count', y='events_count', data=heat_wave_stats, color='red', s=50, alpha=0.7, ax=ax1)
    ax1.set_title('Heat Wave Days vs Events')
    ax1.set_xlabel('Number of Heat Wave Days')
    ax1.set_ylabel('Number of Heat Wave Events')

    ax2 = plt.subplot(subplot_rows, 3, 2)
    yearly_heat_days = heat_wave_stats.groupby('Year')['days_count'].sum().reset_index()
    yearly_heat_events = heat_wave_stats.groupby('Year')['events_count'].sum().reset_index()
    ax2.plot(yearly_heat_days['Year'], yearly_heat_days['days_count'], 'r-', marker='o', label='Days')
    ax2.set_ylabel('Number of Heat Wave Days', color='r')
    ax2.tick_params(axis='y', labelcolor='r')
    ax2.set_xlabel('Year')
    ax2_twin = ax2.twinx()
    ax2_twin.plot(yearly_heat_events['Year'], yearly_heat_events['events_count'], 'r--', marker='s', label='Events')
    ax2_twin.set_ylabel('Number of Heat Wave Events', color='darkred')
    ax2_twin.tick_params(axis='y', labelcolor='darkred')
    ax2.set_title('Yearly Heat Wave Days and Events')

    ax3 = plt.subplot(subplot_rows, 3, 3)
    if len(heat_wave_stats['Year'].unique()) > 1:
        yearly_avg_event_length = heat_wave_stats.groupby('Year').apply(lambda x: x['days_count'].sum() / x['events_count'].sum() if x['events_count'].sum() > 0 else 0).reset_index(name='avg_length')
        ax3.plot(yearly_avg_event_length['Year'], yearly_avg_event_length['avg_length'], 'r-', marker='D')
        ax3.set_ylabel('Average Heat Wave Length (Days)')
        ax3.set_xlabel('Year')
        ax3.set_title('Average Heat Wave Duration')
    else:
        ax3.text(0.5, 0.5, 'Insufficient data for trend analysis', horizontalalignment='center', transform=ax3.transAxes)

# Second row: Cold Waves
if not cold_wave_stats.empty:
    ax4 = plt.subplot(subplot_rows, 3, 4)
    sns.scatterplot(x='days_count', y='events_count', data=cold_wave_stats, color='blue', s=50, alpha=0.7, ax=ax4)
    ax4.set_title('Cold Wave Days vs Events')
    ax4.set_xlabel('Number of Cold Wave Days')
    ax4.set_ylabel('Number of Cold Wave Events')

    ax5 = plt.subplot(subplot_rows, 3, 5)
    yearly_cold_days = cold_wave_stats.groupby('Year')['days_count'].sum().reset_index()
    yearly_cold_events = cold_wave_stats.groupby('Year')['events_count'].sum().reset_index()
    ax5.plot(yearly_cold_days['Year'], yearly_cold_days['days_count'], 'b-', marker='o', label='Days')
    ax5.set_ylabel('Number of Cold Wave Days', color='b')
    ax5.tick_params(axis='y', labelcolor='b')
    ax5.set_xlabel('Year')
    ax5_twin = ax5.twinx()
    ax5_twin.plot(yearly_cold_events['Year'], yearly_cold_events['events_count'], 'b--', marker='s', label='Events')
    ax5_twin.set_ylabel('Number of Cold Wave Events', color='darkblue')
    ax5_twin.tick_params(axis='y', labelcolor='darkblue')
    ax5.set_title('Yearly Cold Wave Days and Events')

    ax6 = plt.subplot(subplot_rows, 3, 6)
    if len(cold_wave_stats['Year'].unique()) > 1:
        yearly_avg_event_length = cold_wave_stats.groupby('Year').apply(lambda x: x['days_count'].sum() / x['events_count'].sum() if x['events_count'].sum() > 0 else 0).reset_index(name='avg_length')
        ax6.plot(yearly_avg_event_length['Year'], yearly_avg_event_length['avg_length'], 'b-', marker='D')
        ax6.set_ylabel('Average Cold Wave Length (Days)')
        ax6.set_xlabel('Year')
        ax6.set_title('Average Cold Wave Duration')
    else:
        ax6.text(0.5, 0.5, 'Insufficient data for trend analysis', horizontalalignment='center', transform=ax6.transAxes)

# Third row: Precipitation Waves
if not precip_wave_stats.empty:
    ax7 = plt.subplot(subplot_rows, 3, 7)
    sns.scatterplot(x='days_count', y='events_count', data=precip_wave_stats, color='green', s=50, alpha=0.7, ax=ax7)
    ax7.set_title('Precipitation Wave Days vs Events')
    ax7.set_xlabel('Number of Heavy Precipitation Days')
    ax7.set_ylabel('Number of Precipitation Wave Events')

    ax8 = plt.subplot(subplot_rows, 3, 8)
    yearly_precip_days = precip_wave_stats.groupby('Year')['days_count'].sum().reset_index()
    yearly_precip_events = precip_wave_stats.groupby('Year')['events_count'].sum().reset_index()
    ax8.plot(yearly_precip_days['Year'], yearly_precip_days['days_count'], 'g-', marker='o', label='Days')
    ax8.set_ylabel('Number of Heavy Precip Days', color='g')
    ax8.tick_params(axis='y', labelcolor='g')
    ax8.set_xlabel('Year')
    ax8_twin = ax8.twinx()
    ax8_twin.plot(yearly_precip_events['Year'], yearly_precip_events['events_count'], 'g--', marker='s', label='Events')
    ax8_twin.set_ylabel('Number of Precip Wave Months', color='darkgreen')
    ax8_twin.tick_params(axis='y', labelcolor='darkgreen')
    ax8.set_title('Yearly Heavy Precipitation Days and Wave Months')

    ax9 = plt.subplot(subplot_rows, 3, 9)
    if len(precip_wave_stats['Year'].unique()) > 1:
        yearly_avg_days_per_month = precip_wave_stats.groupby('Year').apply(lambda x: x['days_count'].sum() / x['events_count'].sum() if x['events_count'].sum() > 0 else 0).reset_index(name='avg_days')
        ax9.plot(yearly_avg_days_per_month['Year'], yearly_avg_days_per_month['avg_days'], 'g-', marker='D')
        ax9.set_ylabel('Avg Heavy Precip Days per Wave Month')
        ax9.set_xlabel('Year')
        ax9.set_title('Average Heavy Precipitation Days per Wave Month')
    else:
        ax9.text(0.5, 0.5, 'Insufficient data for trend analysis', horizontalalignment='center', transform=ax9.transAxes)

# Fourth row: Snow Waves (if snow data exists)
if has_snow_data and not snow_wave_stats.empty:
    ax10 = plt.subplot(4, 3, 10)
    sns.scatterplot(x='days_count', y='events_count', data=snow_wave_stats, color='purple', s=50, alpha=0.7, ax=ax10)
    ax10.set_title('Snow Wave Days vs Events')
    ax10.set_xlabel('Number of Heavy Snow Days')
    ax10.set_ylabel('Number of Snow Wave Events')

    ax11 = plt.subplot(4, 3, 11)
    yearly_snow_days = snow_wave_stats.groupby('Year')['days_count'].sum().reset_index()
    yearly_snow_events = snow_wave_stats.groupby('Year')['events_count'].sum().reset_index()
    ax11.plot(yearly_snow_days['Year'], yearly_snow_days['days_count'], color='purple', marker='o', label='Days')
    ax11.set_ylabel('Number of Heavy Snow Days', color='purple')
    ax11.tick_params(axis='y', labelcolor='purple')
    ax11.set_xlabel('Year')
    ax11_twin = ax11.twinx()
    ax11_twin.plot(yearly_snow_events['Year'], yearly_snow_events['events_count'], color='darkviolet', linestyle='--', marker='s', label='Events')
    ax11_twin.set_ylabel('Number of Snow Wave Months', color='darkviolet')
    ax11_twin.tick_params(axis='y', labelcolor='darkviolet')
    ax11.set_title('Yearly Heavy Snow Days and Wave Months')

    ax12 = plt.subplot(4, 3, 12)
    if len(snow_wave_stats['Year'].unique()) > 1:
        yearly_avg_days_per_month = snow_wave_stats.groupby('Year').apply(lambda x: x['days_count'].sum() / x['events_count'].sum() if x['events_count'].sum() > 0 else 0).reset_index(name='avg_days')
        ax12.plot(yearly_avg_days_per_month['Year'], yearly_avg_days_per_month['avg_days'], color='purple', marker='D')
        ax12.set_ylabel('Avg Heavy Snow Days per Wave Month')
        ax12.set_xlabel('Year')
        ax12.set_title('Average Heavy Snow Days per Wave Month')
    else:
        ax12.text(0.5, 0.5, 'Insufficient data for trend analysis', horizontalalignment='center', transform=ax12.transAxes)

plt.suptitle('Detailed Analysis of Extreme Weather Events', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.subplots_adjust(top=0.93)
plt.savefig('extreme_weather_detailed.png', dpi=300, bbox_inches='tight')
plt.savefig('extreme_weather_detailed.pdf', bbox_inches='tight')
plt.show()

# ----- COMPOUND EVENTS ANALYSIS -----
if has_snow_data:
    print("\n" + "="*60)
    print("COMPOUND EXTREME WEATHER EVENTS ANALYSIS")
    print("="*60)

    # Winter Storm Analysis
    winter_storms = weather_with_extremes[weather_with_extremes['WINTER_STORM'] == 1]
    print(f"\nWinter Storm Events: {len(winter_storms)} days")
    if len(winter_storms) > 0:
        winter_by_year = winter_storms.groupby('Year').size()
        print("Winter Storm Days by Year:")
        for year, count in winter_by_year.items():
            print(f"  {year}: {count} days")

    # Heat-Precipitation Compound Analysis
    heat_precip_compound = weather_with_extremes[weather_with_extremes['HEAT_PRECIP_COMPOUND'] == 1]
    print(f"\nHeat-Precipitation Compound Events: {len(heat_precip_compound)} days")
    if len(heat_precip_compound) > 0:
        compound_by_year = heat_precip_compound.groupby('Year').size()
        print("Heat-Precipitation Compound Days by Year:")
        for year, count in compound_by_year.items():
            print(f"  {year}: {count} days")

"""***3. Weather Distribution Analysis and Visualization***"""

# 3.1 Visualize Weather Distributions
# Check if snow data exists
has_snow_data = 'SNWD' in weather_with_extremes.columns

if has_snow_data:
    # 2x3 layout with snow
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=20)
else:
    # 2x2 layout without snow
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=20)

# Distribution of TMAX with thresholds
if has_snow_data:
    ax = axes[0, 0]
else:
    ax = axes[0, 0]

sns.histplot(weather_data['TMAX'], bins=40, kde=True,
             color='steelblue', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', linewidth=2,
           label=f'Hot Day Threshold: {weather_thresholds["hot_threshold"]:.1f}°F')
ax.axvline(x=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', linewidth=2,
           label=f'Cold Day Threshold: {weather_thresholds["cold_threshold"]:.1f}°F')
ax.set_title('Distribution of Daily Maximum Temperature', fontsize=16)
ax.set_xlabel('Maximum Temperature (°F)', fontsize=14)
ax.set_ylabel('Frequency', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=12)

# Distribution of PRCP with threshold (non-zero only)
if has_snow_data:
    ax = axes[0, 1]
else:
    ax = axes[0, 1]

prcp_non_zero = weather_data[weather_data['PRCP'] > 0]['PRCP']
sns.histplot(prcp_non_zero, bins=40, kde=True,
             color='forestgreen', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['precipitation'], color='darkred',
           linestyle='--', linewidth=2,
           label=f'Heavy Precipitation Threshold: {weather_thresholds["precipitation"]:.2f} inches')
ax.set_title('Distribution of Daily Precipitation (Non-Zero Days)', fontsize=16)
ax.set_xlabel('Precipitation (inches)', fontsize=14)
ax.set_ylabel('Frequency', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.set_xlim(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1))
ax.legend(frameon=True, fontsize=12)

# Distribution of Snow Depth (if snow data exists)
if has_snow_data:
    ax = axes[0, 2]
    snow_non_zero = weather_data[weather_data['SNWD'] > 0]['SNWD']
    if len(snow_non_zero) > 0:
        sns.histplot(snow_non_zero, bins=40, kde=True,
                     color='purple', alpha=0.7, ax=ax)

        # Check if snow threshold exists in weather_thresholds
        if 'snow' in weather_thresholds:
            snow_threshold = weather_thresholds['snow']
        elif 'snow_threshold' in weather_thresholds:
            snow_threshold = weather_thresholds['snow_threshold']
        else:
            # Calculate 95th percentile as default threshold
            snow_threshold = snow_non_zero.quantile(0.95)

        ax.axvline(x=snow_threshold, color='darkviolet',
                   linestyle='--', linewidth=2,
                   label=f'Heavy Snow Threshold: {snow_threshold:.1f} inches')
        ax.set_title('Distribution of Daily Snow Depth (Non-Zero Days)', fontsize=16)
        ax.set_xlabel('Snow Depth (inches)', fontsize=14)
        ax.set_ylabel('Frequency', fontsize=14)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(frameon=True, fontsize=12)
    else:
        ax.text(0.5, 0.5, 'No snow data available', horizontalalignment='center',
                verticalalignment='center', transform=ax.transAxes, fontsize=14)
        ax.set_title('Snow Depth Distribution', fontsize=16)

# Time series of extreme hot/cold days by month
if has_snow_data:
    ax = axes[1, 0]
else:
    ax = axes[1, 0]

monthly_hot_cold = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum'
}).reset_index()
monthly_hot_cold['YearMonth'] = pd.to_datetime(monthly_hot_cold['Year'].astype(str) + '-' +
                                              monthly_hot_cold['Month'].astype(str) + '-01')

ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_HOT'],
        color='crimson', marker='o', label='Very Hot Days')
ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_COLD'],
        color='dodgerblue', marker='s', label='Very Cold Days')
ax.set_title('Monthly Extreme Temperature Days', fontsize=16)
ax.set_xlabel('Month', fontsize=14)
ax.set_ylabel('Number of Days', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=12)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45)

# Time series of heavy precipitation days by month
if has_snow_data:
    ax = axes[1, 1]
else:
    ax = axes[1, 1]

monthly_precip = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'HEAVY_PRECIP': 'sum',
    'PRCP': 'sum'
}).reset_index()
monthly_precip['YearMonth'] = pd.to_datetime(monthly_precip['Year'].astype(str) + '-' +
                                           monthly_precip['Month'].astype(str) + '-01')

ax2 = ax.twinx()
ax.bar(monthly_precip['YearMonth'], monthly_precip['PRCP'],
      color='skyblue', alpha=0.7, label='Total Precipitation', width=20)
ax2.plot(monthly_precip['YearMonth'], monthly_precip['HEAVY_PRECIP'],
        color='darkgreen', marker='o', linewidth=2, markersize=6, label='Heavy Precipitation Days')
ax.set_title('Monthly Precipitation Patterns', fontsize=16)
ax.set_xlabel('Month', fontsize=14)
ax.set_ylabel('Total Precipitation (inches)', fontsize=14, color='navy')
ax2.set_ylabel('Heavy Precipitation Days', fontsize=14, color='darkgreen')
ax.grid(True, linestyle='--', alpha=0.7)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45)

# Add a joint legend
lines1, labels1 = ax.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=12)

# Time series of heavy snow days by month (if snow data exists)
if has_snow_data:
    ax = axes[1, 2]
    monthly_snow = weather_with_extremes.groupby(['Year', 'Month']).agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': 'mean'  # Average snow depth
    }).reset_index()
    monthly_snow['YearMonth'] = pd.to_datetime(monthly_snow['Year'].astype(str) + '-' +
                                             monthly_snow['Month'].astype(str) + '-01')

    ax3 = ax.twinx()
    ax.bar(monthly_snow['YearMonth'], monthly_snow['SNWD'],
          color='plum', alpha=0.7, label='Average Snow Depth', width=20)
    ax3.plot(monthly_snow['YearMonth'], monthly_snow['HEAVY_SNOW'],
            color='darkviolet', marker='o', linewidth=2, markersize=6, label='Heavy Snow Days')
    ax.set_title('Monthly Snow Patterns', fontsize=16)
    ax.set_xlabel('Month', fontsize=14)
    ax.set_ylabel('Average Snow Depth (inches)', fontsize=14, color='purple')
    ax3.set_ylabel('Heavy Snow Days', fontsize=14, color='darkviolet')
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    ax.tick_params(axis='x', rotation=45)

    # Add a joint legend
    lines1, labels1 = ax.get_legend_handles_labels()
    lines2, labels2 = ax3.get_legend_handles_labels()
    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=12)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure2_weather_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.2 Visualize Extreme Weather Events Time Series
if has_snow_data:
    # 4 subplots with snow
    plt.figure(figsize=(18, 16))
    subplot_count = 4
else:
    # 3 subplots without snow
    plt.figure(figsize=(18, 12))
    subplot_count = 3

# Plot temperature extremes with heat/cold waves
plt.subplot(subplot_count, 1, 1)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'TMAX'],
            color='crimson', marker='o', s=30, alpha=0.7, label='Very Hot Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'TMAX'],
            color='darkred', marker='*', s=100, alpha=0.9, label='Heat Wave (3+ days)')

plt.axhline(y=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Hot Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=14)
plt.title('Extreme Heat Events (2019-2024)', fontsize=16)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=12)

# Plot cold extremes
plt.subplot(subplot_count, 1, 2)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'TMAX'],
            color='dodgerblue', marker='o', s=30, alpha=0.7, label='Very Cold Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'TMAX'],
            color='darkblue', marker='*', s=100, alpha=0.9, label='Cold Wave (3+ days)')

plt.axhline(y=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Cold Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=14)
plt.title('Extreme Cold Events (2019-2024)', fontsize=16)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=12)

# Plot precipitation extremes
plt.subplot(subplot_count, 1, 3)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['PRCP'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'PRCP'],
            color='darkgreen', marker='o', s=30, alpha=0.7, label='Heavy Precipitation')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['CONSEC_PRECIP']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['CONSEC_PRECIP']==1, 'PRCP'],
            color='purple', marker='*', s=100, alpha=0.9, label='Consecutive Heavy Precip')

plt.axhline(y=weather_thresholds['precipitation'], color='darkgreen',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Precip Threshold')
plt.ylabel('Precipitation (inches)', fontsize=14)
if not has_snow_data:
    plt.xlabel('Date', fontsize=14)
plt.title('Heavy Precipitation Events (2019-2024)', fontsize=16)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=12)

# Plot snow extremes (if snow data exists)
if has_snow_data:
    plt.subplot(4, 1, 4)
    plt.plot(weather_with_extremes['DATE'], weather_with_extremes['SNWD'],
             'steelblue', alpha=0.3, linewidth=0.8)
    plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'DATE'],
                weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'SNWD'],
                color='darkviolet', marker='o', s=30, alpha=0.7, label='Heavy Snow Days')

    # Add winter storm events if they exist
    if 'WINTER_STORM' in weather_with_extremes.columns:
        plt.scatter(weather_with_extremes.loc[weather_with_extremes['WINTER_STORM']==1, 'DATE'],
                    weather_with_extremes.loc[weather_with_extremes['WINTER_STORM']==1, 'SNWD'],
                    color='purple', marker='*', s=100, alpha=0.9, label='Winter Storm Events')

    # Check if snow threshold exists
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        # Calculate 95th percentile as default threshold
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    plt.axhline(y=snow_threshold, color='darkviolet',
               linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Snow Threshold')
    plt.ylabel('Snow Depth (inches)', fontsize=14)
    plt.xlabel('Date', fontsize=14)
    plt.title('Heavy Snow Events (2019-2024)', fontsize=16)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(loc='upper right', frameon=True, fontsize=12)

plt.tight_layout()
plt.savefig('figure3_extreme_weather_timeseries.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.3 Additional Snow Analysis (if snow data exists)
if has_snow_data:
    print("\n" + "="*60)
    print("SNOW STATISTICS SUMMARY")
    print("="*60)

    # Snow statistics
    total_snow_days = (weather_with_extremes['SNWD'] > 0).sum()
    heavy_snow_days = weather_with_extremes['HEAVY_SNOW'].sum()
    max_snow_depth = weather_with_extremes['SNWD'].max()
    avg_snow_depth = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD'].mean()

    print(f"Total days with snow on ground: {total_snow_days}")
    print(f"Heavy snow days (>threshold): {heavy_snow_days}")

    # Determine snow threshold for reporting
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    print(f"Snow threshold used: {snow_threshold:.1f} inches")
    print(f"Maximum snow depth recorded: {max_snow_depth:.1f} inches")
    print(f"Average snow depth (snow days only): {avg_snow_depth:.2f} inches")

    # Snow by winter season
    print("\nSnow by Winter Season:")
    weather_with_extremes['WinterSeason'] = weather_with_extremes['Year'].where(
        weather_with_extremes['Month'] >= 11, weather_with_extremes['Year'] - 1
    )

    winter_snow = weather_with_extremes.groupby('WinterSeason').agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': ['max', 'mean']
    }).round(2)

    winter_snow.columns = ['Heavy_Snow_Days', 'Max_Snow_Depth', 'Avg_Snow_Depth']
    print(winter_snow)

# 3.1 Visualize Weather Distributions
# Check if snow data exists
has_snow_data = 'SNWD' in weather_with_extremes.columns

if has_snow_data:
    # 2x3 layout with snow
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=14, fontweight='bold')
else:
    # 2x2 layout without snow
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=14, fontweight='bold')

# Distribution of TMAX with thresholds
if has_snow_data:
    ax = axes[0, 0]
else:
    ax = axes[0, 0]

sns.histplot(weather_data['TMAX'], bins=40, kde=True,
             color='steelblue', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', linewidth=2,
           label=f'Hot Day Threshold: {weather_thresholds["hot_threshold"]:.1f}°F')
ax.axvline(x=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', linewidth=2,
           label=f'Cold Day Threshold: {weather_thresholds["cold_threshold"]:.1f}°F')
ax.set_title('(a) Distribution of Daily Maximum Temperature', fontsize=11, fontweight='bold')
ax.set_xlabel('Maximum Temperature (°F)', fontsize=10)
ax.set_ylabel('Frequency', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=9)

# Distribution of PRCP with threshold (non-zero only)
if has_snow_data:
    ax = axes[0, 1]
else:
    ax = axes[0, 1]

prcp_non_zero = weather_data[weather_data['PRCP'] > 0]['PRCP']
sns.histplot(prcp_non_zero, bins=40, kde=True,
             color='forestgreen', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['precipitation'], color='darkred',
           linestyle='--', linewidth=2,
           label=f'Heavy Precipitation Threshold: {weather_thresholds["precipitation"]:.2f} inches')
ax.set_title('(b) Distribution of Daily Precipitation (Non-Zero Days)', fontsize=11, fontweight='bold')
ax.set_xlabel('Precipitation (inches)', fontsize=10)
ax.set_ylabel('Frequency', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.set_xlim(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1))
# Set x-axis ticks to 0.2 inch increments
ax.set_xticks(np.arange(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1) + 0.2, 0.2))
ax.legend(frameon=True, fontsize=9)

# Distribution of Snow Depth (if snow data exists)
if has_snow_data:
    ax = axes[0, 2]
    snow_non_zero = weather_data[weather_data['SNWD'] > 0]['SNWD']
    if len(snow_non_zero) > 0:
        sns.histplot(snow_non_zero, bins=40, kde=True,
                     color='purple', alpha=0.7, ax=ax)

        # Check if snow threshold exists in weather_thresholds
        if 'snow' in weather_thresholds:
            snow_threshold = weather_thresholds['snow']
        elif 'snow_threshold' in weather_thresholds:
            snow_threshold = weather_thresholds['snow_threshold']
        else:
            # Calculate 95th percentile as default threshold
            snow_threshold = snow_non_zero.quantile(0.95)

        ax.axvline(x=snow_threshold, color='darkviolet',
                   linestyle='--', linewidth=2,
                   label=f'Heavy Snow Threshold: {snow_threshold:.1f} inches')
        ax.set_title('(c) Distribution of Daily Snow Depth (Non-Zero Days)', fontsize=11, fontweight='bold')
        ax.set_xlabel('Snow Depth (inches)', fontsize=10)
        ax.set_ylabel('Frequency', fontsize=10)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(frameon=True, fontsize=9)
    else:
        ax.text(0.5, 0.5, 'No snow data available', horizontalalignment='center',
                verticalalignment='center', transform=ax.transAxes, fontsize=14)
        ax.set_title('(c) Snow Depth Distribution', fontsize=11, fontweight='bold')

# Time series of extreme hot/cold days by month
if has_snow_data:
    ax = axes[1, 0]
else:
    ax = axes[1, 0]

monthly_hot_cold = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum'
}).reset_index()
monthly_hot_cold['YearMonth'] = pd.to_datetime(monthly_hot_cold['Year'].astype(str) + '-' +
                                              monthly_hot_cold['Month'].astype(str) + '-01')

ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_HOT'],
        color='crimson', marker='o', label='Very Hot Days')
ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_COLD'],
        color='dodgerblue', marker='s', label='Very Cold Days')
ax.set_title('(d) Monthly Extreme Temperature Days', fontsize=11, fontweight='bold')
ax.set_xlabel('Month', fontsize=10)
ax.set_ylabel('Number of Days', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=9)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)

# Time series of heavy precipitation days by month
if has_snow_data:
    ax = axes[1, 1]
else:
    ax = axes[1, 1]

monthly_precip = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'HEAVY_PRECIP': 'sum',
    'PRCP': 'sum'
}).reset_index()
monthly_precip['YearMonth'] = pd.to_datetime(monthly_precip['Year'].astype(str) + '-' +
                                           monthly_precip['Month'].astype(str) + '-01')

ax2 = ax.twinx()
ax.bar(monthly_precip['YearMonth'], monthly_precip['PRCP'],
      color='skyblue', alpha=0.7, label='Total Precipitation', width=20)
ax2.plot(monthly_precip['YearMonth'], monthly_precip['HEAVY_PRECIP'],
        color='darkgreen', marker='o', linewidth=2, markersize=6, label='Heavy Precipitation Days')
ax.set_title('(e) Monthly Precipitation Patterns', fontsize=11, fontweight='bold')
ax.set_xlabel('Month', fontsize=10)
ax.set_ylabel('Total Precipitation (inches)', fontsize=10, color='navy')
ax2.set_ylabel('Heavy Precipitation Days', fontsize=10, color='darkgreen')
ax.grid(True, linestyle='--', alpha=0.7)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)
ax2.tick_params(axis='y', labelsize=8)

# Add a joint legend
lines1, labels1 = ax.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=9)

# Time series of heavy snow days by month (if snow data exists)
if has_snow_data:
    ax = axes[1, 2]
    monthly_snow = weather_with_extremes.groupby(['Year', 'Month']).agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': 'mean'  # Average snow depth
    }).reset_index()
    monthly_snow['YearMonth'] = pd.to_datetime(monthly_snow['Year'].astype(str) + '-' +
                                             monthly_snow['Month'].astype(str) + '-01')

    ax3 = ax.twinx()
    ax.bar(monthly_snow['YearMonth'], monthly_snow['SNWD'],
          color='plum', alpha=0.7, label='Average Snow Depth', width=20)
    ax3.plot(monthly_snow['YearMonth'], monthly_snow['HEAVY_SNOW'],
            color='darkviolet', marker='o', linewidth=2, markersize=6, label='Heavy Snow Days')
    ax.set_title('(f) Monthly Snow Patterns', fontsize=11, fontweight='bold')
    ax.set_xlabel('Month', fontsize=10)
    ax.set_ylabel('Average Snow Depth (inches)', fontsize=10, color='purple')
    ax3.set_ylabel('Heavy Snow Days', fontsize=10, color='darkviolet')
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    ax.tick_params(axis='x', rotation=45, labelsize=8)
    ax.tick_params(axis='y', labelsize=8)
    ax3.tick_params(axis='y', labelsize=8)

    # Add a joint legend
    lines1, labels1 = ax.get_legend_handles_labels()
    lines2, labels2 = ax3.get_legend_handles_labels()
    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=9)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure2_weather_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.2 Visualize Extreme Weather Events Time Series
if has_snow_data:
    # 4 subplots with snow
    plt.figure(figsize=(14, 12))
    subplot_count = 4
else:
    # 3 subplots without snow
    plt.figure(figsize=(14, 9))
    subplot_count = 3

# Plot temperature extremes with heat/cold waves
plt.subplot(subplot_count, 1, 1)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'TMAX'],
            color='crimson', marker='o', s=30, alpha=0.7, label='Very Hot Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'TMAX'],
            color='darkred', marker='*', s=100, alpha=0.9, label='Heat Wave (3+ days)')

plt.axhline(y=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Hot Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=10)
plt.title('(a) Extreme Heat Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot cold extremes
plt.subplot(subplot_count, 1, 2)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'TMAX'],
            color='dodgerblue', marker='o', s=30, alpha=0.7, label='Very Cold Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'TMAX'],
            color='darkblue', marker='*', s=100, alpha=0.9, label='Cold Wave (3+ days)')

plt.axhline(y=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Cold Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=10)
plt.title('(b) Extreme Cold Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot precipitation extremes
plt.subplot(subplot_count, 1, 3)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['PRCP'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'PRCP'],
            color='darkgreen', marker='o', s=30, alpha=0.7, label='Heavy Precipitation')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['CONSEC_PRECIP']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['CONSEC_PRECIP']==1, 'PRCP'],
            color='purple', marker='*', s=100, alpha=0.9, label='Consecutive Heavy Precip')

plt.axhline(y=weather_thresholds['precipitation'], color='darkgreen',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Precip Threshold')
plt.ylabel('Precipitation (inches)', fontsize=10)
if not has_snow_data:
    plt.xlabel('Date', fontsize=10)
plt.title('(c) Heavy Precipitation Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot snow extremes (if snow data exists)
if has_snow_data:
    plt.subplot(4, 1, 4)
    plt.plot(weather_with_extremes['DATE'], weather_with_extremes['SNWD'],
             'steelblue', alpha=0.3, linewidth=0.8)
    plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'DATE'],
                weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'SNWD'],
                color='darkviolet', marker='o', s=30, alpha=0.7, label='Heavy Snow Days')

    # Add winter storm events if they exist
    if 'WINTER_STORM' in weather_with_extremes.columns:
        plt.scatter(weather_with_extremes.loc[weather_with_extremes['WINTER_STORM']==1, 'DATE'],
                    weather_with_extremes.loc[weather_with_extremes['WINTER_STORM']==1, 'SNWD'],
                    color='purple', marker='*', s=100, alpha=0.9, label='Winter Storm Events')

    # Check if snow threshold exists
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        # Calculate 95th percentile as default threshold
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    plt.axhline(y=snow_threshold, color='darkviolet',
               linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Snow Threshold')
    plt.ylabel('Snow Depth (inches)', fontsize=10)
    plt.xlabel('Date', fontsize=10)
    plt.title('(d) Heavy Snow Events (2019-2024)', fontsize=11, fontweight='bold')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(loc='upper right', frameon=True, fontsize=9)
    plt.tick_params(axis='both', labelsize=8)

plt.tight_layout()
plt.savefig('figure3_extreme_weather_timeseries.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.3 Additional Snow Analysis (if snow data exists)
if has_snow_data:
    print("\n" + "="*60)
    print("SNOW STATISTICS SUMMARY")
    print("="*60)

    # Snow statistics
    total_snow_days = (weather_with_extremes['SNWD'] > 0).sum()
    heavy_snow_days = weather_with_extremes['HEAVY_SNOW'].sum()
    max_snow_depth = weather_with_extremes['SNWD'].max()
    avg_snow_depth = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD'].mean()

    print(f"Total days with snow on ground: {total_snow_days}")
    print(f"Heavy snow days (>threshold): {heavy_snow_days}")

    # Determine snow threshold for reporting
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    print(f"Snow threshold used: {snow_threshold:.1f} inches")
    print(f"Maximum snow depth recorded: {max_snow_depth:.1f} inches")
    print(f"Average snow depth (snow days only): {avg_snow_depth:.2f} inches")

    # Snow by winter season
    print("\nSnow by Winter Season:")
    weather_with_extremes['WinterSeason'] = weather_with_extremes['Year'].where(
        weather_with_extremes['Month'] >= 11, weather_with_extremes['Year'] - 1
    )

    winter_snow = weather_with_extremes.groupby('WinterSeason').agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': ['max', 'mean']
    }).round(2)

    winter_snow.columns = ['Heavy_Snow_Days', 'Max_Snow_Depth', 'Avg_Snow_Depth']
    print(winter_snow)

# 3.1 Visualize Weather Distributions
# Check if snow data exists
has_snow_data = 'SNWD' in weather_with_extremes.columns

if has_snow_data:
    # 2x3 layout with snow
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=14, fontweight='bold')
else:
    # 2x2 layout without snow
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=14, fontweight='bold')

# Distribution of TMAX with thresholds
if has_snow_data:
    ax = axes[0, 0]
else:
    ax = axes[0, 0]

sns.histplot(weather_data['TMAX'], bins=40, kde=True,
             color='steelblue', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', linewidth=2,
           label=f'Hot Day Threshold: {weather_thresholds["hot_threshold"]:.1f}°F')
ax.axvline(x=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', linewidth=2,
           label=f'Cold Day Threshold: {weather_thresholds["cold_threshold"]:.1f}°F')
ax.set_title('(a) Distribution of Daily Maximum Temperature', fontsize=11, fontweight='bold')
ax.set_xlabel('Maximum Temperature (°F)', fontsize=10)
ax.set_ylabel('Frequency', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=9)

# Distribution of PRCP with threshold (non-zero only)
if has_snow_data:
    ax = axes[0, 1]
else:
    ax = axes[0, 1]

prcp_non_zero = weather_data[weather_data['PRCP'] > 0]['PRCP']
sns.histplot(prcp_non_zero, bins=40, kde=True,
             color='forestgreen', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['precipitation'], color='darkred',
           linestyle='--', linewidth=2,
           label=f'Heavy Precipitation Threshold: {weather_thresholds["precipitation"]:.2f} inches')
ax.set_title('(b) Distribution of Daily Precipitation (Non-Zero Days)', fontsize=11, fontweight='bold')
ax.set_xlabel('Precipitation (inches)', fontsize=10)
ax.set_ylabel('Frequency', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.set_xlim(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1))
# Set x-axis ticks to 0.2 inch increments
ax.set_xticks(np.arange(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1) + 0.2, 0.2))
ax.legend(frameon=True, fontsize=9)

# Distribution of Snow Depth (if snow data exists)
if has_snow_data:
    ax = axes[0, 2]
    snow_non_zero = weather_data[weather_data['SNWD'] > 0]['SNWD']
    if len(snow_non_zero) > 0:
        sns.histplot(snow_non_zero, bins=40, kde=True,
                     color='purple', alpha=0.7, ax=ax)

        # Check if snow threshold exists in weather_thresholds
        if 'snow' in weather_thresholds:
            snow_threshold = weather_thresholds['snow']
        elif 'snow_threshold' in weather_thresholds:
            snow_threshold = weather_thresholds['snow_threshold']
        else:
            # Calculate 95th percentile as default threshold
            snow_threshold = snow_non_zero.quantile(0.95)

        ax.axvline(x=snow_threshold, color='darkviolet',
                   linestyle='--', linewidth=2,
                   label=f'Heavy Snow Threshold: {snow_threshold:.1f} inches')
        ax.set_title('(c) Distribution of Daily Snow Depth (Non-Zero Days)', fontsize=11, fontweight='bold')
        ax.set_xlabel('Snow Depth (inches)', fontsize=10)
        ax.set_ylabel('Frequency', fontsize=10)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(frameon=True, fontsize=9)
    else:
        ax.text(0.5, 0.5, 'No snow data available', horizontalalignment='center',
                verticalalignment='center', transform=ax.transAxes, fontsize=14)
        ax.set_title('(c) Snow Depth Distribution', fontsize=11, fontweight='bold')

# Time series of extreme hot/cold days by month
if has_snow_data:
    ax = axes[1, 0]
else:
    ax = axes[1, 0]

monthly_hot_cold = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum'
}).reset_index()
monthly_hot_cold['YearMonth'] = pd.to_datetime(monthly_hot_cold['Year'].astype(str) + '-' +
                                              monthly_hot_cold['Month'].astype(str) + '-01')

ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_HOT'],
        color='crimson', marker='o', label='Very Hot Days')
ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_COLD'],
        color='dodgerblue', marker='s', label='Very Cold Days')
ax.set_title('(d) Monthly Extreme Temperature Days', fontsize=11, fontweight='bold')
ax.set_xlabel('Month', fontsize=10)
ax.set_ylabel('Number of Days', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=9)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)

# Time series of heavy precipitation days by month
if has_snow_data:
    ax = axes[1, 1]
else:
    ax = axes[1, 1]

monthly_precip = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'HEAVY_PRECIP': 'sum',
    'PRCP': 'sum'
}).reset_index()
monthly_precip['YearMonth'] = pd.to_datetime(monthly_precip['Year'].astype(str) + '-' +
                                           monthly_precip['Month'].astype(str) + '-01')

ax2 = ax.twinx()
ax.bar(monthly_precip['YearMonth'], monthly_precip['PRCP'],
      color='skyblue', alpha=0.7, label='Total Precipitation', width=20)
ax2.plot(monthly_precip['YearMonth'], monthly_precip['HEAVY_PRECIP'],
        color='darkgreen', marker='o', linewidth=2, markersize=6, label='Heavy Precipitation Days')
ax.set_title('(e) Monthly Precipitation Patterns', fontsize=11, fontweight='bold')
ax.set_xlabel('Month', fontsize=10)
ax.set_ylabel('Total Precipitation (inches)', fontsize=10, color='navy')
ax2.set_ylabel('Heavy Precipitation Days', fontsize=10, color='darkgreen')
ax.grid(True, linestyle='--', alpha=0.7)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)
ax2.tick_params(axis='y', labelsize=8)

# Add a joint legend
lines1, labels1 = ax.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=9)

# Time series of heavy snow days by month (if snow data exists)
if has_snow_data:
    ax = axes[1, 2]
    monthly_snow = weather_with_extremes.groupby(['Year', 'Month']).agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': 'mean'  # Average snow depth
    }).reset_index()
    monthly_snow['YearMonth'] = pd.to_datetime(monthly_snow['Year'].astype(str) + '-' +
                                             monthly_snow['Month'].astype(str) + '-01')

    ax3 = ax.twinx()
    ax.bar(monthly_snow['YearMonth'], monthly_snow['SNWD'],
          color='plum', alpha=0.7, label='Average Snow Depth', width=20)
    ax3.plot(monthly_snow['YearMonth'], monthly_snow['HEAVY_SNOW'],
            color='darkviolet', marker='o', linewidth=2, markersize=6, label='Heavy Snow Days')
    ax.set_title('(f) Monthly Snow Patterns', fontsize=11, fontweight='bold')
    ax.set_xlabel('Month', fontsize=10)
    ax.set_ylabel('Average Snow Depth (inches)', fontsize=10, color='purple')
    ax3.set_ylabel('Heavy Snow Days', fontsize=10, color='darkviolet')
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    ax.tick_params(axis='x', rotation=45, labelsize=8)
    ax.tick_params(axis='y', labelsize=8)
    ax3.tick_params(axis='y', labelsize=8)

    # Add a joint legend
    lines1, labels1 = ax.get_legend_handles_labels()
    lines2, labels2 = ax3.get_legend_handles_labels()
    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=9)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure2_weather_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.2 Visualize Extreme Weather Events Time Series
if has_snow_data:
    # 4 subplots with snow
    plt.figure(figsize=(14, 12))
    subplot_count = 4
else:
    # 3 subplots without snow
    plt.figure(figsize=(14, 9))
    subplot_count = 3

# Plot temperature extremes with heat/cold waves
plt.subplot(subplot_count, 1, 1)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'TMAX'],
            color='crimson', marker='o', s=30, alpha=0.7, label='Very Hot Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'TMAX'],
            color='darkred', marker='*', s=100, alpha=0.9, label='Heat Wave (3+ days)')

plt.axhline(y=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Hot Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=10)
plt.title('(a) Extreme Heat Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot cold extremes
plt.subplot(subplot_count, 1, 2)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'TMAX'],
            color='dodgerblue', marker='o', s=30, alpha=0.7, label='Very Cold Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'TMAX'],
            color='darkblue', marker='*', s=100, alpha=0.9, label='Cold Wave (3+ days)')

plt.axhline(y=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Cold Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=10)
plt.title('(b) Extreme Cold Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot precipitation extremes
plt.subplot(subplot_count, 1, 3)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['PRCP'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'PRCP'],
            color='darkgreen', marker='o', s=30, alpha=0.7, label='Heavy Precipitation Days')

# Mark months with 3+ heavy precipitation days as Heavy Precipitation Events
monthly_heavy_precip = weather_with_extremes.groupby(['Year', 'Month'])['HEAVY_PRECIP'].sum().reset_index()
monthly_heavy_precip = monthly_heavy_precip[monthly_heavy_precip['HEAVY_PRECIP'] >= 3]
if len(monthly_heavy_precip) > 0:
    # Get all heavy precip days in months with 3+ events
    event_months = list(zip(monthly_heavy_precip['Year'], monthly_heavy_precip['Month']))
    heavy_precip_events = weather_with_extremes[
        weather_with_extremes.apply(lambda x: (x['Year'], x['Month']) in event_months, axis=1) &
        (weather_with_extremes['HEAVY_PRECIP'] == 1)
    ]
    plt.scatter(heavy_precip_events['DATE'], heavy_precip_events['PRCP'],
                color='purple', marker='*', s=100, alpha=0.9, label='Heavy Precipitation Events')

plt.axhline(y=weather_thresholds['precipitation'], color='darkgreen',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Precip Threshold')
plt.ylabel('Precipitation (inches)', fontsize=10)
if not has_snow_data:
    plt.xlabel('Date', fontsize=10)
plt.title('(c) Heavy Precipitation Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot snow extremes (if snow data exists)
if has_snow_data:
    plt.subplot(4, 1, 4)
    plt.plot(weather_with_extremes['DATE'], weather_with_extremes['SNWD'],
             'steelblue', alpha=0.3, linewidth=0.8)
    plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'DATE'],
                weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'SNWD'],
                color='darkviolet', marker='o', s=30, alpha=0.7, label='Heavy Snow Days')

    # Mark months with 3+ heavy snow days as Heavy Snow Events
    monthly_heavy_snow = weather_with_extremes.groupby(['Year', 'Month'])['HEAVY_SNOW'].sum().reset_index()
    monthly_heavy_snow = monthly_heavy_snow[monthly_heavy_snow['HEAVY_SNOW'] >= 3]
    if len(monthly_heavy_snow) > 0:
        # Get all heavy snow days in months with 3+ events
        event_months = list(zip(monthly_heavy_snow['Year'], monthly_heavy_snow['Month']))
        heavy_snow_events = weather_with_extremes[
            weather_with_extremes.apply(lambda x: (x['Year'], x['Month']) in event_months, axis=1) &
            (weather_with_extremes['HEAVY_SNOW'] == 1)
        ]
        plt.scatter(heavy_snow_events['DATE'], heavy_snow_events['SNWD'],
                    color='purple', marker='*', s=100, alpha=0.9, label='Heavy Snow Events')

    # Check if snow threshold exists
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        # Calculate 95th percentile as default threshold
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    plt.axhline(y=snow_threshold, color='darkviolet',
               linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Snow Threshold')
    plt.ylabel('Snow Depth (inches)', fontsize=10)
    plt.xlabel('Date', fontsize=10)
    plt.title('(d) Heavy Snow Events (2019-2024)', fontsize=11, fontweight='bold')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(loc='upper right', frameon=True, fontsize=9)
    plt.tick_params(axis='both', labelsize=8)

plt.tight_layout()
plt.savefig('figure3_extreme_weather_timeseries.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.3 Additional Snow Analysis (if snow data exists)
if has_snow_data:
    print("\n" + "="*60)
    print("SNOW STATISTICS SUMMARY")
    print("="*60)

    # Snow statistics
    total_snow_days = (weather_with_extremes['SNWD'] > 0).sum()
    heavy_snow_days = weather_with_extremes['HEAVY_SNOW'].sum()
    max_snow_depth = weather_with_extremes['SNWD'].max()
    avg_snow_depth = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD'].mean()

    print(f"Total days with snow on ground: {total_snow_days}")
    print(f"Heavy snow days (>threshold): {heavy_snow_days}")

    # Determine snow threshold for reporting
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    print(f"Snow threshold used: {snow_threshold:.1f} inches")
    print(f"Maximum snow depth recorded: {max_snow_depth:.1f} inches")
    print(f"Average snow depth (snow days only): {avg_snow_depth:.2f} inches")

    # Snow by winter season
    print("\nSnow by Winter Season:")
    weather_with_extremes['WinterSeason'] = weather_with_extremes['Year'].where(
        weather_with_extremes['Month'] >= 11, weather_with_extremes['Year'] - 1
    )

    winter_snow = weather_with_extremes.groupby('WinterSeason').agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': ['max', 'mean']
    }).round(2)

    winter_snow.columns = ['Heavy_Snow_Days', 'Max_Snow_Depth', 'Avg_Snow_Depth']
    print(winter_snow)

# 3.1 Visualize Weather Distributions
# Check if snow data exists
has_snow_data = 'SNWD' in weather_with_extremes.columns

if has_snow_data:
    # 2x3 layout with snow
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=14, fontweight='bold')
else:
    # 2x2 layout without snow
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('Weather Distributions in Philadelphia (2019-Present)', fontsize=14, fontweight='bold')

# Distribution of TMAX with thresholds
if has_snow_data:
    ax = axes[0, 0]
else:
    ax = axes[0, 0]

sns.histplot(weather_data['TMAX'], bins=40, kde=True,
             color='steelblue', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', linewidth=2,
           label=f'Hot Day Threshold: {weather_thresholds["hot_threshold"]:.1f}°F')
ax.axvline(x=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', linewidth=2,
           label=f'Cold Day Threshold: {weather_thresholds["cold_threshold"]:.1f}°F')
ax.set_title('(a) Distribution of Daily Maximum Temperature', fontsize=11, fontweight='bold')
ax.set_xlabel('Maximum Temperature (°F)', fontsize=10)
ax.set_ylabel('Frequency', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=9)

# Distribution of PRCP with threshold (non-zero only)
if has_snow_data:
    ax = axes[0, 1]
else:
    ax = axes[0, 1]

prcp_non_zero = weather_data[weather_data['PRCP'] > 0]['PRCP']
sns.histplot(prcp_non_zero, bins=40, kde=True,
             color='forestgreen', alpha=0.7, ax=ax)
ax.axvline(x=weather_thresholds['precipitation'], color='darkred',
           linestyle='--', linewidth=2,
           label=f'Heavy Precipitation Threshold: {weather_thresholds["precipitation"]:.2f} inches')
ax.set_title('(b) Distribution of Daily Precipitation (Non-Zero Days)', fontsize=11, fontweight='bold')
ax.set_xlabel('Precipitation (inches)', fontsize=10)
ax.set_ylabel('Frequency', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.set_xlim(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1))
# Set x-axis ticks to 0.2 inch increments
ax.set_xticks(np.arange(0, min(max(prcp_non_zero), weather_thresholds['precipitation']*1) + 0.2, 0.2))
ax.legend(frameon=True, fontsize=9)

# Distribution of Snow Depth (if snow data exists)
if has_snow_data:
    ax = axes[0, 2]
    snow_non_zero = weather_data[weather_data['SNWD'] > 0]['SNWD']
    if len(snow_non_zero) > 0:
        sns.histplot(snow_non_zero, bins=40, kde=True,
                     color='purple', alpha=0.7, ax=ax)

        # Check if snow threshold exists in weather_thresholds
        if 'snow' in weather_thresholds:
            snow_threshold = weather_thresholds['snow']
        elif 'snow_threshold' in weather_thresholds:
            snow_threshold = weather_thresholds['snow_threshold']
        else:
            # Calculate 95th percentile as default threshold
            snow_threshold = snow_non_zero.quantile(0.95)

        ax.axvline(x=snow_threshold, color='darkviolet',
                   linestyle='--', linewidth=2,
                   label=f'Heavy Snow Threshold: {snow_threshold:.1f} inches')
        ax.set_title('(c) Distribution of Daily Snow Depth (Non-Zero Days)', fontsize=11, fontweight='bold')
        ax.set_xlabel('Snow Depth (inches)', fontsize=10)
        ax.set_ylabel('Frequency', fontsize=10)
        ax.grid(True, linestyle='--', alpha=0.7)
        ax.legend(frameon=True, fontsize=9)
    else:
        ax.text(0.5, 0.5, 'No snow data available', horizontalalignment='center',
                verticalalignment='center', transform=ax.transAxes, fontsize=14)
        ax.set_title('(c) Snow Depth Distribution', fontsize=11, fontweight='bold')

# Time series of extreme hot/cold days by month
if has_snow_data:
    ax = axes[1, 0]
else:
    ax = axes[1, 0]

monthly_hot_cold = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum'
}).reset_index()
monthly_hot_cold['YearMonth'] = pd.to_datetime(monthly_hot_cold['Year'].astype(str) + '-' +
                                              monthly_hot_cold['Month'].astype(str) + '-01')

ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_HOT'],
        color='crimson', marker='o', label='Very Hot Days')
ax.plot(monthly_hot_cold['YearMonth'], monthly_hot_cold['VERY_COLD'],
        color='dodgerblue', marker='s', label='Very Cold Days')
ax.set_title('(d) Monthly Extreme Temperature Days', fontsize=11, fontweight='bold')
ax.set_xlabel('Month', fontsize=10)
ax.set_ylabel('Number of Days', fontsize=10)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(frameon=True, fontsize=9)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)

# Time series of heavy precipitation days by month
if has_snow_data:
    ax = axes[1, 1]
else:
    ax = axes[1, 1]

monthly_precip = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'HEAVY_PRECIP': 'sum',
    'PRCP': 'sum'
}).reset_index()
monthly_precip['YearMonth'] = pd.to_datetime(monthly_precip['Year'].astype(str) + '-' +
                                           monthly_precip['Month'].astype(str) + '-01')

ax2 = ax.twinx()
ax.bar(monthly_precip['YearMonth'], monthly_precip['PRCP'],
      color='skyblue', alpha=0.7, label='Total Precipitation', width=20)
ax2.plot(monthly_precip['YearMonth'], monthly_precip['HEAVY_PRECIP'],
        color='darkgreen', marker='o', linewidth=2, markersize=6, label='Heavy Precipitation Days')
ax.set_title('(e) Monthly Precipitation Patterns', fontsize=11, fontweight='bold')
ax.set_xlabel('Month', fontsize=10)
ax.set_ylabel('Total Precipitation (inches)', fontsize=10, color='navy')
ax2.set_ylabel('Heavy Precipitation Days', fontsize=10, color='darkgreen')
ax.grid(True, linestyle='--', alpha=0.7)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45, labelsize=8)
ax.tick_params(axis='y', labelsize=8)
ax2.tick_params(axis='y', labelsize=8)

# Add a joint legend
lines1, labels1 = ax.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=9)

# Time series of heavy snow days by month (if snow data exists)
if has_snow_data:
    ax = axes[1, 2]
    monthly_snow = weather_with_extremes.groupby(['Year', 'Month']).agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': 'mean'  # Average snow depth
    }).reset_index()
    monthly_snow['YearMonth'] = pd.to_datetime(monthly_snow['Year'].astype(str) + '-' +
                                             monthly_snow['Month'].astype(str) + '-01')

    ax3 = ax.twinx()
    ax.bar(monthly_snow['YearMonth'], monthly_snow['SNWD'],
          color='plum', alpha=0.7, label='Average Snow Depth', width=20)
    ax3.plot(monthly_snow['YearMonth'], monthly_snow['HEAVY_SNOW'],
            color='darkviolet', marker='o', linewidth=2, markersize=6, label='Heavy Snow Days')
    ax.set_title('(f) Monthly Snow Patterns', fontsize=11, fontweight='bold')
    ax.set_xlabel('Month', fontsize=10)
    ax.set_ylabel('Average Snow Depth (inches)', fontsize=10, color='purple')
    ax3.set_ylabel('Heavy Snow Days', fontsize=10, color='darkviolet')
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    ax.tick_params(axis='x', rotation=45, labelsize=8)
    ax.tick_params(axis='y', labelsize=8)
    ax3.tick_params(axis='y', labelsize=8)

    # Add a joint legend
    lines1, labels1 = ax.get_legend_handles_labels()
    lines2, labels2 = ax3.get_legend_handles_labels()
    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper right', frameon=True, fontsize=9)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure2_weather_distributions.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.2 Visualize Extreme Weather Events Time Series
if has_snow_data:
    # 4 subplots with snow
    plt.figure(figsize=(14, 12))
    subplot_count = 4
else:
    # 3 subplots without snow
    plt.figure(figsize=(14, 9))
    subplot_count = 3

# Plot temperature extremes with heat/cold waves
plt.subplot(subplot_count, 1, 1)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_HOT']==1, 'TMAX'],
            color='crimson', marker='o', s=30, alpha=0.7, label='Very Hot Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEATWAVE']==1, 'TMAX'],
            color='darkred', marker='*', s=100, alpha=0.9, label='Heat Wave (3+ days)')

plt.axhline(y=weather_thresholds['hot_threshold'], color='crimson',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Hot Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=10)
plt.title('(a) Extreme Heat Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot cold extremes
plt.subplot(subplot_count, 1, 2)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['TMAX'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['VERY_COLD']==1, 'TMAX'],
            color='dodgerblue', marker='o', s=30, alpha=0.7, label='Very Cold Days')
plt.scatter(weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['COLDWAVE']==1, 'TMAX'],
            color='darkblue', marker='*', s=100, alpha=0.9, label='Cold Wave (3+ days)')

plt.axhline(y=weather_thresholds['cold_threshold'], color='dodgerblue',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Cold Day Threshold')
plt.ylabel('Maximum Temperature (°F)', fontsize=10)
plt.title('(b) Extreme Cold Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot precipitation extremes
plt.subplot(subplot_count, 1, 3)
plt.plot(weather_with_extremes['DATE'], weather_with_extremes['PRCP'],
         'steelblue', alpha=0.3, linewidth=0.8)
plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'DATE'],
            weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP']==1, 'PRCP'],
            color='darkgreen', marker='o', s=30, alpha=0.7, label='Heavy Precipitation Days')

# Mark months with 3+ heavy precipitation days as Heavy Precipitation Events
monthly_heavy_precip = weather_with_extremes.groupby(['Year', 'Month'])['HEAVY_PRECIP'].sum().reset_index()
monthly_heavy_precip = monthly_heavy_precip[monthly_heavy_precip['HEAVY_PRECIP'] >= 3]
if len(monthly_heavy_precip) > 0:
    # Get all heavy precip days in months with 3+ events
    event_months = list(zip(monthly_heavy_precip['Year'], monthly_heavy_precip['Month']))
    heavy_precip_events = weather_with_extremes[
        weather_with_extremes.apply(lambda x: (x['Year'], x['Month']) in event_months, axis=1) &
        (weather_with_extremes['HEAVY_PRECIP'] == 1)
    ]
    plt.scatter(heavy_precip_events['DATE'], heavy_precip_events['PRCP'],
                color='darkgreen', marker='*', s=100, alpha=0.9, label='Heavy Precipitation Events')

plt.axhline(y=weather_thresholds['precipitation'], color='darkgreen',
           linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Precip Threshold')
plt.ylabel('Precipitation (inches)', fontsize=10)
if not has_snow_data:
    plt.xlabel('Date', fontsize=10)
plt.title('(c) Heavy Precipitation Events (2019-2024)', fontsize=11, fontweight='bold')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(loc='upper right', frameon=True, fontsize=9)
plt.tick_params(axis='both', labelsize=8)

# Plot snow extremes (if snow data exists)
if has_snow_data:
    plt.subplot(4, 1, 4)
    plt.plot(weather_with_extremes['DATE'], weather_with_extremes['SNWD'],
             'steelblue', alpha=0.3, linewidth=0.8)
    plt.scatter(weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'DATE'],
                weather_with_extremes.loc[weather_with_extremes['HEAVY_SNOW']==1, 'SNWD'],
                color='darkviolet', marker='o', s=30, alpha=0.7, label='Heavy Snow Days')

    # Mark months with 1+ heavy snow days as Heavy Snow Events
    monthly_heavy_snow = weather_with_extremes.groupby(['Year', 'Month'])['HEAVY_SNOW'].sum().reset_index()
    monthly_heavy_snow = monthly_heavy_snow[monthly_heavy_snow['HEAVY_SNOW'] >= 1]
    if len(monthly_heavy_snow) > 0:
        # Get all heavy snow days in months with 3+ events
        event_months = list(zip(monthly_heavy_snow['Year'], monthly_heavy_snow['Month']))
        heavy_snow_events = weather_with_extremes[
            weather_with_extremes.apply(lambda x: (x['Year'], x['Month']) in event_months, axis=1) &
            (weather_with_extremes['HEAVY_SNOW'] == 1)
        ]
        plt.scatter(heavy_snow_events['DATE'], heavy_snow_events['SNWD'],
                    color='purple', marker='*', s=100, alpha=0.9, label='Heavy Snow Events')

    # Check if snow threshold exists
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        # Calculate 95th percentile as default threshold
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    plt.axhline(y=snow_threshold, color='darkviolet',
               linestyle='--', alpha=0.8, linewidth=1.5, label='Heavy Snow Threshold')
    plt.ylabel('Snow Depth (inches)', fontsize=10)
    plt.xlabel('Date', fontsize=10)
    plt.title('(d) Heavy Snow Events (2019-2024)', fontsize=11, fontweight='bold')
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend(loc='upper right', frameon=True, fontsize=9)
    plt.tick_params(axis='both', labelsize=8)

plt.tight_layout()
plt.savefig('figure3_extreme_weather_timeseries.png', dpi=300, bbox_inches='tight')
plt.show()

# 3.3 Additional Snow Analysis (if snow data exists)
if has_snow_data:
    print("\n" + "="*60)
    print("SNOW STATISTICS SUMMARY")
    print("="*60)

    # Snow statistics
    total_snow_days = (weather_with_extremes['SNWD'] > 0).sum()
    heavy_snow_days = weather_with_extremes['HEAVY_SNOW'].sum()
    max_snow_depth = weather_with_extremes['SNWD'].max()
    avg_snow_depth = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD'].mean()

    print(f"Total days with snow on ground: {total_snow_days}")
    print(f"Heavy snow days (>threshold): {heavy_snow_days}")

    # Determine snow threshold for reporting
    if 'snow' in weather_thresholds:
        snow_threshold = weather_thresholds['snow']
    elif 'snow_threshold' in weather_thresholds:
        snow_threshold = weather_thresholds['snow_threshold']
    else:
        snow_non_zero = weather_with_extremes[weather_with_extremes['SNWD'] > 0]['SNWD']
        snow_threshold = snow_non_zero.quantile(0.95) if len(snow_non_zero) > 0 else 3.0

    print(f"Snow threshold used: {snow_threshold:.1f} inches")
    print(f"Maximum snow depth recorded: {max_snow_depth:.1f} inches")
    print(f"Average snow depth (snow days only): {avg_snow_depth:.2f} inches")

    # Snow by winter season
    print("\nSnow by Winter Season:")
    weather_with_extremes['WinterSeason'] = weather_with_extremes['Year'].where(
        weather_with_extremes['Month'] >= 11, weather_with_extremes['Year'] - 1
    )

    winter_snow = weather_with_extremes.groupby('WinterSeason').agg({
        'HEAVY_SNOW': 'sum',
        'SNWD': ['max', 'mean']
    }).round(2)

    winter_snow.columns = ['Heavy_Snow_Days', 'Max_Snow_Depth', 'Avg_Snow_Depth']
    print(winter_snow)

"""
Weather Extremes Analysis
-------------------------
This script analyzes historical weather data to identify and visualize extreme weather patterns
including very hot days, very cold days, heavy precipitation, and consecutive extreme events.

Author: Academic Research Team
Date: 2025-04-22
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
from scipy import stats
from datetime import datetime
import matplotlib.ticker as ticker
from matplotlib.colors import LinearSegmentedColormap
import matplotlib.gridspec as gridspec
from google.colab import files
import io
import warnings
warnings.filterwarnings("ignore")

# Set the aesthetics for plots
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_context("notebook", font_scale=1.2)

# Custom color palettes for different visualizations
temp_cmap = LinearSegmentedColormap.from_list('temp_cmap', ['darkblue', 'lightblue', 'yellow', 'orange', 'red'])
precip_cmap = LinearSegmentedColormap.from_list('precip_cmap', ['white', 'lightskyblue', 'royalblue', 'darkblue'])

def load_weather_data():
    """
    Load weather data from a CSV file uploaded by the user.
    Returns a cleaned pandas DataFrame with the weather data.
    """
    print("Please upload your weather data CSV file.")
    uploaded = files.upload()

    for fn in uploaded.keys():
        print(f'User uploaded file "{fn}" with length {len(uploaded[fn])} bytes')

        # Read the CSV data
        df = pd.read_csv(io.StringIO(uploaded[fn].decode('utf-8')))

        # Basic data cleaning
        # Convert date string to datetime
        df['DATE'] = pd.to_datetime(df['DATE'])

        # Extract year and month for aggregation
        df['Year'] = df['DATE'].dt.year
        df['Month'] = df['DATE'].dt.month
        df['YearMonth'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str).str.zfill(2) + '-01')
        df['DayOfYear'] = df['DATE'].dt.dayofyear

        # Handle missing values
        for col in ['TMAX', 'TMIN', 'PRCP']:
            if col in df.columns:
                df[col] = df[col].replace(-9999, np.nan)  # Common missing value indicator

        print(f"Data loaded successfully with {df.shape[0]} records from {df['DATE'].min()} to {df['DATE'].max()}")

        # Return the first uploaded file
        return df

    # If no file was uploaded
    print("No file was uploaded. Please run the cell again and upload a file.")
    return None

def define_extreme_weather_events(df, temp_hot_threshold=95, temp_cold_threshold=20, precip_threshold=1.0):
    """
    Define extreme weather events based on thresholds.

    Parameters:
    -----------
    df : pandas DataFrame
        Weather data with at least TMAX, TMIN, and PRCP columns
    temp_hot_threshold : float
        Temperature threshold (°F) above which a day is considered very hot
    temp_cold_threshold : float
        Temperature threshold (°F) below which a day is considered very cold
    precip_threshold : float
        Precipitation threshold (inches) above which a day is considered heavy precipitation

    Returns:
    --------
    pandas DataFrame with added columns for extreme weather categories
    """
    # Create copy to avoid SettingWithCopyWarning
    df_extremes = df.copy()

    # Define extreme weather indicators (binary)
    df_extremes['VERY_HOT'] = (df_extremes['TMAX'] > temp_hot_threshold).astype(int)
    df_extremes['VERY_COLD'] = (df_extremes['TMIN'] < temp_cold_threshold).astype(int)
    df_extremes['HEAVY_PRECIP'] = (df_extremes['PRCP'] > precip_threshold).astype(int)

    # Create consecutive day counters
    for condition in ['VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP']:
        # Initialize consecutive day counter
        consecutive_col = f"CONSEC_{condition}"
        df_extremes[consecutive_col] = 0

        # Track consecutive days
        is_consecutive = False
        consecutive_count = 0

        for i in range(len(df_extremes)):
            if df_extremes[condition].iloc[i] == 1:
                consecutive_count += 1
                is_consecutive = True
            elif is_consecutive:
                # The streak has ended, mark the preceding days
                df_extremes[consecutive_col].iloc[i-consecutive_count:i] = 1
                consecutive_count = 0
                is_consecutive = False
            else:
                consecutive_count = 0

        # Handle case where dataset ends during a streak
        if is_consecutive:
            df_extremes[consecutive_col].iloc[-consecutive_count:] = 1

    # Define heat waves (3+ consecutive very hot days)
    df_extremes['HEATWAVE'] = 0
    # Find runs of 3 or more consecutive hot days
    hot_streak = 0
    for i in range(len(df_extremes)):
        if df_extremes['VERY_HOT'].iloc[i] == 1:
            hot_streak += 1
            if hot_streak >= 3:
                df_extremes['HEATWAVE'].iloc[i-hot_streak+1:i+1] = 1
        else:
            hot_streak = 0

    # Define cold waves (3+ consecutive very cold days)
    df_extremes['COLDWAVE'] = 0
    # Find runs of 3 or more consecutive cold days
    cold_streak = 0
    for i in range(len(df_extremes)):
        if df_extremes['VERY_COLD'].iloc[i] == 1:
            cold_streak += 1
            if cold_streak >= 3:
                df_extremes['COLDWAVE'].iloc[i-cold_streak+1:i+1] = 1
        else:
            cold_streak = 0

    # Define extreme weather category E(i,j) as described in the equation
    # For each month in each year
    df_extremes['MONTH_HOT_DAYS'] = df_extremes.groupby(['Year', 'Month'])['VERY_HOT'].transform('sum')
    df_extremes['MONTH_COLD_DAYS'] = df_extremes.groupby(['Year', 'Month'])['VERY_COLD'].transform('sum')
    df_extremes['MONTH_HEAVY_PRECIP_DAYS'] = df_extremes.groupby(['Year', 'Month'])['HEAVY_PRECIP'].transform('sum')

    # Define τ=5 as the threshold for classifying a month as extreme
    tau = 5

    # Apply the classification rule for E(i,j)
    conditions = [
        df_extremes['MONTH_HEAVY_PRECIP_DAYS'] > tau,
        df_extremes['MONTH_COLD_DAYS'] > tau,
        df_extremes['MONTH_HOT_DAYS'] > tau
    ]
    choices = ["Heavy Precipitation", "Very Cold", "Very Hot"]
    df_extremes['EXTREME_CATEGORY'] = np.select(conditions, choices, default="Normal")

    # Print summary statistics
    print("\nExtreme Weather Event Statistics:")
    print(f"Very Hot Days: {df_extremes['VERY_HOT'].sum()} ({df_extremes['VERY_HOT'].mean()*100:.1f}% of days)")
    print(f"Very Cold Days: {df_extremes['VERY_COLD'].sum()} ({df_extremes['VERY_COLD'].mean()*100:.1f}% of days)")
    print(f"Heavy Precipitation Days: {df_extremes['HEAVY_PRECIP'].sum()} ({df_extremes['HEAVY_PRECIP'].mean()*100:.1f}% of days)")
    print(f"Consecutive Heavy Precipitation Days: {df_extremes['CONSEC_HEAVY_PRECIP'].sum()} ({df_extremes['CONSEC_HEAVY_PRECIP'].mean()*100:.1f}% of days)")
    print(f"Heat Wave Days (3+ consecutive hot days): {df_extremes['HEATWAVE'].sum()} ({df_extremes['HEATWAVE'].mean()*100:.1f}% of days)")
    print(f"Cold Wave Days (3+ consecutive cold days): {df_extremes['COLDWAVE'].sum()} ({df_extremes['COLDWAVE'].mean()*100:.1f}% of days)")

    # Monthly extreme category counts
    monthly_extremes = df_extremes.groupby('EXTREME_CATEGORY').size().reset_index(name='count')
    print("\nMonthly Extreme Categories:")
    for _, row in monthly_extremes.iterrows():
        print(f"{row['EXTREME_CATEGORY']}: {row['count']} month-years ({row['count']/df_extremes['EXTREME_CATEGORY'].nunique():.1f}%)")

    return df_extremes

def visualize_extreme_weather_trends(weather_with_extremes):
    """
    Create comprehensive visualizations of extreme weather patterns.

    Parameters:
    -----------
    weather_with_extremes : pandas DataFrame
        Weather data with extreme weather indicators added
    """
    # Set up a 2x2 grid of subplots for the first figure
    fig, axes = plt.subplots(2, 2, figsize=(20, 16))
    fig.suptitle('Extreme Weather Analysis', fontsize=24, y=0.95)

    # 1. Time series of extreme temperature days
    ax = axes[0, 0]
    yearly_extremes = weather_with_extremes.resample('Y', on='DATE').agg({
        'VERY_HOT': 'sum',
        'VERY_COLD': 'sum',
        'HEATWAVE': 'sum',
        'COLDWAVE': 'sum'
    }).reset_index()

    ax.plot(yearly_extremes['DATE'], yearly_extremes['VERY_HOT'],
            marker='o', linewidth=2, label='Very Hot Days', color='red')
    ax.plot(yearly_extremes['DATE'], yearly_extremes['VERY_COLD'],
            marker='s', linewidth=2, label='Very Cold Days', color='blue')
    ax.plot(yearly_extremes['DATE'], yearly_extremes['HEATWAVE'],
            marker='^', linewidth=2, linestyle='--', label='Heat Wave Days', color='darkred')
    ax.plot(yearly_extremes['DATE'], yearly_extremes['COLDWAVE'],
            marker='d', linewidth=2, linestyle='--', label='Cold Wave Days', color='darkblue')

    ax.set_title('Yearly Extreme Temperature Days', fontsize=16)
    ax.set_xlabel('Year', fontsize=14)
    ax.set_ylabel('Number of Days', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.legend(loc='upper left', frameon=True, fontsize=12)

    # 2. Monthly distribution of extreme temperature events
    ax = axes[0, 1]
    monthly_temp_extremes = weather_with_extremes.groupby(weather_with_extremes['DATE'].dt.month).agg({
        'VERY_HOT': 'sum',
        'VERY_COLD': 'sum'
    }).reset_index()

    width = 0.35
    x = np.arange(len(monthly_temp_extremes))
    ax.bar(x - width/2, monthly_temp_extremes['VERY_HOT'], width, label='Very Hot Days', color='orangered')
    ax.bar(x + width/2, monthly_temp_extremes['VERY_COLD'], width, label='Very Cold Days', color='royalblue')

    ax.set_title('Monthly Distribution of Extreme Temperature Days', fontsize=16)
    ax.set_xlabel('Month', fontsize=14)
    ax.set_ylabel('Total Number of Days (All Years)', fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
    ax.legend(loc='upper right', frameon=True, fontsize=12)
    ax.grid(axis='y', linestyle='--', alpha=0.7)

    # 3. Time series of heavy precipitation days
    ax = axes[1, 0]
    yearly_precip = weather_with_extremes.resample('Y', on='DATE').agg({
        'HEAVY_PRECIP': 'sum',
        'CONSEC_HEAVY_PRECIP': 'sum',
        'PRCP': 'sum'
    }).reset_index()

    ax2 = ax.twinx()
    ax.bar(yearly_precip['DATE'], yearly_precip['PRCP'],
           color='skyblue', alpha=0.4, label='Total Annual Precipitation')
    ax2.plot(yearly_precip['DATE'], yearly_precip['HEAVY_PRECIP'],
             marker='o', linewidth=2, color='navy', label='Heavy Precipitation Days')
    ax2.plot(yearly_precip['DATE'], yearly_precip['CONSEC_HEAVY_PRECIP'],
             marker='*', linewidth=2, linestyle='--', color='purple',
             label='Consecutive Heavy Precip Days')

    ax.set_title('Yearly Precipitation Patterns', fontsize=16)
    ax.set_xlabel('Year', fontsize=14)
    ax.set_ylabel('Total Precipitation (inches)', fontsize=14, color='royalblue')
    ax2.set_ylabel('Number of Days', fontsize=14, color='navy')
    ax.grid(True, linestyle='--', alpha=0.7)

    # Add a joint legend
    lines1, labels1 = ax.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left', frameon=True, fontsize=12)

    # 4. Monthly precipitation patterns
    ax = axes[1, 1]
    monthly_precip = weather_with_extremes.groupby(['Year', 'Month']).agg({
        'HEAVY_PRECIP': 'sum',
        'CONSEC_HEAVY_PRECIP': 'sum',  # Count consecutive heavy precip days
        'PRCP': 'sum'
    }).reset_index()
    monthly_precip['YearMonth'] = pd.to_datetime(monthly_precip['Year'].astype(str) + '-' +
                                               monthly_precip['Month'].astype(str) + '-01')

    ax2 = ax.twinx()
    ax.bar(monthly_precip['YearMonth'], monthly_precip['PRCP'],
          color='lightblue', alpha=0.4, label='Total Precipitation')

    # Plot both heavy

"""***4. Ridership Data Preprocessing and Aggregation***"""

# 4.1 Ridership Data Preprocessing
print("Processing ridership data...")

# Map month names to numbers for consistent joining
month_mapping = {
    'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
    'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12
}
ridership_data['Month_Num'] = ridership_data['Month'].map(month_mapping)

# Add season information
ridership_data['Season'] = pd.cut(
    ridership_data['Month_Num'],
    bins=[0, 3, 6, 9, 12],
    labels=['Winter', 'Spring', 'Summer', 'Fall'],
    ordered=True
)

# 4.2 Aggregate ridership data by year, month, and mode
monthly_ridership = ridership_data.groupby(['Year', 'Month_Num', 'Month', 'Mode']).agg(
    Total_Ridership=('Ridership', 'sum'),
    Route_Count=('Route', 'nunique')  # Changed to nunique for better accuracy
).reset_index()

print(f"\nRidership data aggregated to {len(monthly_ridership)} month-mode combinations")

# 4.3 Weather data monthly aggregation
monthly_weather = weather_with_extremes.groupby(['Year', 'Month']).agg(
    Very_Hot_Days=('VERY_HOT', 'sum'),
    Very_Cold_Days=('VERY_COLD', 'sum'),
    Heavy_Precip_Days=('HEAVY_PRECIP', 'sum'),
    Heat_Wave_Days=('HEATWAVE', 'sum'),
    Cold_Wave_Days=('COLDWAVE', 'sum'),
    Avg_TMAX=('TMAX', 'mean'),
    Avg_TMIN=('TMIN', 'mean'),
    Total_PRCP=('PRCP', 'sum'),
    Days_With_Rain=('PRCP', lambda x: (x > 0).sum())
).reset_index()

print(f"Weather data aggregated to {len(monthly_weather)} months")

# 4.4 Merge ridership and weather data
merged_data = pd.merge(
    monthly_ridership,
    monthly_weather,
    left_on=['Year', 'Month_Num'],
    right_on=['Year', 'Month'],
    how='inner'
)

# Create date column for time series analysis
merged_data['Date'] = pd.to_datetime(merged_data['Year'].astype(str) + '-' +
                                    merged_data['Month_Num'].astype(str) + '-01')

print(f"Final merged dataset: {merged_data.shape[0]} observations with {merged_data.shape[1]} variables")
print(f"Date range: {merged_data['Date'].min().strftime('%B %Y')} to {merged_data['Date'].max().strftime('%B %Y')}")
print(f"Transportation modes: {', '.join(merged_data['Mode'].unique())}")

# 5.4 Year by Year Ridership Analysis (2019-2024)
plt.figure(figsize=(20, 15))

# Extract year from date
merged_data['Year'] = merged_data['Date'].dt.year

# Create subplots for each year
fig, axes = plt.subplots(2, 3, figsize=(20, 12), sharex=False, sharey=True)
fig.suptitle('Transit Ridership Year by Year (2019-2024)', fontsize=22)

# Flatten the axes array for easier iteration
axes = axes.flatten()

# Get unique years from 2019-2024
years = sorted([year for year in range(2019, 2025) if year in merged_data['Year'].unique()])

# Color mapping for consistent colors across subplots
modes = merged_data['Mode'].unique()
colors = plt.cm.tab10(np.linspace(0, 1, len(modes)))
mode_color_map = dict(zip(modes, colors))

# Plot each year
for i, year in enumerate(years):
    ax = axes[i]
    year_data = merged_data[merged_data['Year'] == year]

    # Plot each mode for this year
    for mode in modes:
        mode_year_data = year_data[year_data['Mode'] == mode]
        if not mode_year_data.empty:
            # Sort by month for proper line plotting
            mode_year_data = mode_year_data.sort_values('Date')
            ax.plot(mode_year_data['Date'], mode_year_data['Total_Ridership'],
                   marker='o', markersize=5, linewidth=2, alpha=0.8,
                   label=mode, color=mode_color_map[mode])

    ax.set_title(f"Transit Ridership in {year}", fontsize=16)
    ax.set_ylabel('Monthly Ridership', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.7)

    # Format x-axis to show only months
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))
    ax.tick_params(axis='x', rotation=45)

    # Add year-specific legend only if this is the first subplot
    if i == 0:
        ax.legend(title='Transit Mode', title_fontsize=12, frameon=True, fontsize=10, loc='upper right')

# Remove empty subplots if there are fewer than 6 years
if len(years) < 6:
    for j in range(len(years), 6):
        fig.delaxes(axes[j])

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.savefig('figure7_yearly_ridership_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

# Year-by-Year Transit Ridership and Weather Conditions Visualization with a single legend
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib.lines import Line2D

# Calculate the years present in the data (from 2019 to present)
years = sorted(merged_data['Date'].dt.year.unique())
num_years = len(years)

# Create a subplot layout with one row per year
fig, axes = plt.subplots(num_years, 1, figsize=(16, 5*num_years), sharex=False)
fig.suptitle('Transit Ridership and Weather Conditions Year-by-Year (2019-Present)',
             fontsize=24, y=0.995)

# Color mapping for different transit modes
mode_colors = {
    mode: plt.cm.tab10(i) for i, mode in enumerate(merged_data['Mode'].unique())
}

# Keep track of all lines for the single legend
all_lines = []
all_labels = []
weather_symbols_added = False

for i, year in enumerate(years):
    ax = axes[i] if num_years > 1 else axes

    # Filter data for current year
    year_data = merged_data[merged_data['Date'].dt.year == year]

    # Primary y-axis for ridership
    ax.set_title(f"{year} Transit Ridership and Weather Conditions", fontsize=18)

    # Plot each transit mode with different colors
    for mode in year_data['Mode'].unique():
        mode_year_data = year_data[year_data['Mode'] == mode].sort_values('Date')
        line = ax.plot(mode_year_data['Date'], mode_year_data['Total_Ridership'],
                color=mode_colors[mode], marker='o', markersize=4, linewidth=2)

        # Only add to legend items once
        if i == 0:
            all_lines.append(line[0])
            all_labels.append(f'{mode} Ridership')

    ax.set_ylabel('Monthly Ridership', fontsize=14)
    ax.grid(True, linestyle='--', alpha=0.4)

    # Secondary y-axis for temperature
    ax2 = ax.twinx()

    # Calculate average temperature across all modes for each month
    monthly_temp = year_data.groupby('Date')['Avg_TMAX'].mean().reset_index()
    temp_line = ax2.plot(monthly_temp['Date'], monthly_temp['Avg_TMAX'],
             color='crimson', linestyle='--', linewidth=2.5)

    # Only add temperature line to legend once
    if i == 0:
        all_lines.append(temp_line[0])
        all_labels.append('Avg Max Temp')

    ax2.set_ylabel('Avg Max Temperature (°F)', fontsize=12, color='crimson')
    ax2.tick_params(axis='y', labelcolor='crimson')

    # Highlight extreme weather months
    hot_months = year_data[year_data['Very_Hot_Days'] > 5]['Date'].unique()
    cold_months = year_data[year_data['Very_Cold_Days'] > 5]['Date'].unique()
    precip_months = year_data[year_data['Heavy_Precip_Days'] > 2]['Date'].unique()

    # Add markers for extreme months at the top of the chart
    y_pos = ax.get_ylim()[1] * 0.95  # Position near the top

    for date in hot_months:
        ax.annotate('🔥', xy=(date, y_pos), xytext=(0, 0),
                   textcoords="offset points", ha='center', fontsize=16)

    for date in cold_months:
        ax.annotate('❄️', xy=(date, y_pos), xytext=(0, 5),
                   textcoords="offset points", ha='center', fontsize=16)

    for date in precip_months:
        ax.annotate('☔', xy=(date, y_pos), xytext=(0, 10),
                   textcoords="offset points", ha='center', fontsize=16)

    # Format x-axis to show months
    ax.xaxis.set_major_locator(mdates.MonthLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))
    ax.set_xlabel('Month', fontsize=14)

    # Add weather event symbols to legend once
    if (not weather_symbols_added and
        (len(hot_months) > 0 or len(cold_months) > 0 or len(precip_months) > 0)):

        if len(hot_months) > 0:
            all_lines.append(Line2D([0], [0], marker='o', color='white',
                            markerfacecolor='red', markersize=10))
            all_labels.append('Hot Month (>5 hot days)')

        if len(cold_months) > 0:
            all_lines.append(Line2D([0], [0], marker='o', color='white',
                            markerfacecolor='blue', markersize=10))
            all_labels.append('Cold Month (>5 cold days)')

        if len(precip_months) > 0:
            all_lines.append(Line2D([0], [0], marker='^', color='white',
                            markerfacecolor='green', markersize=10))
            all_labels.append('Wet Month (>2 heavy precip days)')

        weather_symbols_added = True

# Add a single legend at the bottom of the figure
fig.legend(all_lines, all_labels,
           loc='lower center', ncol=min(len(all_lines), 5),
           bbox_to_anchor=(0.5, 0.01), fontsize=12)

plt.tight_layout(rect=[0, 0.06, 1, 0.97])  # Adjust bottom to make room for legend
plt.savefig('figure_ridership_weather_by_year.png', dpi=300, bbox_inches='tight')
plt.show()

"""***5. Transit Ridership Analysis and Visualization***"""

# 5.1 Overall Transit Ridership Trends
plt.figure(figsize=(16, 10))

# Plot ridership trends by mode
for mode in merged_data['Mode'].unique():
    mode_data = merged_data[merged_data['Mode'] == mode]
    plt.plot(mode_data['Date'], mode_data['Total_Ridership'],
             marker='o', markersize=5, linewidth=2, alpha=0.8, label=mode)

plt.title('Monthly Public Transit Ridership by Mode in Philadelphia (2019-Present)', fontsize=18)
plt.xlabel('Date', fontsize=14)
plt.ylabel('Total Monthly Ridership', fontsize=14)
plt.legend(title='Transit Mode', title_fontsize=14, frameon=True, fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('figure4_ridership_trends.png', dpi=300, bbox_inches='tight')
plt.show()

# 5.2 Create a multi-panel visualization of ridership by mode with weather overlay
fig, axes = plt.subplots(3, 2, figsize=(18, 20), sharex=True)
fig.suptitle('Transit Ridership and Weather Conditions (2019-Present)', fontsize=22, y=0.995)
axes = axes.flatten()

modes = merged_data['Mode'].unique()[:6]  # Take up to 6 modes to fit in the panels
colors = ['navy', 'darkgreen', 'darkred', 'darkorange', 'purple', 'brown']

for i, mode in enumerate(modes):
    ax = axes[i]
    mode_data = merged_data[merged_data['Mode'] == mode].sort_values('Date')

    # Primary y-axis for ridership
    ax.set_title(f"{mode} Ridership", fontsize=16)
    line1 = ax.plot(mode_data['Date'], mode_data['Total_Ridership'],
                    color=colors[i], marker='o', markersize=4, linewidth=2.5,
                    label='Ridership')
    ax.set_ylabel('Monthly Ridership', fontsize=14, color=colors[i])
    ax.tick_params(axis='y', labelcolor=colors[i])
    ax.grid(True, linestyle='--', alpha=0.4)

    # Secondary y-axis for temperature
    ax2 = ax.twinx()
    line2 = ax2.plot(mode_data['Date'], mode_data['Avg_TMAX'],
                     color='crimson', linestyle='--', linewidth=1.5, label='Avg Max Temp')
    ax2.set_ylabel('Avg Max Temperature (°F)', fontsize=12, color='crimson')
    ax2.tick_params(axis='y', labelcolor='crimson')

    # Highlight extreme weather months
    hot_months = mode_data[mode_data['Very_Hot_Days'] > 5]
    cold_months = mode_data[mode_data['Very_Cold_Days'] > 5]
    precip_months = mode_data[mode_data['Heavy_Precip_Days'] > 2]

    # Add markers for extreme weather months
    if len(hot_months) > 0:
        ax.scatter(hot_months['Date'], hot_months['Total_Ridership'],
                   s=120, color='red', marker='*', label='Hot Month (>5 hot days)')
    if len(cold_months) > 0:
        ax.scatter(cold_months['Date'], cold_months['Total_Ridership'],
                   s=120, color='blue', marker='*', label='Cold Month (>5 cold days)')
    if len(precip_months) > 0:
        ax.scatter(precip_months['Date'], precip_months['Total_Ridership'],
                   s=120, color='green', marker='^', label='Wet Month (>2 heavy precip days)')

    # Add combined legend
    lines1, labels1 = ax.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=10)

    # Format x-axis dates
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    ax.tick_params(axis='x', rotation=45)

plt.tight_layout(rect=[0, 0, 1, 0.97])
plt.savefig('figure5_ridership_weather_overlay.png', dpi=300, bbox_inches='tight')
plt.show()

# 5.3 Seasonal Analysis
seasonal_data = merged_data.copy()
seasonal_data['Season'] = pd.cut(
    seasonal_data['Month_Num'],
    bins=[0, 3, 6, 9, 12],
    labels=['Winter', 'Spring', 'Summer', 'Fall'],
    ordered=True
)

# Plot seasonal ridership patterns
plt.figure(figsize=(16, 10))
sns.boxplot(x='Season', y='Total_Ridership', hue='Mode', data=seasonal_data,
            palette='Set2', fliersize=3)
plt.title('Seasonal Variation in Transit Ridership by Mode', fontsize=18)
plt.xlabel('Season', fontsize=14)
plt.ylabel('Total Monthly Ridership', fontsize=14)
plt.legend(title='Transit Mode', title_fontsize=14, frameon=True, fontsize=12)
plt.grid(True, linestyle='--', alpha=0.3)
plt.tight_layout()
plt.savefig('figure6_seasonal_ridership.png', dpi=300, bbox_inches='tight')
plt.show()





"""***6. Statistical Analysis of Weather Impact on Ridership***"""

# 6.1 Correlation Analysis
# Create pivot tables for correlation analysis
bus_data = merged_data[merged_data['Mode'] == 'Bus'].copy()

# Calculate correlation matrix for bus data
corr_matrix = bus_data[['Total_Ridership', 'Very_Hot_Days', 'Very_Cold_Days',
                        'Heavy_Precip_Days', 'Avg_TMAX', 'Avg_TMIN', 'Total_PRCP']].corr()

# Plot the correlation heatmap
plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
cmap = sns.diverging_palette(230, 20, as_cmap=True)

sns.heatmap(corr_matrix, mask=mask, cmap=cmap, annot=True, fmt='.2f',
            square=True, linewidths=.5, center=0, vmin=-1, vmax=1)
plt.title('Correlation Between Weather Variables and Bus Ridership', fontsize=18)
plt.tight_layout()
plt.savefig('figure7_correlation_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

# 6.2 Year-by-Year Correlation Analysis - ADJUSTED VERSION
years = merged_data['Year'].unique()
print(f"Analyzing correlations for years: {sorted(years)}")

# Create a figure with subplots for each year
fig, axes = plt.subplots(len(years), 1, figsize=(14, 3*len(years)))
fig.suptitle('Yearly Correlation Between Weather and Ridership', fontsize=20, y=0.99)

# Handle single year case
if len(years) == 1:
    axes = np.array([axes])

# Define a narrower color range to better show the small correlations
vmin, vmax = -0.25, 0.25

for i, year in enumerate(sorted(years)):
    year_data = merged_data[merged_data['Year'] == year]

    # Calculate correlations for the year
    year_corr = year_data[['Total_Ridership', 'Very_Hot_Days', 'Very_Cold_Days',
                         'Heavy_Precip_Days', 'Avg_TMAX', 'Avg_TMIN']].corr()

    # Create a more readable dataframe for the heatmap
    corr_values = year_corr.loc[['Very_Hot_Days', 'Very_Cold_Days', 'Heavy_Precip_Days',
                              'Avg_TMAX', 'Avg_TMIN'], 'Total_Ridership']

    # Reshape for horizontal display
    heatmap_data = pd.DataFrame(corr_values).T

    # Create heatmap for this year
    sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdBu_r',
              center=0, ax=axes[i], vmin=vmin, vmax=vmax, cbar=False)

    axes[i].set_title(f'Year {year}', fontsize=16)
    axes[i].set_ylabel('Ridership\nCorrelation', fontsize=12)

    # Make the y-axis label more readable
    axes[i].set_yticklabels([''], rotation=0)

# Add a shared colorbar for the entire figure
# Position it to the right without overlapping the plots
cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [left, bottom, width, height]
sm = plt.cm.ScalarMappable(cmap='RdBu_r', norm=plt.Normalize(vmin=vmin, vmax=vmax))
sm.set_array([])
cbar = fig.colorbar(sm, cax=cbar_ax)
cbar.set_label('Correlation with Ridership', fontsize=14)

# Add a more descriptive x-axis label at the bottom
fig.text(0.5, 0.04, 'Weather Variables', ha='center', fontsize=16)

plt.tight_layout(rect=[0, 0.05, 0.9, 0.95])  # Adjust layout to accommodate the colorbar and labels
plt.savefig('figure8_yearly_correlation.png', dpi=300, bbox_inches='tight')
plt.show()

# 7.1 Create a heatmap of ridership by weather conditions
# Focus on bus data as the largest mode
bus_data = merged_data[merged_data['Mode'] == 'Bus'].copy()

# Create binned temperature and precipitation columns
bus_data['Temp_Bin'] = pd.cut(bus_data['Avg_TMAX'],
                               bins=[0, 40, 50, 60, 70, 80, 90, 100],
                               labels=['<40°F', '40-50°F', '50-60°F', '60-70°F',
                                       '70-80°F', '80-90°F', '>90°F'])
bus_data['Precip_Bin'] = pd.cut(bus_data['Total_PRCP'],
                                bins=[0, 1, 2, 4, 8, 100],
                                labels=['0-1"', '1-2"', '2-4"', '4-8"', '>8"'])

# Create pivot table of average ridership by temperature and precipitation bins
ridership_by_weather = bus_data.pivot_table(
    values='Total_Ridership',
    index='Temp_Bin',
    columns='Precip_Bin',
    aggfunc='mean'
)

# Plot heatmap
plt.figure(figsize=(14, 10))
sns.heatmap(ridership_by_weather, cmap='YlGnBu', annot=True, fmt='.0f', linewidths=.5)
plt.title('Bus Ridership by Temperature and Precipitation Conditions', fontsize=18)
plt.xlabel('Monthly Precipitation', fontsize=14)
plt.ylabel('Average Maximum Temperature', fontsize=14)
plt.tight_layout()
plt.savefig('figure10_ridership_weather_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

# 7.2 Ridership by extreme weather count
# Create bins for number of extreme days in a month
bus_data['Hot_Days_Cat'] = pd.cut(bus_data['Very_Hot_Days'],
                                  bins=[-1, 0, 3, 6, 31],
                                  labels=['None', '1-3', '4-6', '>6'])
bus_data['Cold_Days_Cat'] = pd.cut(bus_data['Very_Cold_Days'],
                                   bins=[-1, 0, 3, 6, 31],
                                   labels=['None', '1-3', '4-6', '>6'])
bus_data['Heavy_Rain_Cat'] = pd.cut(bus_data['Heavy_Precip_Days'],
                                    bins=[-1, 0, 1, 2, 31],
                                    labels=['None', '1', '2', '>2'])

# Create a combined plot showing ridership by extreme weather categories
fig, axes = plt.subplots(1, 3, figsize=(18, 6))
fig.suptitle('Impact of Extreme Weather Events on Bus Ridership', fontsize=18)

# Hot days impact
sns.boxplot(x='Hot_Days_Cat', y='Total_Ridership', data=bus_data, ax=axes[0],
            palette='YlOrRd')
axes[0].set_title('Effect of Very Hot Days', fontsize=16)
axes[0].set_xlabel('Number of Very Hot Days in Month', fontsize=14)
axes[0].set_ylabel('Monthly Bus Ridership', fontsize=14)
axes[0].grid(True, linestyle='--', alpha=0.7)

# Cold days impact
sns.boxplot(x='Cold_Days_Cat', y='Total_Ridership', data=bus_data, ax=axes[1],
            palette='Blues')
axes[1].set_title('Effect of Very Cold Days', fontsize=16)
axes[1].set_xlabel('Number of Very Cold Days in Month', fontsize=14)
axes[1].set_ylabel('Monthly Bus Ridership', fontsize=14)
axes[1].grid(True, linestyle='--', alpha=0.7)

# Heavy rain impact
sns.boxplot(x='Heavy_Rain_Cat', y='Total_Ridership', data=bus_data, ax=axes[2],
            palette='Greens')
axes[2].set_title('Effect of Heavy Precipitation Days', fontsize=16)
axes[2].set_xlabel('Number of Heavy Precipitation Days in Month', fontsize=14)
axes[2].set_ylabel('Monthly Bus Ridership', fontsize=14)
axes[2].grid(True, linestyle='--', alpha=0.7)

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.savefig('figure11_extreme_weather_impact.png', dpi=300, bbox_inches='tight')
plt.show()

# 8.1 Create heatmaps showing year-month patterns

# Function to create year-month heatmap for a specific mode
def create_year_month_heatmap(data, mode_name, value_col, cmap, title):
    mode_data = data[data['Mode'] == mode_name].copy()

    # Create pivot table by year and month
    pivot = mode_data.pivot_table(
        index='Year',
        columns='Month_Num',
        values=value_col,
        aggfunc='mean'
    )

    # Plot heatmap
    plt.figure(figsize=(14, 8))
    sns.heatmap(pivot, annot=True, fmt='.1f' if 'TMAX' in value_col else '.0f',
                cmap=cmap, linewidths=.5)

    # Replace month numbers with month names
    month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    plt.xticks(np.arange(12)+0.5, month_labels)

    plt.title(title, fontsize=18)
    plt.xlabel('Month', fontsize=14)
    plt.ylabel('Year', fontsize=14)
    plt.tight_layout()
    return plt.gcf()

# Create ridership heatmaps for Bus and Heavy Rail
bus_heatmap = create_year_month_heatmap(
    merged_data, 'Bus', 'Total_Ridership', 'YlGnBu',
    'Bus Ridership by Year and Month'
)
bus_heatmap.savefig('figure12a_bus_ridership_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

try:
    rail_heatmap = create_year_month_heatmap(
        merged_data, 'Heavy Rail', 'Total_Ridership', 'YlOrRd',
        'Heavy Rail Ridership by Year and Month'
    )
    rail_heatmap.savefig('figure12b_rail_ridership_heatmap.png', dpi=300, bbox_inches='tight')
    plt.show()
except:
    print("Unable to create Heavy Rail heatmap - mode may not exist in dataset")

# Create temperature heatmap
temp_heatmap = create_year_month_heatmap(
    merged_data, 'Bus', 'Avg_TMAX', 'RdYlBu_r',
    'Average Maximum Temperature (°F) by Year and Month'
)
temp_heatmap.savefig('figure12c_temperature_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

# Create hot-cold days comparison heatmap
# Calculate hot days minus cold days to show net effect
net_temp_data = merged_data[merged_data['Mode'] == 'Bus'].copy()
net_temp_data['Hot_Minus_Cold'] = net_temp_data['Very_Hot_Days'] - net_temp_data['Very_Cold_Days']

heat_cold_heatmap = create_year_month_heatmap(
    net_temp_data, 'Bus', 'Hot_Minus_Cold', 'RdBu',
    'Hot Days Minus Cold Days by Year and Month (positive = less hot days)'
)
heat_cold_heatmap.savefig('figure12d_hot_cold_balance_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

# 9.1 Create a comprehensive summary visualization

# First, add the Season column to merged_data if it doesn't exist
if 'Season' not in merged_data.columns:
    merged_data['Season'] = pd.cut(
        merged_data['Month_Num'],
        bins=[0, 3, 6, 9, 12],
        labels=['Winter', 'Spring', 'Summer', 'Fall'],
        ordered=True
    )

# Create a figure showing the relationship between key weather metrics and ridership
fig, axes = plt.subplots(2, 2, figsize=(18, 16))
fig.suptitle('Weather Impact on Transit Ridership: Multiyear Analysis', fontsize=20, y=0.98)

# 1. Temperature vs Ridership by Mode
ax = axes[0, 0]
for mode in merged_data['Mode'].unique():
    mode_data = merged_data[merged_data['Mode'] == mode]
    ax.scatter(mode_data['Avg_TMAX'], mode_data['Total_Ridership'],
               alpha=0.7, label=mode, s=50)

    # Add trendline for each mode
    z = np.polyfit(mode_data['Avg_TMAX'], mode_data['Total_Ridership'], 1)
    p = np.poly1d(z)
    ax.plot(sorted(mode_data['Avg_TMAX']), p(sorted(mode_data['Avg_TMAX'])),
            linestyle='--', alpha=0.8)

ax.set_title('Temperature Impact on Ridership by Mode', fontsize=16)
ax.set_xlabel('Average Maximum Temperature (°F)', fontsize=14)
ax.set_ylabel('Monthly Ridership', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(title='Transit Mode', title_fontsize=14, fontsize=12)

# 2. Extreme Weather Days vs Ridership (All Modes Combined)
ax = axes[0, 1]
mode_colors = {'Bus': 'blue', 'Heavy Rail': 'red', 'Trolley': 'green',
               'Trackless Trolley': 'purple', 'RRD': 'orange', 'CCT': 'brown'}

for mode in merged_data['Mode'].unique():
    if mode in mode_colors:
        mode_data = merged_data[merged_data['Mode'] == mode]

        # Calculate total extreme days
        mode_data['Total_Extreme_Days'] = (mode_data['Very_Hot_Days'] +
                                          mode_data['Very_Cold_Days'] +
                                          mode_data['Heavy_Precip_Days'])

        # Plot
        ax.scatter(mode_data['Total_Extreme_Days'], mode_data['Total_Ridership'],
                   alpha=0.7, label=mode, color=mode_colors.get(mode, 'gray'), s=50)

        # Add trendline
        if len(mode_data) > 5:  # Only add trendline if we have enough data points
            z = np.polyfit(mode_data['Total_Extreme_Days'], mode_data['Total_Ridership'], 1)
            p = np.poly1d(z)
            ax.plot(sorted(mode_data['Total_Extreme_Days']),
                    p(sorted(mode_data['Total_Extreme_Days'])),
                    linestyle='--', color=mode_colors.get(mode, 'gray'), alpha=0.8)

ax.set_title('Impact of Combined Extreme Weather Days on Ridership', fontsize=16)
ax.set_xlabel('Total Extreme Weather Days in Month\n(Hot + Cold + Heavy Precip)', fontsize=14)
ax.set_ylabel('Monthly Ridership', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(title='Transit Mode', title_fontsize=14, fontsize=12)

# 3. Seasonal Ridership Patterns
ax = axes[1, 0]

# Calculate seasonal averages
seasonal_avg = merged_data.groupby(['Mode', 'Season'])['Total_Ridership'].mean().reset_index()
seasonal_avg['Season'] = pd.Categorical(
    seasonal_avg['Season'],
    categories=['Winter', 'Spring', 'Summer', 'Fall'],
    ordered=True
)
seasonal_avg = seasonal_avg.sort_values(['Mode', 'Season'])

# Create the seasonal plot
sns.barplot(x='Season', y='Total_Ridership', hue='Mode', data=seasonal_avg, ax=ax)

ax.set_title('Seasonal Ridership Patterns by Mode', fontsize=16)
ax.set_xlabel('Season', fontsize=14)
ax.set_ylabel('Average Monthly Ridership', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(title='Transit Mode', title_fontsize=14, fontsize=12)

# 4. Summary correlation heatmap
ax = axes[1, 1]

# Create a correlation table for all modes
corr_rows = []
for mode in merged_data['Mode'].unique():
    mode_data = merged_data[merged_data['Mode'] == mode]

    for var in ['Very_Hot_Days', 'Very_Cold_Days', 'Heavy_Precip_Days', 'Avg_TMAX', 'Total_PRCP']:
        corr = mode_data[['Total_Ridership', var]].corr().iloc[0, 1]
        corr_rows.append({'Mode': mode, 'Weather_Var': var, 'Correlation': corr})

corr_df = pd.DataFrame(corr_rows)
corr_pivot = corr_df.pivot(index='Mode', columns='Weather_Var', values='Correlation')

# Plot the correlation heatmap
sns.heatmap(corr_pivot, cmap='RdBu_r', center=0, annot=True, fmt='.2f',
            linewidths=.5, ax=ax, vmin=-1, vmax=1)

ax.set_title('Weather-Ridership Correlation by Mode', fontsize=16)
ax.set_ylabel('Transit Mode', fontsize=14)
ax.set_xlabel('Weather Variable', fontsize=14)

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.savefig('figure13_comprehensive_weather_ridership_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# Print key findings
print("\n" + "="*80)
print("SUMMARY OF KEY FINDINGS".center(80))
print("="*80)

# 1. Overall correlation between weather and ridership
print("\n1. Weather-Ridership Correlations:")
for mode in merged_data['Mode'].unique():
    mode_data = merged_data[merged_data['Mode'] == mode]
    corr = mode_data[['Total_Ridership', 'Avg_TMAX']].corr().iloc[0, 1]
    print(f"   - {mode}: Correlation with temperature = {corr:.3f}")

# 2. Seasonal patterns
print("\n2. Seasonal Patterns:")
seasonal_summary = merged_data.groupby(['Season', 'Mode'])['Total_Ridership'].mean().reset_index()
for mode in merged_data['Mode'].unique():
    mode_seasons = seasonal_summary[seasonal_summary['Mode'] == mode]
    highest_season = mode_seasons.loc[mode_seasons['Total_Ridership'].idxmax()]
    lowest_season = mode_seasons.loc[mode_seasons['Total_Ridership'].idxmin()]
    print(f"   - {mode}: Highest in {highest_season['Season']} ({highest_season['Total_Ridership']:.0f}), " +
          f"Lowest in {lowest_season['Season']} ({lowest_season['Total_Ridership']:.0f})")

# 3. Extreme weather impact
print("\n3. Extreme Weather Impact:")
for mode in merged_data['Mode'].unique():
    mode_data = merged_data[merged_data['Mode'] == mode]

    # Calculate average ridership on months with different weather conditions
    normal_months = mode_data[(mode_data['Very_Hot_Days'] <= 3) &
                             (mode_data['Very_Cold_Days'] <= 3) &
                             (mode_data['Heavy_Precip_Days'] <= 1)]

    hot_months = mode_data[mode_data['Very_Hot_Days'] > 3]
    cold_months = mode_data[mode_data['Very_Cold_Days'] > 3]
    wet_months = mode_data[mode_data['Heavy_Precip_Days'] > 1]

    normal_avg = normal_months['Total_Ridership'].mean() if len(normal_months) > 0 else 0
    hot_avg = hot_months['Total_Ridership'].mean() if len(hot_months) > 0 else 0
    cold_avg = cold_months['Total_Ridership'].mean() if len(cold_months) > 0 else 0
    wet_avg = wet_months['Total_Ridership'].mean() if len(wet_months) > 0 else 0

    hot_pct = ((hot_avg / normal_avg) - 1) * 100 if normal_avg > 0 and hot_avg > 0 else 0
    cold_pct = ((cold_avg / normal_avg) - 1) * 100 if normal_avg > 0 and cold_avg > 0 else 0
    wet_pct = ((wet_avg / normal_avg) - 1) * 100 if normal_avg > 0 and wet_avg > 0 else 0

    print(f"   - {mode}: Hot months ({hot_pct:.1f}%), Cold months ({cold_pct:.1f}%), " +
          f"Wet months ({wet_pct:.1f}%)")

print("\n" + "="*80)
print("IMPLICATIONS AND RECOMMENDATIONS".center(80))
print("="*80)

print("""
1. Transit Planning:
   - Adjust service frequency based on seasonal and weather-related ridership patterns
   - Consider weather forecasts in short-term planning and resource allocation

2. Infrastructure Development:
   - Improve weather protection at stops and stations in areas with high weather sensitivity
   - Design climate-resilient transit facilities for extreme weather conditions

3. Further Research:
   - Investigate interaction effects between weather and other factors (e.g. COVID-19, events)
   - Develop predictive models incorporating weather forecasts for ridership prediction

4. Climate Change Adaptation:
   - Plan for potential shifts in ridership patterns as climate change alters weather patterns
   - Develop strategies to maintain service reliability during increasing extreme weather events
""")

print("\n" + "="*80)

# 4.1 Prepare data for temporal analysis
print("Preparing data for temporal analysis...")

# Convert date columns to datetime
ridership_data['Year_Month'] = pd.to_datetime(ridership_data['Year'].astype(str) + '-' +
                                           ridership_data['Month'].astype(str), format='%Y-%B')

# Extract day of week information from weather data
weather_with_extremes['DayOfWeek'] = weather_with_extremes['DATE'].dt.dayofweek
weather_with_extremes['IsWeekend'] = weather_with_extremes['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)

# Aggregate ridership by year, month and transportation mode
monthly_ridership = ridership_data.groupby(['Year', 'Month', 'Mode'])['Ridership'].sum().reset_index()
monthly_ridership['Year_Month'] = pd.to_datetime(monthly_ridership['Year'].astype(str) + '-' +
                                              monthly_ridership['Month'].astype(str), format='%Y-%B')

# Assign seasons
month_to_season = {
    'January': 'Winter', 'February': 'Winter', 'December': 'Winter',
    'March': 'Spring', 'April': 'Spring', 'May': 'Spring',
    'June': 'Summer', 'July': 'Summer', 'August': 'Summer',
    'September': 'Fall', 'October': 'Fall', 'November': 'Fall'
}
ridership_data['Season'] = ridership_data['Month'].map(month_to_season)

# 4.2 Weekday vs Weekend Analysis
# Merge weather and ridership data to analyze weekend vs weekday patterns
# Note: Since the ridership data is already filtered for weekdays, we'll need to
# simulate weekend data based on typical weekend ridership patterns from literature
# (typically 60-75% of weekday ridership)

# 4.3 Seasonal Ridership Visualization
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('Seasonal Public Transit Ridership Patterns (2019-Present)', fontsize=20, y=0.98)

# Plot 1: Seasonal ridership by transportation mode
seasonal_ridership = ridership_data.groupby(['Season', 'Mode'])['Ridership'].sum().reset_index()
seasonal_order = ['Winter', 'Spring', 'Summer', 'Fall']
ax = axes[0, 0]
sns.barplot(x='Season', y='Ridership', hue='Mode', data=seasonal_ridership,
            order=seasonal_order, palette='viridis', ax=ax)
ax.set_title('Total Ridership by Season and Mode', fontsize=16)
ax.set_ylabel('Total Ridership (millions)', fontsize=14)
ax.set_xlabel('Season', fontsize=14)
y_formatter = mpl.ticker.FuncFormatter(lambda x, p: f'{x/1e6:.1f}')
ax.yaxis.set_major_formatter(y_formatter)
ax.grid(axis='y', linestyle='--', alpha=0.7)
ax.legend(title='Transit Mode', frameon=True, fontsize=12)

# Plot 2: Monthly ridership trends by year
ax = axes[0, 1]
yearly_monthly_ridership = ridership_data.groupby(['Year', 'Month'])['Ridership'].sum().reset_index()
yearly_monthly_ridership['MonthNum'] = yearly_monthly_ridership['Month'].map({
    'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,
    'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12
})
yearly_monthly_ridership = yearly_monthly_ridership.sort_values(['Year', 'MonthNum'])

for year in yearly_monthly_ridership['Year'].unique():
    year_data = yearly_monthly_ridership[yearly_monthly_ridership['Year'] == year]
    ax.plot(year_data['MonthNum'], year_data['Ridership']/1e6, marker='o',
            linewidth=2, label=f'{year}', markersize=6)

ax.set_title('Monthly Ridership Trends by Year', fontsize=16)
ax.set_xlabel('Month', fontsize=14)
ax.set_ylabel('Total Ridership (millions)', fontsize=14)
ax.set_xticks(range(1, 13))
ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
ax.grid(True, linestyle='--', alpha=0.7)
ax.legend(title='Year', frameon=True, fontsize=12)

# Plot 3: Winter focus analysis - Combine weather and ridership
ax = axes[1, 0]
winter_data = ridership_data[ridership_data['Season'] == 'Winter'].copy()
winter_monthly = winter_data.groupby(['Year', 'Month'])['Ridership'].sum().reset_index()
winter_monthly['Year_Month'] = pd.to_datetime(winter_monthly['Year'].astype(str) + '-' +
                                           winter_monthly['Month'].astype(str), format='%Y-%B')

# Get winter temperature data
winter_weather = weather_with_extremes[weather_with_extremes['Month'].isin([12, 1, 2])].copy()
winter_weather['Year_Month'] = pd.to_datetime(winter_weather['Year'].astype(str) + '-' +
                                           winter_weather['Month'].astype(str) + '-01')
winter_temp_monthly = winter_weather.groupby('Year_Month')['TMAX'].mean().reset_index()

# Create dual-axis plot
color1, color2 = 'dodgerblue', 'firebrick'
ax.bar(winter_monthly['Year_Month'], winter_monthly['Ridership']/1e6,
       color=color1, alpha=0.7, label='Winter Ridership')
ax.set_ylabel('Total Ridership (millions)', fontsize=14, color=color1)
ax.tick_params(axis='y', labelcolor=color1)

ax2 = ax.twinx()
ax2.plot(winter_temp_monthly['Year_Month'], winter_temp_monthly['TMAX'],
         color=color2, linewidth=2.5, marker='o', label='Avg Max Temp')
ax2.set_ylabel('Average Maximum Temperature (°F)', fontsize=14, color=color2)
ax2.tick_params(axis='y', labelcolor=color2)

ax.set_title('Winter Ridership vs Temperature', fontsize=16)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
ax.tick_params(axis='x', rotation=45)

# Add combined legend
lines1, labels1 = ax.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=12)
ax.grid(True, linestyle='--', alpha=0.7)

# Plot 4: Impact of extreme weather on ridership
ax = axes[1, 1]

# First, let's create monthly aggregates of extreme weather days
monthly_extremes = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum',
    'HEAVY_PRECIP': 'sum',
    'HEATWAVE': 'sum',
    'COLDWAVE': 'sum'
}).reset_index()

monthly_extremes['Year_Month'] = pd.to_datetime(monthly_extremes['Year'].astype(str) + '-' +
                                             monthly_extremes['Month'].astype(str) + '-01')

# Merge with ridership data
ridership_monthly = ridership_data.groupby(['Year', 'Month'])['Ridership'].sum().reset_index()
ridership_monthly['Year_Month'] = pd.to_datetime(ridership_monthly['Year'].astype(str) + '-' +
                                              ridership_monthly['Month'].astype(str), format='%Y-%B')

monthly_merged = pd.merge(monthly_extremes, ridership_monthly, on='Year_Month', how='inner')

# Calculate correlation
from scipy.stats import pearsonr
corr_hot, p_hot = pearsonr(monthly_merged['VERY_HOT'], monthly_merged['Ridership'])
corr_cold, p_cold = pearsonr(monthly_merged['VERY_COLD'], monthly_merged['Ridership'])
corr_precip, p_precip = pearsonr(monthly_merged['HEAVY_PRECIP'], monthly_merged['Ridership'])
corr_heatwave, p_heatwave = pearsonr(monthly_merged['HEATWAVE'], monthly_merged['Ridership'])
corr_coldwave, p_coldwave = pearsonr(monthly_merged['COLDWAVE'], monthly_merged['Ridership'])

# Create a bar chart showing correlation between extreme weather events and ridership
corr_data = {
    'Event Type': ['Very Hot Days', 'Very Cold Days', 'Heavy Precipitation', 'Heat Waves', 'Cold Waves'],
    'Correlation': [corr_hot, corr_cold, corr_precip, corr_heatwave, corr_coldwave],
    'p-value': [p_hot, p_cold, p_precip, p_heatwave, p_coldwave]
}
corr_df = pd.DataFrame(corr_data)

# Plot the correlation
bars = ax.bar(corr_df['Event Type'], corr_df['Correlation'],
       color=['crimson', 'dodgerblue', 'forestgreen', 'darkorange', 'midnightblue'])

# Add significance indicators
for i, bar in enumerate(bars):
    if corr_df['p-value'].iloc[i] < 0.01:
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.03,
               '**', ha='center', va='bottom', fontsize=14)
    elif corr_df['p-value'].iloc[i] < 0.05:
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.03,
               '*', ha='center', va='bottom', fontsize=14)

ax.axhline(y=0, color='black', linestyle='-', alpha=0.7)
ax.set_title('Correlation: Extreme Weather Events vs. Ridership', fontsize=16)
ax.set_ylabel('Pearson Correlation Coefficient', fontsize=14)
ax.set_ylim(-0.8, 0.8)
ax.text(0.05, -0.75, '*p<0.05, **p<0.01', fontsize=12)
ax.grid(axis='y', linestyle='--', alpha=0.7)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure4_temporal_seasonal_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# 4.4 Create cross-tabulation of weather conditions and ridership
# First, let's prepare daily aggregated ridership (this is an approximation as we have monthly data)
print("\nEstimating daily ridership patterns based on monthly data...")

# Approximate daily ridership by dividing monthly ridership by average number of weekdays per month
weekdays_per_month = {
    'January': 22, 'February': 20, 'March': 22, 'April': 21, 'May': 22,
    'June': 21, 'July': 21, 'August': 22, 'September': 21, 'October': 22,
    'November': 21, 'December': 20
}

ridership_data['Approx_Daily_Ridership'] = ridership_data.apply(
    lambda x: x['Ridership'] / weekdays_per_month.get(x['Month'], 21), axis=1)

# Extract year and month from weather data
weather_with_extremes['Year_Month'] = pd.to_datetime(
    weather_with_extremes['Year'].astype(str) + '-' +
    weather_with_extremes['Month'].astype(str) + '-01'
)

# Create weather condition categories
weather_with_extremes['Weather_Category'] = 'Normal'
weather_with_extremes.loc[weather_with_extremes['VERY_HOT'] == 1, 'Weather_Category'] = 'Very Hot'
weather_with_extremes.loc[weather_with_extremes['VERY_COLD'] == 1, 'Weather_Category'] = 'Very Cold'
weather_with_extremes.loc[weather_with_extremes['HEAVY_PRECIP'] == 1, 'Weather_Category'] = 'Heavy Precipitation'
weather_with_extremes.loc[(weather_with_extremes['VERY_HOT'] == 1) &
                        (weather_with_extremes['HEAVY_PRECIP'] == 1), 'Weather_Category'] = 'Hot & Rainy'
weather_with_extremes.loc[(weather_with_extremes['VERY_COLD'] == 1) &
                        (weather_with_extremes['HEAVY_PRECIP'] == 1), 'Weather_Category'] = 'Cold & Precipitation'
weather_with_extremes.loc[weather_with_extremes['HEATWAVE'] == 1, 'Weather_Category'] = 'Heat Wave'
weather_with_extremes.loc[weather_with_extremes['COLDWAVE'] == 1, 'Weather_Category'] = 'Cold Wave'

# Count days in each weather category by year and month
weather_counts = weather_with_extremes.groupby(['Year', 'Month', 'Weather_Category']).size().reset_index(name='Days')

# Reshape to get weather categories as columns
weather_pivot = weather_counts.pivot_table(
    index=['Year', 'Month'],
    columns='Weather_Category',
    values='Days',
    fill_value=0
).reset_index()

# Merge with monthly ridership data
ridership_monthly = ridership_data.groupby(['Year', 'Month'])['Ridership'].sum().reset_index()
ridership_monthly['Year_Month'] = pd.to_datetime(ridership_monthly['Year'].astype(str) + '-' +
                                               ridership_monthly['Month'].astype(str), format='%Y-%B')
weather_pivot['Year_Month'] = pd.to_datetime(weather_pivot['Year'].astype(str) + '-' +
                                           weather_pivot['Month'].astype(str).str.zfill(2), format='%Y-%m')

# Convert 'Month' column in weather_pivot to string before merging
weather_pivot['Month'] = weather_pivot['Month'].astype(str)

# Now perform the merge
weather_ridership = pd.merge(weather_pivot, ridership_monthly, on=['Year', 'Month'], how='inner')

# Calculate approximate daily ridership by weather category
for category in ['Normal', 'Very Hot', 'Very Cold', 'Heavy Precipitation',
                'Hot & Rainy', 'Cold & Precipitation', 'Heat Wave', 'Cold Wave']:
    if category in weather_ridership.columns:
        weather_days = weather_ridership[category]
        total_days = weather_days.sum()
        if total_days > 0:
            # This is a simplification assuming ridership is evenly distributed
            weather_ridership[f'{category}_Ridership'] = weather_ridership.apply(
                lambda x: (x['Ridership'] * x[category] / weekdays_per_month.get(x['Month'], 21))
                if x[category] > 0 else 0, axis=1)

# Create summary table for publication
weather_impact_summary = pd.DataFrame({
    'Weather Condition': ['Normal', 'Very Hot', 'Very Cold', 'Heavy Precipitation',
                       'Heat Wave', 'Cold Wave', 'Hot & Rainy', 'Cold & Precipitation'],
    'Total Days': [
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Normal'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Very Hot'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Very Cold'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Heavy Precipitation'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Heat Wave'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Cold Wave'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Hot & Rainy'].shape[0],
        weather_with_extremes[weather_with_extremes['Weather_Category'] == 'Cold & Precipitation'].shape[0]
    ]
})

# Display the summary table
print("\nSummary of Weather Condition Days (2019-Present):")
print(weather_impact_summary)

# Let's also export this as a formatted table for publication
plt.figure(figsize=(10, 6))
ax = plt.subplot(111, frame_on=False)
ax.xaxis.set_visible(False)
ax.yaxis.set_visible(False)

table = ax.table(cellText=weather_impact_summary.values,
               colLabels=weather_impact_summary.columns,
               cellLoc='center',
               loc='center',
               colWidths=[0.4, 0.2])

table.auto_set_font_size(False)
table.set_fontsize(12)
table.scale(1.2, 1.5)

plt.savefig('table1_weather_condition_summary.png', dpi=300, bbox_inches='tight')
plt.show()

# 5.1 Route Classification by Ridership Volume
print("\nClassifying routes by ridership volume...")

# Calculate average monthly ridership by route
route_avg_ridership = ridership_data.groupby('Route')['Ridership'].mean().reset_index()

# Determine ridership categories using quantiles
low_threshold = route_avg_ridership['Ridership'].quantile(0.33)
high_threshold = route_avg_ridership['Ridership'].quantile(0.67)

route_avg_ridership['Ridership_Category'] = pd.cut(
    route_avg_ridership['Ridership'],
    bins=[0, low_threshold, high_threshold, float('inf')],
    labels=['Low', 'Medium', 'High']
)

# Add category back to main data
ridership_data = pd.merge(ridership_data,
                        route_avg_ridership[['Route', 'Ridership_Category']],
                        on='Route')

# 5.2 Analyze routes by category
print("\nAnalyzing route performance by category...")

# Calculate year-over-year changes for routes
route_yearly = ridership_data.groupby(['Year', 'Route'])['Ridership'].sum().reset_index()
route_yearly_wide = route_yearly.pivot(index='Route', columns='Year', values='Ridership')

# Calculate percent change if we have multiple years of data
if route_yearly_wide.shape[1] > 1:
    years = sorted(ridership_data['Year'].unique())
    for i in range(1, len(years)):
        prev_year = years[i-1]
        curr_year = years[i]
        if prev_year in route_yearly_wide.columns and curr_year in route_yearly_wide.columns:
            route_yearly_wide[f'Pct_Change_{prev_year}_{curr_year}'] = \
                (route_yearly_wide[curr_year] - route_yearly_wide[prev_year]) / route_yearly_wide[prev_year] * 100

# 5.3 Create publication-quality visualizations for route analysis
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('Route-Level Ridership Analysis (2019-Present)', fontsize=20, y=0.98)

# Plot 1: Distribution of routes by ridership category
ax = axes[0, 0]
category_counts = ridership_data['Ridership_Category'].value_counts().sort_index()
category_palette = {'Low': 'lightblue', 'Medium': 'skyblue', 'High': 'steelblue'}
category_counts.plot(kind='bar', ax=ax, color=[category_palette[cat] for cat in category_counts.index])
ax.set_title('Distribution of Routes by Ridership Volume', fontsize=16)
ax.set_xlabel('Ridership Volume Category', fontsize=14)
ax.set_ylabel('Number of Routes', fontsize=14)
ax.grid(axis='y', linestyle='--', alpha=0.7)

for i, v in enumerate(category_counts):
    ax.text(i, v + 0.5, str(v), ha='center', fontsize=12)

# Plot 2: Average ridership by mode and category
ax = axes[0, 1]
mode_category_avg = ridership_data.groupby(['Mode', 'Ridership_Category'])['Ridership'].mean().reset_index()
sns.barplot(x='Mode', y='Ridership', hue='Ridership_Category', data=mode_category_avg,
          palette=category_palette, ax=ax)
ax.set_title('Average Ridership by Mode and Category', fontsize=16)
ax.set_xlabel('Transit Mode', fontsize=14)
ax.set_ylabel('Average Monthly Ridership', fontsize=14)
ax.grid(axis='y', linestyle='--', alpha=0.7)
ax.legend(title='Ridership Category', frameon=True, fontsize=12)

# Plot 3: Top 10 routes by ridership
ax = axes[1, 0]
top_routes = route_avg_ridership.nlargest(10, 'Ridership')
top_routes = top_routes.sort_values('Ridership')
bars = ax.barh(top_routes['Route'].astype(str), top_routes['Ridership'],
             color=[category_palette[cat] for cat in top_routes['Ridership_Category']])
ax.set_title('Top 10 Routes by Average Ridership', fontsize=16)
ax.set_xlabel('Average Monthly Ridership', fontsize=14)
ax.set_ylabel('Route', fontsize=14)

# Add category labels to the bars
for i, bar in enumerate(bars):
    category = top_routes['Ridership_Category'].iloc[i]
    ax.text(bar.get_width() + 100, bar.get_y() + bar.get_height()/2,
           f"{category}", va='center', fontsize=11)

ax.grid(axis='x', linestyle='--', alpha=0.7)

# Plot 4: Routes with largest year-over-year changes
ax = axes[1, 1]

# If we have YoY data, plot it
# ... previous code ...

# 5.3 Create publication-quality visualizations for route analysis
# ... (rest of the code)

# 5.4 Weather effect on different route categories
# ... (rest of the code)

if route_yearly_wide.shape[1] > 1:
    # Get the latest YoY change column
    pct_change_cols = [col for col in route_yearly_wide.columns if isinstance(col, str) and 'Pct_Change' in col]
    #                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # Check if the column is a string before looking for 'Pct_Change'

    if pct_change_cols:
        latest_pct_change = pct_change_cols[-1]
# ... (rest of the code)

        # Select routes with largest positive and negative changes
        top_increase = route_yearly_wide.nlargest(5, latest_pct_change)
        top_decrease = route_yearly_wide.nsmallest(5, latest_pct_change)
        top_change = pd.concat([top_increase, top_decrease])

        # Merge with route categories
        top_change = top_change.reset_index()
        top_change = pd.merge(top_change,
                            route_avg_ridership[['Route', 'Ridership_Category']],
                            on='Route')

        # Sort by percent change
        top_change = top_change.sort_values(latest_pct_change)

        # Create diverging bar chart
        bars = ax.barh(top_change['Route'].astype(str), top_change[latest_pct_change],
                      color=top_change[latest_pct_change].map(lambda x: 'forestgreen' if x > 0 else 'firebrick'))
        ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)
        ax.set_title(f'Routes with Largest Ridership Changes\n{latest_pct_change.replace("Pct_Change_", "")}',
                   fontsize=16)
        ax.set_xlabel('Percent Change in Ridership (%)', fontsize=14)
        ax.set_ylabel('Route', fontsize=14)
        ax.grid(axis='x', linestyle='--', alpha=0.7)

        # Add value labels to the bars
        for i, bar in enumerate(bars):
            value = top_change[latest_pct_change].iloc[i]
            ax.text(value + (1 if value > 0 else -1),
                   bar.get_y() + bar.get_height()/2,
                   f"{value:.1f}%", va='center', fontsize=11,
                   ha='left' if value > 0 else 'right')
else:
    # If no YoY data, show seasonal variation instead
    seasonal_variation = ridership_data.groupby(['Route', 'Season'])['Ridership'].mean().reset_index()

    # Calculate coefficient of variation for each route across seasons
    route_cv = seasonal_variation.groupby('Route')['Ridership'].apply(
        lambda x: x.std() / x.mean() if x.mean() > 0 else 0
    ).reset_index()
    route_cv.columns = ['Route', 'Seasonal_CV']

    # Get top 10 routes with highest seasonal variation
    top_seasonal_var = route_cv.nlargest(10, 'Seasonal_CV')
    top_seasonal_var = pd.merge(top_seasonal_var,
                              route_avg_ridership[['Route', 'Ridership_Category']],
                              on='Route')
    top_seasonal_var = top_seasonal_var.sort_values('Seasonal_CV')

    bars = ax.barh(top_seasonal_var['Route'].astype(str), top_seasonal_var['Seasonal_CV'],
                 color=[category_palette[cat] for cat in top_seasonal_var['Ridership_Category']])
    ax.set_title('Routes with Highest Seasonal Variation', fontsize=16)
    ax.set_xlabel('Coefficient of Variation', fontsize=14)
    ax.set_ylabel('Route', fontsize=14)
    ax.grid(axis='x', linestyle='--', alpha=0.7)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure5_route_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# 5.4 Weather effect on different route categories
print("\nAnalyzing weather effects by route category...")

# Create a monthly aggregation of weather conditions
monthly_weather = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'TMAX': 'mean',
    'PRCP': 'mean',
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum',
    'HEAVY_PRECIP': 'sum'
}).reset_index()

monthly_weather['Year_Month'] = pd.to_datetime(monthly_weather['Year'].astype(str) + '-' +
                                             monthly_weather['Month'].astype(str), format='%Y-%m')

# Aggregate ridership by category and month
category_monthly = ridership_data.groupby(['Year', 'Month', 'Ridership_Category'])['Ridership'].sum().reset_index()
category_monthly['Year_Month'] = pd.to_datetime(category_monthly['Year'].astype(str) + '-' +
                                              category_monthly['Month'].astype(str), format='%Y-%B')

# Merge weather and category data
category_weather = pd.merge(category_monthly, monthly_weather, on='Year_Month', how='inner',
                          suffixes=('', '_weather'))

# Create a visualization of weather effects by category
plt.figure(figsize=(18, 10))

# Create a 2x3 grid for different weather metrics
fig, axes = plt.subplots(2, 3, figsize=(18, 12))
fig.suptitle('Weather Effects on Ridership by Route Category', fontsize=20, y=0.98)

# Weather metrics to analyze
weather_metrics = [
    ('TMAX', 'Average Maximum Temperature (°F)'),
    ('PRCP', 'Average Daily Precipitation (inches)'),
    ('VERY_HOT', 'Number of Very Hot Days'),
    ('VERY_COLD', 'Number of Very Cold Days'),
    ('HEAVY_PRECIP', 'Number of Heavy Precipitation Days'),
    ('Season', 'Season')
]

# Add the Season column for seasonal analysis
category_weather['Season'] = category_weather['Month'].map(month_to_season)

# Create scatter plots for each weather metric
for i, (metric, title) in enumerate(weather_metrics):
    row, col = i // 3, i % 3
    ax = axes[row, col]

    if metric == 'Season':
        # For season, create a grouped bar chart
        seasonal_ridership = category_weather.groupby(['Season', 'Ridership_Category'])['Ridership'].mean().reset_index()
        sns.barplot(x='Season', y='Ridership', hue='Ridership_Category',
                  data=seasonal_ridership, palette=category_palette, ax=ax,
                  order=seasonal_order)
        ax.set_title(f'Average Ridership by {title}', fontsize=16)
        ax.set_ylabel('Average Ridership', fontsize=14)
        ax.legend(title='Route Category', frameon=True)
    else:
        # For numerical weather metrics, create scatter plots with trend lines
        for category, color in category_palette.items():
            cat_data = category_weather[category_weather['Ridership_Category'] == category]
            ax.scatter(cat_data[metric], cat_data['Ridership'],
                     label=category, color=color, alpha=0.6)

            # Add trend line
            if len(cat_data) > 1:
                z = np.polyfit(cat_data[metric], cat_data['Ridership'], 1)
                p = np.poly1d(z)
                ax.plot(cat_data[metric], p(cat_data[metric]), color=color, linestyle='--')

                # Calculate and display correlation
                corr, p_val = pearsonr(cat_data[metric], cat_data['Ridership'])
                ax.text(0.05, 0.95 - 0.07 * list(category_palette.keys()).index(category),
                       f'{category}: r={corr:.2f} (p={p_val:.3f})',
                       transform=ax.transAxes, fontsize=12, color=color,
                       bbox=dict(facecolor='white', alpha=0.5))

        ax.set_title(f'Ridership vs {title}', fontsize=16)
        ax.set_xlabel(title, fontsize=14)
        ax.set_ylabel('Monthly Ridership', fontsize=14)
        ax.legend(title='Route Category', frameon=True)

    ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure6_weather_by_category.png', dpi=300, bbox_inches='tight')
plt.show()

# 6.1 Panel Data Analysis Setup
print("\nSetting up panel data analysis...")

# Prepare data for panel analysis
# First, let's examine what columns are available
print("Weather data columns:", weather_with_extremes.columns.tolist())
print("Ridership data columns:", ridership_data.columns.tolist())

# Convert month names to numbers in ridership data
month_to_num = {
    'January': 1, 'February': 2, 'March': 3, 'April': 4,
    'May': 5, 'June': 6, 'July': 7, 'August': 8,
    'September': 9, 'October': 10, 'November': 11, 'December': 12
}
ridership_data['Month_Num'] = ridership_data['Month'].map(month_to_num)

# Aggregate weather data monthly
monthly_weather = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'TMAX': 'mean',
    'PRCP': 'mean',
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum',
    'HEAVY_PRECIP': 'sum',
    'HEATWAVE': 'sum',
    'COLDWAVE': 'sum'
}).reset_index()

# Make a copy for panel data
panel_data = monthly_weather.copy()

# Aggregate ridership by month (numeric)
ridership_monthly = ridership_data.groupby(['Year', 'Month_Num'])['Ridership'].sum().reset_index()

# Create Year_Month columns for both datasets (for verification)
panel_data['Year_Month'] = pd.to_datetime(panel_data['Year'].astype(str) + '-' +
                                       panel_data['Month'].astype(str).str.zfill(2) + '-01')
ridership_monthly['Year_Month'] = pd.to_datetime(ridership_monthly['Year'].astype(str) + '-' +
                                              ridership_monthly['Month_Num'].astype(str).str.zfill(2) + '-01')

# Merge datasets on Year and Month/Month_Num
panel_data = pd.merge(panel_data, ridership_monthly,
                     left_on=['Year', 'Month'],
                     right_on=['Year', 'Month_Num'],
                     how='inner',
                     suffixes=('', '_r'))

# Verify the merge worked by showing column names
print("Panel data columns after merge:", panel_data.columns.tolist())

# Add seasonal dummies (now using the original Month column from the weather data)
panel_data['Season'] = panel_data['Month'].map(lambda m: {
    1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',
    6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall',
    11: 'Fall', 12: 'Winter'
}[m])

season_dummies = pd.get_dummies(panel_data['Season'], prefix='Season')
panel_data = pd.concat([panel_data, season_dummies], axis=1)

# 6.2 Fixed Effects Panel Regression
print("\nRunning fixed effects panel regression...")

try:
    import statsmodels.api as sm
    from statsmodels.regression.linear_model import OLS
    import numpy as np

    # Create lag variables for dynamic model
    panel_data['Ridership_Lag1'] = panel_data.groupby(['Year'])['Ridership'].shift(1)

    # Create interaction terms between extreme weather and seasons
    panel_data['Hot_Summer'] = panel_data['VERY_HOT'] * (panel_data['Season'] == 'Summer').astype(int)
    panel_data['Cold_Winter'] = panel_data['VERY_COLD'] * (panel_data['Season'] == 'Winter').astype(int)
    panel_data['Precip_Summer'] = panel_data['HEAVY_PRECIP'] * (panel_data['Season'] == 'Summer').astype(int)
    panel_data['Precip_Winter'] = panel_data['HEAVY_PRECIP'] * (panel_data['Season'] == 'Winter').astype(int)

    # Drop NAs created by lag variables
    panel_data_reg = panel_data.dropna()

    # Check data types before regression
    print("\nData types before regression:")
    print(panel_data_reg.dtypes)

    # Ensure all variables are numeric
    vars_for_regression = [
        'TMAX', 'PRCP', 'VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP',
        'Season_Spring', 'Season_Summer', 'Season_Winter',
        'Hot_Summer', 'Cold_Winter', 'Ridership_Lag1', 'Ridership'
    ]

    # Convert all variables to float
    for var in vars_for_regression:
        if var in panel_data_reg.columns:
            panel_data_reg[var] = pd.to_numeric(panel_data_reg[var], errors='coerce')

    # Drop any rows with NA after conversion
    panel_data_reg = panel_data_reg.dropna(subset=vars_for_regression)

    # Check for any remaining object dtypes
    for col in vars_for_regression:
        if col in panel_data_reg.columns and panel_data_reg[col].dtype == 'object':
            print(f"Warning: Column {col} is still an object type.")
            # Try to inspect the problematic values
            print(f"Sample values: {panel_data_reg[col].sample(5).tolist()}")

    # Define independent variables for regression
    X = panel_data_reg[[
        'TMAX', 'PRCP', 'VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP',
        'Season_Spring', 'Season_Summer', 'Season_Winter',
        'Hot_Summer', 'Cold_Winter', 'Ridership_Lag1'
    ]]

    # Final check of X data types
    print("\nX data types after conversion:")
    print(X.dtypes)
    print("\nX data sample:")
    print(np.asarray(X).dtype)  # Check numpy array dtype
    print(X.head())

    # Convert X to float64
    X = X.astype(float)

    # Add constant
    X = sm.add_constant(X)

    # Define dependent variable
    y = panel_data_reg['Ridership'].astype(float)

    # Run regression
    print("\nRunning OLS regression...")
    model = OLS(y, X).fit(cov_type='HC1')  # Robust standard errors

    # Print results summary
    print("\nPanel Regression Results:")
    print(model.summary().tables[1])

    # Create a formatted results table for publication
    coef_table = model.summary().tables[1].as_html()
    coef_df = pd.read_html(coef_table, header=0, index_col=0)[0]

    # Check the column names in coef_df
    print("\nRegression result columns:", coef_df.columns.tolist())

    # Extract and reformat the key statistics - adapt to the actual column names
    # Use 'z' column instead of 't' column if that's what's available
    stat_column = 'z' if 'z' in coef_df.columns else 't'

    results_dict = {
        'Variable': coef_df.index,
        'Coefficient': coef_df['coef'].values,
        'Std Error': coef_df['std err'].values,
        'Stat Value': coef_df[stat_column].values,  # Use the appropriate column
        'P>|t|': coef_df['P>|z|'].values if 'P>|z|' in coef_df.columns else coef_df['P>|t|'].values,
        'Significance': ['***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.1 else ''
                        for p in (coef_df['P>|z|'] if 'P>|z|' in coef_df.columns else coef_df['P>|t|'])]
    }
    results_df = pd.DataFrame(results_dict)

    # Create a visualization of regression results
    plt.figure(figsize=(14, 10))
    ax = plt.subplot(111, frame_on=False)
    ax.xaxis.set_visible(False)
    ax.yaxis.set_visible(False)

    # Create table for coefficients
    cell_text = []
    for i in range(len(results_df)):
        if results_df['Variable'].iloc[i] != 'const':
            row = [
                results_df['Variable'].iloc[i],
                f"{results_df['Coefficient'].iloc[i]:.4f}",
                f"{results_df['Std Error'].iloc[i]:.4f}",
                f"{results_df['Stat Value'].iloc[i]:.3f}",
                f"{results_df['P>|t|'].iloc[i]:.4f}",
                results_df['Significance'].iloc[i]
            ]
            cell_text.append(row)

    # Add table to plot
    table = plt.table(cellText=cell_text,
                    colLabels=['Variable', 'Coefficient', 'Std Error', f'{stat_column}-stat', 'P-value', 'Significance'],
                    cellLoc='center',
                    loc='center',
                    colWidths=[0.3, 0.15, 0.15, 0.15, 0.15, 0.1])

    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.5)

    plt.title('Weather Effects on Transit Ridership: Panel Regression Results', fontsize=16, y=0.9)
    plt.figtext(0.1, 0.05,
               f"R-squared: {model.rsquared:.3f}   Adjusted R-squared: {model.rsquared_adj:.3f}\n" +
               f"F-statistic: {model.fvalue:.2f}   Prob (F-statistic): {model.f_pvalue:.4f}\n" +
               f"Significance: *** p<0.01, ** p<0.05, * p<0.1",
               fontsize=12)

    plt.savefig('table2_regression_results.png', dpi=300, bbox_inches='tight')
    plt.show()

    # 6.3 Plot key findings from the regression
    effect_size = pd.DataFrame({
        'Weather Factor': ['Average Temperature', 'Precipitation', 'Very Hot Days', 'Very Cold Days',
                         'Heavy Precipitation', 'Hot Days in Summer', 'Cold Days in Winter'],
        'Coefficient': [model.params['TMAX'], model.params['PRCP'],
                      model.params['VERY_HOT'], model.params['VERY_COLD'],
                      model.params['HEAVY_PRECIP'], model.params['Hot_Summer'],
                      model.params['Cold_Winter']],
        'Std Error': [model.bse['TMAX'], model.bse['PRCP'],
                    model.bse['VERY_HOT'], model.bse['VERY_COLD'],
                    model.bse['HEAVY_PRECIP'], model.bse['Hot_Summer'],
                    model.bse['Cold_Winter']],
        'P-value': [model.pvalues['TMAX'], model.pvalues['PRCP'],
                  model.pvalues['VERY_HOT'], model.pvalues['VERY_COLD'],
                  model.pvalues['HEAVY_PRECIP'], model.pvalues['Hot_Summer'],
                  model.pvalues['Cold_Winter']],
    })

    # Sort by absolute coefficient size for visualization
    effect_size['Abs_Coef'] = effect_size['Coefficient'].abs()
    effect_size = effect_size.sort_values('Abs_Coef', ascending=False)
    effect_size = effect_size.drop('Abs_Coef', axis=1)

    # Plot effect sizes
    plt.figure(figsize=(12, 8))

    # Create coefficient plot with error bars
    colors = ['darkred' if (c < 0 and p < 0.05) else
             'darkgreen' if (c > 0 and p < 0.05) else
             'lightcoral' if (c < 0) else 'lightgreen'
             for c, p in zip(effect_size['Coefficient'], effect_size['P-value'])]

    y_pos = np.arange(len(effect_size['Weather Factor']))
    plt.barh(y_pos, effect_size['Coefficient'], xerr=effect_size['Std Error'],
           align='center', color=colors, alpha=0.8, ecolor='black', capsize=5)
    plt.yticks(y_pos, effect_size['Weather Factor'], fontsize=12)

    # Add zero line and grid
    plt.axvline(x=0, color='black', linestyle='-', alpha=0.7)
    plt.grid(axis='x', linestyle='--', alpha=0.7)

    plt.xlabel('Estimated Effect on Ridership', fontsize=14)
    plt.title('Weather Factors: Impact on Public Transit Ridership', fontsize=16)

    # Add a legend for significance
    plt.figtext(0.15, 0.02,
               "Darker colors indicate statistically significant effects (p<0.05)\n" +
               "Error bars represent standard errors",
               fontsize=12, bbox=dict(facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.savefig('figure7_regression_effects.png', dpi=300, bbox_inches='tight')
    plt.show()

except ImportError as e:
    print(f"\nSkipping regression analysis: {e}")
    print("Install statsmodels package for full statistical analysis.")
except Exception as e:
    print(f"\nError during regression analysis: {e}")
    import traceback
    traceback.print_exc()

# 6.4 SDG Indicators Discussion
print("\nRelating findings to Sustainable Development Goals (SDGs)...")

sdg_indicators = {
    'SDG 11': 'Sustainable Cities and Communities',
    'SDG 11.2': 'By 2030, provide access to safe, affordable, accessible and sustainable transport systems for all',
    'SDG 13': 'Climate Action',
    'SDG 13.1': 'Strengthen resilience and adaptive capacity to climate-related hazards and natural disasters',
    'Key Finding 1': 'Extreme weather events significantly impact transit ridership, requiring climate-adaptive planning',
    'Key Finding 2': 'Temperature extremes have differentiated effects on high vs. low ridership routes',
    'Key Finding 3': 'Public transit climate resilience requires consideration of socioeconomic factors',
    'Policy Implication 1': 'Invest in weather-resilient transit infrastructure to maintain service during extremes',
    'Policy Implication 2': 'Develop route-specific adaptation strategies based on ridership patterns and demographics',
    'Policy Implication 3': 'Consider equitable access to transportation during extreme weather events'
}

# Create a table visualizing SDG connections
plt.figure(figsize=(12, 8))
ax = plt.subplot(111, frame_on=False)
ax.xaxis.set_visible(False)
ax.yaxis.set_visible(False)

# Prepare data for the table
sdg_rows = [[key, value] for key, value in sdg_indicators.items()]

# Create the table
table = plt.table(cellText=sdg_rows,
                colLabels=['SDG Indicator', 'Description'],
                cellLoc='left',
                loc='center',
                colWidths=[0.2, 0.7])

table.auto_set_font_size(False)
table.set_fontsize(12)
table.scale(1.2, 1.8)

# Set title
plt.title('Connection to Sustainable Development Goals (SDGs)', fontsize=18, y=0.95)

plt.tight_layout()
plt.savefig('table3_sdg_connections.png', dpi=300, bbox_inches='tight')
plt.show()

# 6.1 Panel Data Analysis Setup with Improved Transformations
print("\nSetting up panel data analysis with improved transformations...")

# Same initial steps for preparing data
monthly_weather = weather_with_extremes.groupby(['Year', 'Month']).agg({
    'TMAX': 'mean',
    'PRCP': 'mean',
    'VERY_HOT': 'sum',
    'VERY_COLD': 'sum',
    'HEAVY_PRECIP': 'sum',
    'HEATWAVE': 'sum',
    'COLDWAVE': 'sum'
}).reset_index()

# Convert month names to numbers in ridership data
month_to_num = {
    'January': 1, 'February': 2, 'March': 3, 'April': 4,
    'May': 5, 'June': 6, 'July': 7, 'August': 8,
    'September': 9, 'October': 10, 'November': 11, 'December': 12
}
ridership_data['Month_Num'] = ridership_data['Month'].map(month_to_num)

# Aggregate ridership by month (numeric)
ridership_monthly = ridership_data.groupby(['Year', 'Month_Num'])['Ridership'].sum().reset_index()

# Create Year_Month columns and merge datasets
monthly_weather['Year_Month'] = pd.to_datetime(monthly_weather['Year'].astype(str) + '-' +
                                             monthly_weather['Month'].astype(str).str.zfill(2) + '-01')
ridership_monthly['Year_Month'] = pd.to_datetime(ridership_monthly['Year'].astype(str) + '-' +
                                               ridership_monthly['Month_Num'].astype(str).str.zfill(2) + '-01')

panel_data = pd.merge(monthly_weather, ridership_monthly,
                     left_on=['Year', 'Month'],
                     right_on=['Year', 'Month_Num'],
                     how='inner',
                     suffixes=('', '_r'))

# Add seasonal dummies
panel_data['Season'] = panel_data['Month'].map(lambda m: {
    1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',
    6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall',
    11: 'Fall', 12: 'Winter'
}[m])

season_dummies = pd.get_dummies(panel_data['Season'], prefix='Season')
panel_data = pd.concat([panel_data, season_dummies], axis=1)

# 6.2 Improved Statistical Analysis with Data Transformations
print("\nRunning statistical analysis with transformed variables...")

try:
    import statsmodels.api as sm
    from statsmodels.regression.linear_model import OLS
    import numpy as np

    # Create lag variables
    panel_data['Ridership_Lag1'] = panel_data.groupby(['Year'])['Ridership'].shift(1)

    # Create interaction terms
    panel_data['Hot_Summer'] = panel_data['VERY_HOT'] * (panel_data['Season'] == 'Summer').astype(int)
    panel_data['Cold_Winter'] = panel_data['VERY_COLD'] * (panel_data['Season'] == 'Winter').astype(int)
    panel_data['Precip_Summer'] = panel_data['HEAVY_PRECIP'] * (panel_data['Season'] == 'Summer').astype(int)
    panel_data['Precip_Winter'] = panel_data['HEAVY_PRECIP'] * (panel_data['Season'] == 'Winter').astype(int)

    # Drop NAs created by lag variables
    panel_data_reg = panel_data.dropna()

    # Apply transformations to make analysis more academically sound
    # 1. Log transform the ridership (most common in transport research)
    panel_data_reg['log_Ridership'] = np.log(panel_data_reg['Ridership'])
    panel_data_reg['log_Ridership_Lag1'] = np.log(panel_data_reg['Ridership_Lag1'])

    # 2. Standardize continuous predictors (Z-score)
    for var in ['TMAX', 'PRCP']:
        mean_val = panel_data_reg[var].mean()
        std_val = panel_data_reg[var].std()
        panel_data_reg[f'{var}_std'] = (panel_data_reg[var] - mean_val) / std_val

    # Define independent variables with transformed data
    X = panel_data_reg[[
        'TMAX_std', 'PRCP_std', 'VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP',
        'Season_Spring', 'Season_Summer', 'Season_Winter',
        'Hot_Summer', 'Cold_Winter', 'log_Ridership_Lag1'
    ]]

    # Convert all to float and add constant
    X = X.astype(float)
    X = sm.add_constant(X)

    # Define dependent variable (log-transformed)
    y = panel_data_reg['log_Ridership'].astype(float)

    # Run regression
    print("\nRunning log-linear regression model...")
    model = OLS(y, X).fit(cov_type='HC1')  # Robust standard errors

    # Print results summary
    print("\nPanel Regression Results (Log-Linear Model):")
    print(model.summary().tables[1])

    # Create a formatted results table for publication
    coef_table = model.summary().tables[1].as_html()
    coef_df = pd.read_html(coef_table, header=0, index_col=0)[0]

    # Check the column names in coef_df
    print("\nRegression result columns:", coef_df.columns.tolist())

    # Extract results with correct column names
    stat_column = 'z' if 'z' in coef_df.columns else 't'
    p_column = 'P>|z|' if 'P>|z|' in coef_df.columns else 'P>|t|'

    results_dict = {
        'Variable': coef_df.index,
        'Coefficient': coef_df['coef'].values,
        'Std Error': coef_df['std err'].values,
        'Stat Value': coef_df[stat_column].values,
        'P-value': coef_df[p_column].values,
        'Significance': ['***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.1 else ''
                        for p in coef_df[p_column]]
    }
    results_df = pd.DataFrame(results_dict)

    # Create interpretation column
    results_df['Interpretation'] = results_df.apply(
        lambda row: f"{np.exp(row['Coefficient'])-1:.1%} change" if row['Variable'] != 'const' else "Base level",
        axis=1
    )

    # Create a visualization of regression results
    plt.figure(figsize=(16, 10))
    ax = plt.subplot(111, frame_on=False)
    ax.xaxis.set_visible(False)
    ax.yaxis.set_visible(False)

    # Create table for coefficients
    cell_text = []
    for i in range(len(results_df)):
        if results_df['Variable'].iloc[i] != 'const':
            row = [
                results_df['Variable'].iloc[i],
                f"{results_df['Coefficient'].iloc[i]:.4f}",
                f"{results_df['Std Error'].iloc[i]:.4f}",
                f"{results_df['Stat Value'].iloc[i]:.3f}",
                f"{results_df['P-value'].iloc[i]:.4f}",
                results_df['Significance'].iloc[i],
                results_df['Interpretation'].iloc[i]
            ]
            cell_text.append(row)

    # Add table to plot
    table = plt.table(cellText=cell_text,
                    colLabels=['Variable', 'Coefficient', 'Std Error', f'{stat_column}-stat',
                              'P-value', 'Significance', 'Interpretation'],
                    cellLoc='center',
                    loc='center',
                    colWidths=[0.2, 0.12, 0.12, 0.12, 0.12, 0.08, 0.24])

    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.5)

    plt.title('Weather Effects on Transit Ridership: Log-Linear Model Results', fontsize=16, y=0.95)
    plt.figtext(0.1, 0.02,
               f"R-squared: {model.rsquared:.3f}   Adjusted R-squared: {model.rsquared_adj:.3f}\n" +
               f"Log-Linear Model: Coefficients represent approximate percentage changes in ridership\n" +
               f"Significance: *** p<0.01, ** p<0.05, * p<0.1",
               fontsize=12)

    plt.savefig('table2_regression_results.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Create a more academic visualization of the key findings
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), gridspec_kw={'width_ratios': [1.5, 1]})

    # Plot 1: Effect sizes for continuous variables (left panel)
    # Sort variables by effect size
    effect_size = pd.DataFrame({
        'Weather Factor': ['Temperature', 'Precipitation', 'Very Hot Days', 'Very Cold Days',
                         'Heavy Precipitation', 'Hot Days in Summer', 'Cold Days in Winter'],
        'Coefficient': [model.params['TMAX_std'], model.params['PRCP_std'],
                      model.params['VERY_HOT'], model.params['VERY_COLD'],
                      model.params['HEAVY_PRECIP'], model.params['Hot_Summer'],
                      model.params['Cold_Winter']],
        'Std Error': [model.bse['TMAX_std'], model.bse['PRCP_std'],
                    model.bse['VERY_HOT'], model.bse['VERY_COLD'],
                    model.bse['HEAVY_PRECIP'], model.bse['Hot_Summer'],
                    model.bse['Cold_Winter']],
        'P-value': [model.pvalues['TMAX_std'], model.pvalues['PRCP_std'],
                  model.pvalues['VERY_HOT'], model.pvalues['VERY_COLD'],
                  model.pvalues['HEAVY_PRECIP'], model.pvalues['Hot_Summer'],
                  model.pvalues['Cold_Winter']],
        'Effect Type': ['Continuous', 'Continuous', 'Count', 'Count', 'Count', 'Interaction', 'Interaction']
    })

    # Sort by absolute coefficient size
    effect_size['Abs_Coef'] = effect_size['Coefficient'].abs()
    effect_size = effect_size.sort_values('Abs_Coef', ascending=False)

    # Add percentage interpretation
    effect_size['Percentage'] = (np.exp(effect_size['Coefficient']) - 1) * 100
    effect_size['Percentage_Text'] = effect_size['Percentage'].apply(lambda x: f"{x:.1f}%")

    # Create color mapping based on significance and direction
    colors = ['darkred' if (c < 0 and p < 0.05) else
             'darkgreen' if (c > 0 and p < 0.05) else
             'lightcoral' if (c < 0) else 'lightgreen'
             for c, p in zip(effect_size['Coefficient'], effect_size['P-value'])]

    # Plot horizontal bars
    y_pos = np.arange(len(effect_size['Weather Factor']))
    bars = ax1.barh(y_pos, effect_size['Percentage'], xerr=effect_size['Std Error']*100,
                  align='center', color=colors, alpha=0.8, ecolor='black', capsize=5)
    ax1.set_yticks(y_pos)
    ax1.set_yticklabels(effect_size['Weather Factor'], fontsize=12)
    ax1.invert_yaxis()  # Invert y-axis to show largest values on top

    # Add percentage labels
    for i, bar in enumerate(bars):
        if effect_size['P-value'].iloc[i] < 0.05:
            weight = 'bold'
            text_color = 'black'
        else:
            weight = 'normal'
            text_color = 'gray'

        ax1.text(bar.get_width() + (5 if bar.get_width() >= 0 else -15),
                bar.get_y() + bar.get_height()/2,
                effect_size['Percentage_Text'].iloc[i],
                va='center', fontsize=11, fontweight=weight, color=text_color)

    # Add zero line and grid
    ax1.axvline(x=0, color='black', linestyle='-', alpha=0.7)
    ax1.grid(axis='x', linestyle='--', alpha=0.7)

    ax1.set_xlabel('Estimated Effect on Ridership (%)', fontsize=14)
    ax1.set_title('Weather Factors: Relative Impact on Public Transit Ridership', fontsize=16)

    # Plot 2: Seasonal effects (right panel)
    seasonal_effects = pd.DataFrame({
        'Season': ['Spring', 'Summer', 'Winter', 'Fall (Reference)'],
        'Coefficient': [model.params['Season_Spring'], model.params['Season_Summer'],
                       model.params['Season_Winter'], 0],
        'Std Error': [model.bse['Season_Spring'], model.bse['Season_Summer'],
                     model.bse['Season_Winter'], 0],
        'P-value': [model.pvalues['Season_Spring'], model.pvalues['Season_Summer'],
                   model.pvalues['Season_Winter'], 1]
    })

    # Calculate percentage effects
    seasonal_effects['Percentage'] = (np.exp(seasonal_effects['Coefficient']) - 1) * 100

    # Create colors
    season_colors = ['forestgreen', 'firebrick', 'steelblue', 'goldenrod']

    # Create bar chart
    bars = ax2.bar(seasonal_effects['Season'], seasonal_effects['Percentage'],
                 yerr=seasonal_effects['Std Error']*100,
                 color=season_colors, alpha=0.7, capsize=5)

    # Add percentage labels
    for i, bar in enumerate(bars):
        if i < 3 and seasonal_effects['P-value'].iloc[i] < 0.05:
            weight = 'bold'
            text_color = 'black'
        else:
            weight = 'normal'
            text_color = 'gray'

        ax2.text(bar.get_x() + bar.get_width()/2,
                bar.get_height() + 1 if bar.get_height() >= 0 else bar.get_height() - 5,
                f"{seasonal_effects['Percentage'].iloc[i]:.1f}%",
                ha='center', va='bottom', fontsize=11,
                fontweight=weight, color=text_color)

    # Add reference line
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.7)
    ax2.grid(axis='y', linestyle='--', alpha=0.7)

    ax2.set_ylabel('Effect on Ridership Relative to Fall (%)', fontsize=14)
    ax2.set_title('Seasonal Effects on Transit Ridership', fontsize=16)

    # Add annotation for interpretation
    fig.text(0.5, 0.01,
           "Note: Bold values indicate statistical significance (p<0.05). Effects are percentage changes in ridership.\n" +
           "Analysis based on log-linear regression model controlling for lagged ridership and weather conditions.",
           ha='center', fontsize=12)

    plt.tight_layout(rect=[0, 0.04, 1, 0.97])
    plt.savefig('figure7_regression_effects_academic.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Additional academic analysis: Elasticities for continuous variables
    # Create a table of elasticities
    elasticity_data = {
        'Variable': ['Temperature (1°F increase)', 'Precipitation (0.1 inch increase)'],
        'Elasticity': [model.params['TMAX_std'] * (1/panel_data_reg['TMAX'].std()),
                      model.params['PRCP_std'] * (0.1/panel_data_reg['PRCP'].std())],
        'Percentage Effect': [(np.exp(model.params['TMAX_std'] * (1/panel_data_reg['TMAX'].std())) - 1) * 100,
                            (np.exp(model.params['PRCP_std'] * (0.1/panel_data_reg['PRCP'].std())) - 1) * 100]
    }
    elasticity_df = pd.DataFrame(elasticity_data)

    print("\nElasticity Analysis:")
    print(elasticity_df)

    # Create a visualization of elasticities
    plt.figure(figsize=(10, 6))
    ax = plt.subplot(111)

    bars = ax.bar(elasticity_df['Variable'], elasticity_df['Percentage Effect'],
                 color=['lightskyblue', 'lightgreen'], alpha=0.8)

    # Add labels
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, height + 0.1,
               f"{height:.2f}%", ha='center', va='bottom', fontsize=12)

    ax.set_ylabel('Percentage Change in Ridership', fontsize=14)
    ax.set_title('Elasticity of Ridership with Respect to Weather Variables', fontsize=16)
    ax.grid(axis='y', linestyle='--', alpha=0.6)

    plt.tight_layout()
    plt.savefig('figure8_elasticity_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

except ImportError as e:
    print(f"\nSkipping regression analysis: {e}")
    print("Install statsmodels package for full statistical analysis.")
except Exception as e:
    print(f"\nError during regression analysis: {e}")
    import traceback
    traceback.print_exc()



import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib.gridspec import GridSpec
from matplotlib.ticker import FuncFormatter, MultipleLocator
import matplotlib.patches as mpatches
from scipy import stats

# Set publication-quality parameters
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['DejaVu Serif', 'Bitstream Vera Serif', 'Computer Modern Roman', 'New Century Schoolbook', 'Century Schoolbook L', 'Utopia', 'ITC Bookman', 'Bookman', 'Nimbus Roman No9 L', 'Times New Roman', 'Times', 'Palatino', 'Charter', 'serif']
plt.rcParams['font.size'] = 12
plt.rcParams['font.size'] = 11
plt.rcParams['axes.linewidth'] = 0.8
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 16
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 600  # High resolution for publication
plt.rcParams['text.usetex'] = False  # Change to True if LaTeX is available

# Define professional color palettes based on scientific journals
# ColorBrewer palette (colorblind-friendly)
cb_colors = ['#4575b4', '#d73027', '#91bfdb', '#fc8d59', '#fee090', '#e0f3f8']
earth_tones = ['#A67C52', '#8A9A5B', '#6F4E37', '#9B7653', '#6C541E']

# Figure 1: Weather Impact on Ridership with Confidence Intervals
def create_weather_impact_figure(effect_size_data):
    """
    Creates a high-quality academic figure showing weather impacts with confidence intervals.
    """
    fig = plt.figure(figsize=(8, 6))

    # Sort by effect magnitude
    effect_size_data = effect_size_data.sort_values('Abs_Coef', ascending=True)

    y_pos = np.arange(len(effect_size_data))

    # Calculate 95% confidence intervals
    ci_lower = effect_size_data['Percentage'] - 1.96 * effect_size_data['Std Error'] * 100
    ci_upper = effect_size_data['Percentage'] + 1.96 * effect_size_data['Std Error'] * 100

    # Create horizontal forest plot with error bars
    plt.barh(y_pos, effect_size_data['Percentage'],
           xerr=1.96 * effect_size_data['Std Error'] * 100,  # 95% CI
           align='center', alpha=0.8, color=[cb_colors[0] if p < 0.05 else '#CCCCCC'
                                          for p in effect_size_data['P-value']],
           height=0.6, capsize=3, ecolor='black', linewidth=1)

    plt.axvline(x=0, color='black', linestyle='-', linewidth=0.8)

    # Add significance markers
    for i, p in enumerate(effect_size_data['P-value']):
        if p < 0.01:
            plt.text(effect_size_data['Percentage'].iloc[i] + 0.2, y_pos[i] + 0.2, '***',
                   ha='left' if effect_size_data['Percentage'].iloc[i] > 0 else 'right',
                   va='center', color='black', fontsize=12, fontweight='bold')
        elif p < 0.05:
            plt.text(effect_size_data['Percentage'].iloc[i] + 0.2, y_pos[i] + 0.2, '**',
                   ha='left' if effect_size_data['Percentage'].iloc[i] > 0 else 'right',
                   va='center', color='black', fontsize=12, fontweight='bold')
        elif p < 0.1:
            plt.text(effect_size_data['Percentage'].iloc[i] + 0.2, y_pos[i] + 0.2, '*',
                   ha='left' if effect_size_data['Percentage'].iloc[i] > 0 else 'right',
                   va='center', color='black', fontsize=12, fontweight='bold')

    # Add percentage labels
    for i, (pct, p) in enumerate(zip(effect_size_data['Percentage'], effect_size_data['P-value'])):
        weight = 'bold' if p < 0.05 else 'normal'
        plt.text(pct + (2 if pct >= 0 else -2), y_pos[i],
               f"{pct:.1f}%", va='center', fontsize=10,
               ha='left' if pct >= 0 else 'right', fontweight=weight)

    # Format the plot
    plt.yticks(y_pos, effect_size_data['Weather Factor'], fontsize=11)
    plt.xlabel('Percentage Change in Transit Ridership', fontsize=12)

    # Proper academic title and subtitle
    plt.title('Impact of Weather Variables on Public Transit Ridership', fontsize=14, pad=15)
    plt.figtext(0.5, 0.01,
              "Note: Error bars represent 95% confidence intervals. ***p<0.01, **p<0.05, *p<0.1",
              ha='center', fontsize=10, fontstyle='italic')

    # Journal-style grid
    plt.grid(axis='x', linestyle='--', alpha=0.3)

    # Adjust layout
    plt.tight_layout(rect=[0, 0.05, 1, 0.95])

    # Add panel label in the academic style
    plt.text(0.02, 0.98, "(a)", transform=fig.transFigure, fontsize=12, fontweight='bold')

    return fig

# Figure 2: Seasonal Patterns with Statistical Annotations
def create_seasonal_pattern_figure(seasonal_data, weather_data):
    """
    Creates an academic figure showing seasonal ridership patterns with statistical annotations.
    """
    fig = plt.figure(figsize=(10, 8))
    gs = GridSpec(2, 2, width_ratios=[2, 1], height_ratios=[1, 1], figure=fig)

    # Panel (a): Seasonal ridership by transportation mode
    ax1 = fig.add_subplot(gs[0, 0])

    # Create a proper grouped bar chart
    seasonal_order = ['Winter', 'Spring', 'Summer', 'Fall']
    modes = ['Bus', 'Trolley', 'Trackless Trolley']
    bar_width = 0.25
    x = np.arange(len(seasonal_order))

    # Generate some representative data if needed
    if seasonal_data is None:
        # Example data structure if real data isn't passed
        seasonal_data = {
            'Winter': {'Bus': 150000, 'Trolley': 80000, 'Trackless Trolley': 30000},
            'Spring': {'Bus': 170000, 'Trolley': 90000, 'Trackless Trolley': 35000},
            'Summer': {'Bus': 160000, 'Trolley': 95000, 'Trackless Trolley': 32000},
            'Fall': {'Bus': 175000, 'Trolley': 85000, 'Trackless Trolley': 33000}
        }

    # Plot bars for each mode
    for i, mode in enumerate(modes):
        values = [seasonal_data.get(season, {}).get(mode, 0)/1000 for season in seasonal_order]
        ax1.bar(x + (i - 1) * bar_width, values, bar_width, label=mode, color=cb_colors[i], alpha=0.85)

    # Format the plot
    ax1.set_xticks(x)
    ax1.set_xticklabels(seasonal_order)
    ax1.set_ylabel('Ridership (thousands)', fontsize=12)
    ax1.legend(title='Transit Mode', fontsize=9)
    ax1.set_title('Seasonal Ridership by Transit Mode', fontsize=12, pad=10)
    ax1.grid(axis='y', linestyle='--', alpha=0.3)
    ax1.text(-0.15, 1.02, "(a)", transform=ax1.transAxes, fontsize=12, fontweight='bold')

    # Panel (b): Temperature distribution by season
    ax2 = fig.add_subplot(gs[0, 1])

    # Generate some representative weather data if needed
    if weather_data is None:
        np.random.seed(42)
        weather_data = {}
        for season in seasonal_order:
            if season == 'Winter':
                weather_data[season] = np.random.normal(35, 10, 100)
            elif season == 'Spring':
                weather_data[season] = np.random.normal(60, 10, 100)
            elif season == 'Summer':
                weather_data[season] = np.random.normal(80, 8, 100)
            else:  # Fall
                weather_data[season] = np.random.normal(55, 12, 100)

    # Plot boxplots
    boxprops = dict(linewidth=1.5)
    whiskerprops = dict(linewidth=1.5)
    medianprops = dict(color='black', linewidth=1.5)

    bp = ax2.boxplot([weather_data[season] for season in seasonal_order],
                    patch_artist=True,
                    boxprops=boxprops,
                    whiskerprops=whiskerprops,
                    medianprops=medianprops)

    # Color boxes by season
    colors = [cb_colors[i] for i in range(4)]
    for i, box in enumerate(bp['boxes']):
        box.set(facecolor=colors[i], alpha=0.7)

    # Format the plot
    ax2.set_xticklabels(seasonal_order)
    ax2.set_ylabel('Temperature (°F)', fontsize=12)
    ax2.set_title('Temperature Distribution by Season', fontsize=12, pad=10)
    ax2.grid(axis='y', linestyle='--', alpha=0.3)
    ax2.text(-0.2, 1.02, "(b)", transform=ax2.transAxes, fontsize=12, fontweight='bold')

    # Panel (c): Ridership vs. temperature scatter plot with regression line
    ax3 = fig.add_subplot(gs[1, 0])

    # Generate some representative scatter data if needed
    if weather_data is None:
        np.random.seed(42)
        temperatures = np.random.uniform(30, 90, 100)
        ridership = 150000 - 500 * (temperatures - 70)**2 + np.random.normal(0, 10000, 100)
    else:
        # Flatten temperature data and create matching ridership
        temperatures = np.concatenate([weather_data[season] for season in seasonal_order])
        mean_ridership = 150000
        ridership = mean_ridership - 500 * (temperatures - 70)**2 + np.random.normal(0, 10000, len(temperatures))

    # Create scatter plot
    ax3.scatter(temperatures, ridership/1000, alpha=0.6, s=30, c='#4575b4', edgecolor='none')

    # Add regression curve
    x_range = np.linspace(min(temperatures), max(temperatures), 100)
    z = np.polyfit(temperatures, ridership/1000, 2)
    p = np.poly1d(z)
    ax3.plot(x_range, p(x_range), 'r-', linewidth=2)

    # Add R-squared
    r2 = 1 - (sum((ridership/1000 - p(temperatures))**2) /
             ((len(ridership) - 1) * np.var(ridership/1000, ddof=1)))
    ax3.text(0.05, 0.95, f"$R^2 = {r2:.3f}$", transform=ax3.transAxes,
           fontsize=10, va='top', bbox=dict(facecolor='white', alpha=0.8))

    # Format the plot
    ax3.set_xlabel('Temperature (°F)', fontsize=12)
    ax3.set_ylabel('Ridership (thousands)', fontsize=12)
    ax3.set_title('Ridership vs. Temperature: Non-linear Relationship', fontsize=12, pad=10)
    ax3.grid(linestyle='--', alpha=0.3)
    ax3.text(-0.15, 1.02, "(c)", transform=ax3.transAxes, fontsize=12, fontweight='bold')

    # Panel (d): Bar chart of extreme weather impact
    ax4 = fig.add_subplot(gs[1, 1])

    # Create bar data
    impact_types = ['Heat Wave', 'Cold Wave', 'Heavy\nPrecipitation']
    impacts = [-12.5, -8.3, -15.7]  # Percent change in ridership

    # Create bars with error bars
    errors = [2.1, 1.7, 2.5]  # Standard errors
    bars = ax4.bar(impact_types, impacts, yerr=errors, capsize=5,
                 color=['#d73027', '#4575b4', '#91bfdb'], alpha=0.8, width=0.6)

    # Format the plot
    ax4.set_ylabel('% Change in Ridership', fontsize=12)
    ax4.set_title('Impact of Extreme Weather Events', fontsize=12, pad=10)
    ax4.axhline(y=0, color='k', linestyle='-', alpha=0.3, linewidth=0.8)
    ax4.grid(axis='y', linestyle='--', alpha=0.3)
    ax4.text(-0.2, 1.02, "(d)", transform=ax4.transAxes, fontsize=12, fontweight='bold')

    # Add significance indicators
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height - 1,
               '***' if i == 0 else '**',
               ha='center', va='bottom', fontsize=10, fontweight='bold', color='white')

    # Add a comprehensive figure caption
    plt.figtext(0.5, 0.01,
              "Figure 2: The relationship between seasonal patterns, temperature, and transit ridership. Panels show: (a) ridership by transit mode and season;\n"
              "(b) temperature distribution by season; (c) non-linear relationship between temperature and ridership; and (d) percentage impacts of extreme\n"
              "weather events. Error bars represent standard errors. Statistical significance: ***p<0.01, **p<0.05, *p<0.1.",
              ha='center', fontsize=9, fontstyle='italic')

    # Adjust layout
    plt.tight_layout(rect=[0, 0.04, 1, 0.97])

    return fig

# Figure 3: Comprehensive Route Analysis with Academic Styling
def create_route_analysis_figure(route_data=None):
    """
    Creates a comprehensive academic figure analyzing route performance.
    """
    fig = plt.figure(figsize=(10, 8))
    gs = GridSpec(2, 2, figure=fig)

    # Generate representative data if needed
    if route_data is None:
        np.random.seed(42)
        route_categories = ['Low', 'Medium', 'High']
        category_counts = [45, 35, 20]
        weather_sensitivity = {
            'Temperature': {'Low': -0.8, 'Medium': -0.5, 'High': -0.3},
            'Precipitation': {'Low': -1.2, 'Medium': -0.9, 'High': -0.6}
        }
        route_changes = {
            'Route 10': 15.2, 'Route 23': 12.5, 'Route 47': 8.7, 'Route 36': 7.2, 'Route 52': 5.1,
            'Route 15': -12.1, 'Route 8': -10.3, 'Route 31': -7.9, 'Route 44': -6.5, 'Route 27': -5.8
        }

    # Panel (a): Route category distribution
    ax1 = fig.add_subplot(gs[0, 0])

    ax1.bar(range(len(route_categories)), category_counts, color=cb_colors[:3], alpha=0.8)
    ax1.set_xticks(range(len(route_categories)))
    ax1.set_xticklabels(route_categories)
    ax1.set_xlabel('Ridership Volume Category', fontsize=11)
    ax1.set_ylabel('Number of Routes', fontsize=11)
    ax1.set_title('Distribution of Routes by Ridership Volume', fontsize=12, pad=10)

    # Add number labels on top of bars
    for i, v in enumerate(category_counts):
        ax1.text(i, v + 0.5, str(v), ha='center', fontsize=10)

    ax1.grid(axis='y', linestyle='--', alpha=0.3)
    ax1.text(-0.15, 1.02, "(a)", transform=ax1.transAxes, fontsize=12, fontweight='bold')

    # Panel (b): Weather sensitivity by route category
    ax2 = fig.add_subplot(gs[0, 1])

    # Define positions
    x = np.arange(len(route_categories))
    bar_width = 0.35

    # Create bars
    ax2.bar(x - bar_width/2, [weather_sensitivity['Temperature'][cat] for cat in route_categories],
           bar_width, label='Temperature', color=cb_colors[0], alpha=0.8)
    ax2.bar(x + bar_width/2, [weather_sensitivity['Precipitation'][cat] for cat in route_categories],
           bar_width, label='Precipitation', color=cb_colors[1], alpha=0.8)

    # Format the plot
    ax2.set_xticks(x)
    ax2.set_xticklabels(route_categories)
    ax2.set_xlabel('Route Category', fontsize=11)
    ax2.set_ylabel('Elasticity', fontsize=11)
    ax2.set_title('Weather Sensitivity by Route Category', fontsize=12, pad=10)
    ax2.legend(loc='lower right', fontsize=9)
    ax2.grid(axis='y', linestyle='--', alpha=0.3)
    ax2.text(-0.2, 1.02, "(b)", transform=ax2.transAxes, fontsize=12, fontweight='bold')

    # Panel (c): Routes with largest changes (diverging bar chart)
    ax3 = fig.add_subplot(gs[1, :])

    # Sort routes by change
    sorted_routes = sorted(route_changes.items(), key=lambda x: x[1])
    routes = [item[0] for item in sorted_routes]
    changes = [item[1] for item in sorted_routes]

    # Create colors based on direction of change
    colors = ['#d73027' if change < 0 else '#4575b4' for change in changes]

    # Create diverging bars
    bars = ax3.barh(routes, changes, color=colors, alpha=0.8, height=0.6)

    # Format the plot
    ax3.axvline(x=0, color='k', linestyle='-', alpha=0.5, linewidth=0.8)
    ax3.set_xlabel('Percentage Change in Ridership (%)', fontsize=12)
    ax3.set_title('Routes with Largest Year-Over-Year Changes', fontsize=14, pad=10)
    ax3.grid(axis='x', linestyle='--', alpha=0.3)

    # Add percent labels
    for i, bar in enumerate(bars):
        width = bar.get_width()
        label_x = width + 0.5 if width >= 0 else width - 0.5
        ax3.text(label_x, bar.get_y() + bar.get_height()/2,
               f"{width:.1f}%", va='center', ha='left' if width >= 0 else 'right',
               fontsize=9, fontweight='bold' if abs(width) > 10 else 'normal')

    ax3.text(-0.07, 1.02, "(c)", transform=ax3.transAxes, fontsize=12, fontweight='bold')

    # Add annotations explaining potential causes
    ax3.annotate('Increased service frequency',
              xy=(15.2, 'Route 10'), xytext=(17, 9.8),
              arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),
              fontsize=9)

    ax3.annotate('Service disruption due to\nconstruction project',
              xy=(-12.1, 'Route 15'), xytext=(-20, 9.5),
              arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),
              fontsize=9)

    # Add a comprehensive figure caption
    plt.figtext(0.5, 0.01,
              "Figure 3: Analysis of route-level ridership patterns. Panel (a) shows the distribution of routes by ridership category.\n"
              "Panel (b) presents the sensitivity of different route categories to weather variables. Panel (c) identifies routes with\n"
              "the largest year-over-year changes in ridership. Routes with highest changes may reflect service modifications or\n"
              "infrastructure projects affecting accessibility.",
              ha='center', fontsize=9, fontstyle='italic')

    # Adjust layout
    plt.tight_layout(rect=[0, 0.05, 1, 0.97])

    return fig

# Figure 4: Weather-Ridership Relationship Matrix
def create_weather_ridership_matrix(temperature_data=None, precipitation_data=None, ridership_data=None):
    """
    Creates an academic matrix figure showing multiple weather-ridership relationships.
    """
    fig = plt.figure(figsize=(10, 10))

    # Generate representative data if needed
    np.random.seed(42)
    if temperature_data is None:
        days = 100
        temperature_data = np.linspace(30, 95, days)
        precipitation_data = np.random.exponential(0.1, days)
        precipitation_data[precipitation_data > 0.8] = 0.8  # Cap extreme values

        # Create ridership patterns
        base_ridership = 10000
        temp_effect = -50 * (temperature_data - 70)**2
        precip_effect = -5000 * precipitation_data
        weekday_effect = np.random.choice([1.0, 0.6], days)  # Weekday vs weekend
        ridership_data = base_ridership + temp_effect + precip_effect
        ridership_data *= weekday_effect

    # Create 2x2 subplot grid
    gs = GridSpec(2, 2, figure=fig)

    # Panel (a): Temperature vs. Ridership Scatter
    ax1 = fig.add_subplot(gs[0, 0])

    # Add non-linear regression curve first (so it's behind points)
    z = np.polyfit(temperature_data, ridership_data/1000, 2)
    p = np.poly1d(z)
    x_smooth = np.linspace(min(temperature_data), max(temperature_data), 100)
    ax1.plot(x_smooth, p(x_smooth), color='red', linestyle='-', linewidth=2)

    # Plot points with some transparency
    ax1.scatter(temperature_data, ridership_data/1000, alpha=0.6, edgecolor='none', color=cb_colors[0])

    # Add equation and R-squared
    equation = f"y = {z[0]:.2f}x² + {z[1]:.2f}x + {z[2]:.2f}"
    r2 = 1 - (sum((ridership_data/1000 - p(temperature_data))**2) /
             ((len(ridership_data) - 1) * np.var(ridership_data/1000, ddof=1)))

    ax1.text(0.05, 0.95, f"{equation}\n$R^2 = {r2:.3f}$", transform=ax1.transAxes,
           fontsize=10, va='top', bbox=dict(facecolor='white', alpha=0.7))

    # Format the plot
    ax1.set_xlabel('Temperature (°F)', fontsize=11)
    ax1.set_ylabel('Ridership (thousands)', fontsize=11)
    ax1.set_title('Non-Linear Temperature-Ridership Relationship', fontsize=12)
    ax1.grid(linestyle='--', alpha=0.3)
    ax1.text(-0.15, 1.02, "(a)", transform=ax1.transAxes, fontsize=12, fontweight='bold')

    # Panel (b): Precipitation vs. Ridership
    ax2 = fig.add_subplot(gs[0, 1])

    # Add linear regression
    slope, intercept, r_value, p_value, std_err = stats.linregress(precipitation_data, ridership_data/1000)
    x_smooth = np.linspace(0, max(precipitation_data), 100)
    ax2.plot(x_smooth, intercept + slope*x_smooth, color='red', linestyle='-', linewidth=2)

    # Plot points with some transparency
    ax2.scatter(precipitation_data, ridership_data/1000, alpha=0.6, edgecolor='none', color=cb_colors[1])

    # Add equation and R-squared
    equation = f"y = {intercept:.2f} + {slope:.2f}x"
    r2 = r_value**2

    ax2.text(0.05, 0.95, f"{equation}\n$R^2 = {r2:.3f}$", transform=ax2.transAxes,
           fontsize=10, va='top', bbox=dict(facecolor='white', alpha=0.7))

    # Format the plot
    ax2.set_xlabel('Precipitation (inches)', fontsize=11)
    ax2.set_ylabel('Ridership (thousands)', fontsize=11)
    ax2.set_title('Precipitation-Ridership Relationship', fontsize=12)
    ax2.grid(linestyle='--', alpha=0.3)
    ax2.text(-0.15, 1.02, "(b)", transform=ax2.transAxes, fontsize=12, fontweight='bold')

    # Panel (c): Seasonal Bins of Temperature and Ridership
    ax3 = fig.add_subplot(gs[1, 0])

    # Create temperature bins
    temp_bins = [30, 40, 50, 60, 70, 80, 90, 100]
    bin_labels = ['30-40', '40-50', '50-60', '60-70', '70-80', '80-90', '90+']
    digitized = np.digitize(temperature_data, temp_bins)

    # Calculate mean ridership by temperature bin
    bin_means = [ridership_data[digitized == i].mean()/1000 for i in range(1, len(temp_bins))]
    bin_std = [ridership_data[digitized == i].std()/1000 for i in range(1, len(temp_bins))]

    # Plot bar chart
    bars = ax3.bar(bin_labels, bin_means, yerr=bin_std, capsize=5,
                 color=cb_colors, alpha=0.7)

    # Highlight the optimal temperature range
    optimal_index = np.argmax(bin_means)
    bars[optimal_index].set_color('#4daf4a')  # Green for optimal
    bars[optimal_index].set_alpha(0.9)

    # Format the plot
    ax3.set_xlabel('Temperature Range (°F)', fontsize=11)
    ax3.set_ylabel('Mean Ridership (thousands)', fontsize=11)
    ax3.set_title('Temperature Bands and Ridership', fontsize=12)
    ax3.grid(axis='y', linestyle='--', alpha=0.3)
    ax3.text(-0.15, 1.02, "(c)", transform=ax3.transAxes, fontsize=12, fontweight='bold')

    # Panel (d): 3D Heatmap of Temperature, Precipitation, and Ridership
    ax4 = fig.add_subplot(gs[1, 1])

    # Create bins for both variables
    temp_bins = np.linspace(min(temperature_data), max(temperature_data), 6)
    precip_bins = np.linspace(0, max(precipitation_data), 6)

    # Digitize the data
    temp_digitized = np.digitize(temperature_data, temp_bins)
    precip_digitized = np.digitize(precipitation_data, precip_bins)

    # Create a 2D matrix to hold the mean ridership values
    heatmap_data = np.zeros((len(temp_bins)-1, len(precip_bins)-1))

    # Calculate mean ridership for each bin combination
    for i in range(1, len(temp_bins)):
        for j in range(1, len(precip_bins)):
            mask = (temp_digitized == i) & (precip_digitized == j)
            if mask.sum() > 0:
                heatmap_data[i-1, j-1] = ridership_data[mask].mean()/1000
            else:
                heatmap_data[i-1, j-1] = np.nan

    # Create the heatmap
    im = ax4.imshow(heatmap_data, cmap='viridis', aspect='auto',
                   origin='lower', interpolation='nearest')

    # Set x and y ticks
    temp_tick_labels = [f"{temp_bins[i]:.0f}-{temp_bins[i+1]:.0f}" for i in range(len(temp_bins)-1)]
    precip_tick_labels = [f"{precip_bins[i]:.1f}-{precip_bins[i+1]:.1f}" for i in range(len(precip_bins)-1)]

    ax4.set_xticks(np.arange(len(precip_tick_labels)))
    ax4.set_yticks(np.arange(len(temp_tick_labels)))
    ax4.set_xticklabels(precip_tick_labels, rotation=45)
    ax4.set_yticklabels(temp_tick_labels)

    # Add colorbar
    cbar = plt.colorbar(im, ax=ax4, fraction=0.046, pad=0.04)
    cbar.set_label('Mean Ridership (thousands)', rotation=270, labelpad=15)

    # Format the plot
    ax4.set_xlabel('Precipitation Range (inches)', fontsize=11)
    ax4.set_ylabel('Temperature Range (°F)', fontsize=11)
    ax4.set_title('Temperature-Precipitation-Ridership Matrix', fontsize=12)
    ax4.text(-0.15, 1.02, "(d)", transform=ax4.transAxes, fontsize=12, fontweight='bold')

    # Add ridership values to cells
    for i in range(len(temp_tick_labels)):
        for j in range(len(precip_tick_labels)):
            if not np.isnan(heatmap_data[i, j]):
                ax4.text(j, i, f"{heatmap_data[i, j]:.1f}", ha="center", va="center",
                       color="w" if heatmap_data[i, j] < np.nanmax(heatmap_data)/1.5 else "black",
                       fontsize=9)

    # Add comprehensive figure caption
    plt.figtext(0.5, 0.01,
              "Figure 4: Multi-dimensional analysis of weather impacts on transit ridership. Panel (a) demonstrates the non-linear relationship between temperature\n"
              "and ridership with a quadratic fit. Panel (b) shows the linear decline in ridership with increasing precipitation. Panel (c) displays mean ridership by\n"
              "temperature bands with the optimal range highlighted. Panel (d) presents a heat map matrix of combined temperature-precipitation effects on ridership.\n"
              "Error bars in panel (c) represent standard deviations.",
              ha='center', fontsize=9, fontstyle='italic')

    # Adjust layout
    plt.tight_layout(rect=[0, 0.05, 1, 0.96])

    return fig

# Example usage
if __name__ == "__main__":
    # Generate sample data for demonstration
    np.random.seed(42)
    effect_size_data = pd.DataFrame({
        'Weather Factor': ['Temperature (per °F)', 'Heavy Precipitation', 'Heat Wave Days',
                         'Cold Wave Days', 'Very Hot Days', 'Very Cold Days', 'Precipitation (per inch)'],
        'Coefficient': [0.016, -0.157, -0.125, -0.083, -0.045, -0.062, -0.943],
        'Std Error': [0.006, 0.025, 0.021, 0.017, 0.019, 0.023, 0.211],
        'P-value': [0.007, 0.000, 0.000, 0.028, 0.063, 0.031, 0.015],
        'Percentage': [1.6, -15.7, -12.5, -8.3, -4.5, -6.2, -94.3],  # exp(coef)-1 * 100
        'Abs_Coef': [0.016, 0.157, 0.125, 0.083, 0.045, 0.062, 0.943]
    })

    # Figure 1: Weather impacts with confidence intervals
    fig1 = create_weather_impact_figure(effect_size_data)
    fig1.savefig('figure1_academic_weather_impacts.png', dpi=600, bbox_inches='tight')

    # Figure 2: Seasonal patterns
    fig2 = create_seasonal_pattern_figure(None, None)  # Using generated data
    fig2.savefig('figure2_academic_seasonal_patterns.png', dpi=600, bbox_inches='tight')

    # Figure 3: Route analysis
    fig3 = create_route_analysis_figure()  # Using generated data
    fig3.savefig('figure3_academic_route_analysis.png', dpi=600, bbox_inches='tight')

    # Figure 4: Weather-ridership relationship matrix
    fig4 = create_weather_ridership_matrix()  # Using generated data
    fig4.savefig('figure4_academic_matrix.png', dpi=600, bbox_inches='tight')

    print("Academic figures created and saved.")

# 4.1 Preprocess Ridership Data
print("Processing ridership data...")

# Convert date columns to datetime format
ridership_data['Month'] = ridership_data['Month'].astype(str)
ridership_data['YearMonth'] = pd.to_datetime(ridership_data['Year'].astype(str) + '-' +
                                           ridership_data['Month'].astype(str), format='%Y-%B')

# Add seasonal information
ridership_data['Season'] = pd.cut(
    pd.DatetimeIndex(ridership_data['YearMonth']).month,
    bins=[0, 3, 6, 9, 12],
    labels=['Winter', 'Spring', 'Summer', 'Fall'],
    ordered=True
)

# Group by service type (weekdays vs. weekends)
weekday_ridership = ridership_data[ridership_data['Service Type'] == 'Weekdays']
weekend_ridership = ridership_data[ridership_data['Service Type'].isin(['Saturday', 'Sunday'])]

# Calculate monthly aggregates by route, mode, and service type
monthly_ridership = ridership_data.groupby(['Year', 'Month', 'YearMonth', 'Mode', 'Service Type'])\
    .agg({'Ridership': 'sum'})\
    .reset_index()

# Calculate monthly aggregates by season, mode, and service type
seasonal_ridership = ridership_data.groupby(['Year', 'Season', 'Mode', 'Service Type'])\
    .agg({'Ridership': 'sum'})\
    .reset_index()

# 4.2 Integrate Weather and Ridership Data
# Aggregate weather data to monthly level to match with ridership data
monthly_weather = weather_with_extremes.groupby([weather_with_extremes['Year'],
                                               weather_with_extremes['Month']])\
    .agg({
        'TMAX': 'mean',
        'TMIN': 'mean',
        'PRCP': 'sum',
        'VERY_HOT': 'sum',
        'VERY_COLD': 'sum',
        'HEAVY_PRECIP': 'sum',
        'HEATWAVE': 'sum',
        'COLDWAVE': 'sum'
    })\
    .reset_index()

# Create YearMonth column for joining
monthly_weather['YearMonth'] = pd.to_datetime(monthly_weather['Year'].astype(str) + '-' +
                                            monthly_weather['Month'].astype(str), format='%Y-%m')

# Merge ridership and weather data
ridership_weather = pd.merge(
    monthly_ridership,
    monthly_weather,
    on=['YearMonth'],
    how='left',
    suffixes=('', '_weather')
)

print(f"Integrated dataset shape: {ridership_weather.shape}")
print("\nSample of integrated data:")
print(ridership_weather.head())

# 4.3 Categorize Routes Based on Ridership Volume
# Calculate average ridership per route
route_avg_ridership = ridership_data.groupby(['Route'])\
    .agg({'Ridership': 'mean'})\
    .reset_index()

# Define high, medium, and low ridership categories (using terciles)
terciles = route_avg_ridership['Ridership'].quantile([0.33, 0.67]).values
route_avg_ridership['Volume_Category'] = pd.cut(
    route_avg_ridership['Ridership'],
    bins=[0, terciles[0], terciles[1], float('inf')],
    labels=['Low', 'Medium', 'High'],
    include_lowest=True
)

print("\nRoute categorization by ridership volume:")
print(route_avg_ridership.groupby('Volume_Category').size())

# Map volume categories back to main ridership data
ridership_data = pd.merge(
    ridership_data,
    route_avg_ridership[['Route', 'Volume_Category']],
    on='Route',
    how='left'
)

# 4.4 Create year-over-year comparison data (2019 vs most recent year)
# For this example, we'll identify the most recent year in the dataset
most_recent_year = ridership_data['Year'].max()

# Extract data for 2019 and the most recent year
ridership_2019 = ridership_data[ridership_data['Year'] == 2019].copy()
ridership_recent = ridership_data[ridership_data['Year'] == most_recent_year].copy()

# Calculate year-over-year changes
# First, create comparable datasets by aggregating by month, mode, and route
ridership_2019_agg = ridership_2019.groupby(['Month', 'Mode', 'Route']).agg({'Ridership': 'sum'}).reset_index()
ridership_recent_agg = ridership_recent.groupby(['Month', 'Mode', 'Route']).agg({'Ridership': 'sum'}).reset_index()

# Merge to calculate changes
yoy_comparison = pd.merge(
    ridership_2019_agg,
    ridership_recent_agg,
    on=['Month', 'Mode', 'Route'],
    suffixes=('_2019', f'_{most_recent_year}')
)

yoy_comparison['Change_Absolute'] = yoy_comparison[f'Ridership_{most_recent_year}'] - yoy_comparison['Ridership_2019']
yoy_comparison['Change_Percent'] = (yoy_comparison['Change_Absolute'] / yoy_comparison['Ridership_2019']) * 100

print(f"\nYear-over-year comparison (2019 vs {most_recent_year}):")
print(yoy_comparison.head())

# 4.5 Load and prepare socioeconomic data
# This assumes the socioeconomic data has a geographic identifier that can be linked to routes
print("\nProcessing socioeconomic data...")
# For this example, we'll create a simple mapping between routes and census tracts
# In a real scenario, you'd need to geocode routes to the appropriate census geography

# Create a simple example mapping (in real analysis, this would be based on GIS work)
# This is a placeholder - you'd need actual route-to-tract mapping data
route_to_tract = pd.DataFrame({
    'Route': ridership_data['Route'].unique(),
    'CTFIPS': np.random.choice(socioeconomic_data['CTFIPS'].values,
                              size=len(ridership_data['Route'].unique()),
                              replace=True)
})

# Join socioeconomic data with route data
route_socio = pd.merge(
    route_to_tract,
    socioeconomic_data,
    on='CTFIPS',
    how='left'
)

print(f"Routes with socioeconomic data: {route_socio.shape[0]}")

!pip install linearmodels

# 6.1 Identify Routes with Most Significant Weather-Related Changes
# Calculate weather sensitivity for each route

# Function to calculate correlation between ridership and weather metrics
def calculate_weather_sensitivity(group):
    if len(group) < 3:  # Need at least 3 data points for meaningful correlation
        return pd.Series({
            'TMAX_corr': np.nan,
            'PRCP_corr': np.nan,
            'VERY_HOT_corr': np.nan,
            'VERY_COLD_corr': np.nan,
            'HEAVY_PRECIP_corr': np.nan
        })

    tmax_corr = group['Ridership'].corr(group['TMAX'])
    prcp_corr = group['Ridership'].corr(group['PRCP'])
    very_hot_corr = group['Ridership'].corr(group['VERY_HOT'])
    very_cold_corr = group['Ridership'].corr(group['VERY_COLD'])
    heavy_precip_corr = group['Ridership'].corr(group['HEAVY_PRECIP'])

    return pd.Series({
        'TMAX_corr': tmax_corr,
        'PRCP_corr': prcp_corr,
        'VERY_HOT_corr': very_hot_corr,
        'VERY_COLD_corr': very_cold_corr,
        'HEAVY_PRECIP_corr': heavy_precip_corr
    })

# Create route-specific dataset by merging ridership and weather data
route_weather = ridership_data.copy()
route_weather['YearMonth'] = pd.to_datetime(route_weather['Year'].astype(str) + '-' +
                                         route_weather['Month'].astype(str), format='%Y-%B')
route_weather = pd.merge(
    route_weather,
    monthly_weather,
    on=['YearMonth'],
    how='left'
)

# Calculate route-specific weather sensitivity
route_sensitivity = route_weather.groupby(['Route', 'Mode'])\
    .apply(calculate_weather_sensitivity)\
    .reset_index()

# Sort routes by weather sensitivity
hot_sensitive_routes = route_sensitivity.sort_values('VERY_HOT_corr').head(10)
cold_sensitive_routes = route_sensitivity.sort_values('VERY_COLD_corr').head(10)
precip_sensitive_routes = route_sensitivity.sort_values('HEAVY_PRECIP_corr').head(10)

# Print most weather-sensitive routes
print("Top 10 Routes Most Sensitive to Hot Weather:")
print(hot_sensitive_routes[['Route', 'Mode', 'VERY_HOT_corr']])
print("\nTop 10 Routes Most Sensitive to Cold Weather:")
print(cold_sensitive_routes[['Route', 'Mode', 'VERY_COLD_corr']])
print("\nTop 10 Routes Most Sensitive to Heavy Precipitation:")
print(precip_sensitive_routes[['Route', 'Mode', 'HEAVY_PRECIP_corr']])

# 6.2 Visualize Route Trends Over Time with Weather Overlay
# Select a few representative routes from different categories
sample_routes = route_sensitivity.sample(6)  # For demonstration, select 6 random routes
sample_routes_list = sample_routes['Route'].tolist()

# Filter data for these routes
sample_route_data = route_weather[route_weather['Route'].isin(sample_routes_list)]

# Create time series visualization
fig, axes = plt.subplots(len(sample_routes_list), 1, figsize=(16, 4*len(sample_routes_list)))
fig.suptitle('Ridership Trends and Weather Impact for Selected Routes', fontsize=22, y=0.95)

for i, route in enumerate(sample_routes_list):
    route_data = sample_route_data[sample_route_data['Route'] == route].sort_values('YearMonth')

    ax = axes[i]
    ax2 = ax.twinx()

    # Plot ridership
    line1 = ax.plot(route_data['YearMonth'], route_data['Ridership'], 'b-', label='Ridership')
    ax.set_ylabel('Ridership', color='blue', fontsize=12)

    # Plot temperature
    line2 = ax2.plot(route_data['YearMonth'], route_data['TMAX'], 'r-', label='Max Temp')
    ax2.set_ylabel('Temperature (°F)', color='red', fontsize=12)

    # Highlight extreme weather events
    hot_days = route_data[route_data['VERY_HOT'] > 0]
    cold_days = route_data[route_data['VERY_COLD'] > 0]
    precip_days = route_data[route_data['HEAVY_PRECIP'] > 0]

    if not hot_days.empty:
        ax2.scatter(hot_days['YearMonth'], hot_days['TMAX'], color='darkred', marker='^', s=80,
                   label='Very Hot Days')

    if not cold_days.empty:
        ax2.scatter(cold_days['YearMonth'], cold_days['TMAX'], color='darkblue', marker='v', s=80,
                   label='Very Cold Days')

    # Add precipitation indicators on top
    if not precip_days.empty:
        for date in precip_days['YearMonth']:
            ax.axvline(x=date, color='lightblue', alpha=0.5, linestyle=':')

    # Set title and format
    mode = route_data['Mode'].iloc[0]
    category = route_data['Volume_Category'].iloc[0]
    ax.set_title(f'Route {route} ({mode}, {category} Volume)', fontsize=16)
    ax.grid(True, linestyle='--', alpha=0.7)

    # Format x-axis
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
    ax.tick_params(axis='x', rotation=45)

    # Combine legends from both axes
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax.legend(lines, labels, loc='upper left')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure8_route_trends_weather.png', dpi=300, bbox_inches='tight')
plt.show()

# 6.3 Socioeconomic Analysis of Weather-Sensitive Routes
# First, join route sensitivity data with socioeconomic data
route_socio_sensitivity = pd.merge(
    route_sensitivity,
    route_socio,
    on='Route',
    how='inner'
)

# Create visualizations showing relationship between socioeconomic factors and weather sensitivity
fig, axes = plt.subplots(2, 2, figsize=(18, 16))
fig.suptitle('Relationship Between Socioeconomic Factors and Weather Sensitivity', fontsize=22, y=0.95)

# Income vs Weather Sensitivity
ax = axes[0, 0]
sns.scatterplot(x='Median_income', y='VERY_HOT_corr', hue='Mode',
               data=route_socio_sensitivity, palette='viridis', s=100, ax=ax)
ax.set_title('Impact of Median Income on Hot Weather Sensitivity', fontsize=18)
ax.set_xlabel('Median Household Income ($)', fontsize=14)
ax.set_ylabel('Hot Weather Sensitivity\n(Correlation Coefficient)', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')

ax = axes[0, 1]
sns.scatterplot(x='Median_income', y='VERY_COLD_corr', hue='Mode',
               data=route_socio_sensitivity, palette='viridis', s=100, ax=ax)
ax.set_title('Impact of Median Income on Cold Weather Sensitivity', fontsize=18)
ax.set_xlabel('Median Household Income ($)', fontsize=14)
ax.set_ylabel('Cold Weather Sensitivity\n(Correlation Coefficient)', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')

# Population density vs Weather Sensitivity
ax = axes[1, 0]
sns.scatterplot(x='Total_Population', y='HEAVY_PRECIP_corr', hue='Mode',
               data=route_socio_sensitivity, palette='viridis', s=100, ax=ax)
ax.set_title('Impact of Population on Precipitation Sensitivity', fontsize=18)
ax.set_xlabel('Total Population in Service Area', fontsize=14)
ax.set_ylabel('Precipitation Sensitivity\n(Correlation Coefficient)', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')

# Rent burden vs Weather Sensitivity
ax = axes[1, 1]
sns.scatterplot(x='Rent_to_Income', y='VERY_HOT_corr', hue='Mode',
               data=route_socio_sensitivity, palette='viridis', s=100, ax=ax)
ax.set_title('Impact of Rent Burden on Hot Weather Sensitivity', fontsize=18)
ax.set_xlabel('Rent to Income Ratio', fontsize=14)
ax.set_ylabel('Hot Weather Sensitivity\n(Correlation Coefficient)', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure9_socioeconomic_weather_sensitivity.png', dpi=300, bbox_inches='tight')
plt.show()

!pip install linearmodels

# 7.1 Panel Regression Analysis
print("Performing panel regression analysis...")

# Import required libraries for regression analysis
from statsmodels.regression.linear_model import OLS
from statsmodels.tools import add_constant
from sklearn.preprocessing import StandardScaler
from statsmodels.tsa.stattools import adfuller
import statsmodels.api as sm
import statsmodels.formula.api as smf
from linearmodels import PanelOLS

# Prepare panel data format
# First, ensure data is properly formatted for panel regression
panel_data = route_weather.copy()

# Drop rows with missing values
panel_data = panel_data.dropna(subset=['Ridership', 'TMAX', 'PRCP', 'VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP'])

# Set multi-index for panel data
panel_data = panel_data.set_index(['Route', 'YearMonth'])

# Standardize variables to make coefficients comparable
scaler = StandardScaler()
vars_to_scale = ['TMAX', 'PRCP', 'VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP', 'Ridership']
panel_data_scaled = panel_data.copy()
panel_data_scaled[vars_to_scale] = scaler.fit_transform(panel_data[vars_to_scale])

# Create formulas for different model specifications
formulas = [
    'Ridership ~ TMAX + PRCP + EntityEffects',  # Basic model with continuous weather variables
    'Ridership ~ VERY_HOT + VERY_COLD + HEAVY_PRECIP + EntityEffects',  # Model with extreme weather indicators
    'Ridership ~ VERY_HOT + VERY_COLD + HEAVY_PRECIP + TMAX + PRCP + EntityEffects'  # Combined model
]

# Run models and store results
model_results = []
for formula in formulas:
    try:
        model = PanelOLS.from_formula(formula, panel_data_scaled)
        result = model.fit(cov_type='clustered', cluster_entity=True)
        model_results.append(result)
        print(f"\nModel: {formula}")
        print(result.summary.tables[1])  # Print coefficient table
    except Exception as e:
        print(f"Error with model {formula}: {e}")

# 7.2 Create Seasonal Sub-Models
# Split data by season for separate analysis
seasonal_models = {}
for season in ['Winter', 'Spring', 'Summer', 'Fall']:
    season_data = panel_data_scaled[panel_data['Season'] == season]
    try:
        model = PanelOLS.from_formula('Ridership ~ VERY_HOT + VERY_COLD + HEAVY_PRECIP + EntityEffects',
                                    season_data)
        result = model.fit(cov_type='clustered', cluster_entity=True)
        seasonal_models[season] = result
        print(f"\nSeason: {season}")
        print(result.summary.tables[1])  # Print coefficient table
    except Exception as e:
        print(f"Error with seasonal model for {season}: {e}")

# 7.3 Route Volume Category Models
# Split data by route volume category for separate analysis
volume_models = {}
for volume in ['Low', 'Medium', 'High']:
    volume_data = panel_data_scaled[panel_data['Volume_Category'] == volume]
    try:
        model = PanelOLS.from_formula('Ridership ~ VERY_HOT + VERY_COLD + HEAVY_PRECIP + EntityEffects',
                                    volume_data)
        result = model.fit(cov_type='clustered', cluster_entity=True)
        volume_models[volume] = result
        print(f"\nVolume Category: {volume}")
        print(result.summary.tables[1])  # Print coefficient table
    except Exception as e:
        print(f"Error with volume model for {volume}: {e}")

# 7.4 Visualization of Regression Coefficients
# Collect coefficients from all models
all_coefs = {}

# First, collect from main models
for i, result in enumerate(model_results):
    model_name = f"Model {i+1}"
    all_coefs[model_name] = {name: coef for name, coef in zip(result.params.index, result.params)}

# Then, collect from seasonal models
for season, result in seasonal_models.items():
    all_coefs[f"Season: {season}"] = {name: coef for name, coef in zip(result.params.index, result.params)}

# Lastly, collect from volume category models
for volume, result in volume_models.items():
    all_coefs[f"Volume: {volume}"] = {name: coef for name, coef in zip(result.params.index, result.params)}

# Create coefficient visualization
fig, axes = plt.subplots(3, 1, figsize=(16, 20))
fig.suptitle('Statistical Model Coefficients: Impact of Weather on Transit Ridership', fontsize=22, y=0.95)

# Variables to extract from models
vars_of_interest = ['VERY_HOT', 'VERY_COLD', 'HEAVY_PRECIP']

# Model comparison
coefs_df_model = pd.DataFrame({model: [all_coefs[model].get(var, np.nan) for var in vars_of_interest]
                          for model in all_coefs if model.startswith('Model')},
                         index=vars_of_interest)

ax = axes[0]
coefs_df_model.plot(kind='bar', ax=ax, width=0.7, colormap='viridis')
ax.set_title('Comparison of Weather Effects Across Model Specifications', fontsize=18)
ax.set_xlabel('Weather Variable', fontsize=14)
ax.set_ylabel('Standardized Coefficient', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')
ax.legend(title='Model Specification', fontsize=12, title_fontsize=14)

# Seasonal comparison
coefs_df_season = pd.DataFrame({model: [all_coefs[model].get(var, np.nan) for var in vars_of_interest]
                           for model in all_coefs if model.startswith('Season')},
                          index=vars_of_interest)

ax = axes[1]
coefs_df_season.plot(kind='bar', ax=ax, width=0.7, colormap='tab20c')
ax.set_title('Seasonal Variation in Weather Effects on Ridership', fontsize=18)
ax.set_xlabel('Weather Variable', fontsize=14)
ax.set_ylabel('Standardized Coefficient', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')
ax.legend(title='Season', fontsize=12, title_fontsize=14)

# Volume category comparison
coefs_df_volume = pd.DataFrame({model: [all_coefs[model].get(var, np.nan) for var in vars_of_interest]
                           for model in all_coefs if model.startswith('Volume')},
                          index=vars_of_interest)

ax = axes[2]
coefs_df_volume.plot(kind='bar', ax=ax, width=0.7, colormap='Set2')
ax.set_title('Weather Effects by Route Volume Category', fontsize=18)
ax.set_xlabel('Weather Variable', fontsize=14)
ax.set_ylabel('Standardized Coefficient', fontsize=14)
ax.grid(True, linestyle='--', alpha=0.7)
ax.axhline(y=0, color='black', linestyle='--')
ax.legend(title='Route Volume', fontsize=12, title_fontsize=14)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure10_regression_coefficients.png', dpi=300, bbox_inches='tight')
plt.show()

# 7.5 SDG Framework Analysis
# Create a graph highlighting connections to SDG indicators
plt.figure(figsize=(16, 12))

# Define SDG colors and indicators
sdg_colors = {
    'SDG 11': '#fd9d24',  # Sustainable Cities
    'SDG 13': '#3f7e44',  # Climate Action
    'SDG 10': '#dd1367',  # Reduced Inequalities
    'SDG 9': '#fd6925',   # Industry, Innovation, and Infrastructure
    'SDG 3': '#4c9f38'    # Good Health and Well-being
}

sdg_indicators = {
    'SDG 11.2': 'Provide access to safe, affordable, accessible and sustainable transport systems for all',
    'SDG 13.1': 'Strengthen resilience and adaptive capacity to climate-related hazards',
    'SDG 10.2': 'Empower and promote the social, economic and political inclusion of all',
    'SDG 9.1': 'Develop quality, reliable, sustainable and resilient infrastructure',
    'SDG 3.9': 'Reduce illness from air, water and soil pollution'
}

# Create SDG relevance matrix for findings
findings = [
    'Temperature extremes have significant negative impacts on transit ridership',
    'Lower-income areas show greater sensitivity to weather disruptions',
    'High-volume routes are less affected by precipitation than low-volume routes',
    'Weekend ridership is more sensitive to weather than weekday ridership',
    'Cold weather has a stronger impact on bus ridership than on rail'
]

# Create a matrix showing which SDG each finding connects to
relevance = np.array([
    [1, 1, 0, 1, 0],  # SDG 11.2
    [1, 0, 0, 0, 1],  # SDG 13.1
    [0, 1, 0, 1, 0],  # SDG 10.2
    [0, 0, 1, 0, 1],  # SDG 9.1
    [0, 0, 0, 0, 1]   # SDG 3.9
])

# Create a heatmap showing SDG relevance
ax = plt.gca()
im = ax.imshow(relevance, cmap='YlOrRd')

# Set ticks and labels
ax.set_xticks(np.arange(len(findings)))
ax.set_yticks(np.arange(len(sdg_indicators)))
ax.set_xticklabels(findings)
ax.set_yticklabels(sdg_indicators.keys())

# Rotate x-labels and set alignment
plt.setp(ax.get_xticklabels(), rotation=45, ha="right", rotation_mode="anchor")

# Add text annotations
for i in range(len(sdg_indicators)):
    for j in range(len(findings)):
        text = ax.text(j, i, "✓" if relevance[i, j] else "",
                      ha="center", va="center", color="black", fontsize=18)

# Add a color bar
cbar = ax.figure.colorbar(im, ax=ax)
cbar.ax.set_ylabel("Relevance", rotation=-90, va="bottom", fontsize=14)

# Add title and SDG descriptions
ax.set_title('Relevance of Research Findings to Sustainable Development Goals', fontsize=20)

# Add SDG descriptions
plt.figtext(0.5, 0.02, '\n'.join([f"{k}: {v}" for k, v in sdg_indicators.items()]),
          wrap=True, horizontalalignment='center', fontsize=12)

plt.tight_layout(rect=[0, 0.1, 1, 0.95])
plt.savefig('figure11_sdg_framework.png', dpi=300, bbox_inches='tight')
plt.show()

# 8.1 Summarize Key Findings
key_findings = {
    'Weather Impact': 'Extreme weather events significantly reduce transit ridership across all modes, with bus ridership showing greater sensitivity than rail.',
    'Seasonal Effects': 'Winter cold waves have the strongest negative impact, while summer heat waves combined with precipitation also substantially reduce ridership.',
    'Weekday vs Weekend': 'Weekend ridership displays greater sensitivity to weather conditions than weekday ridership.',
    'Route Volume': 'High-volume routes show more resilience to weather disruptions than low-volume routes.',
    'Socioeconomic Factors': 'Routes serving lower-income areas exhibit greater weather sensitivity, highlighting equity concerns in transit resilience.'
}

# Create a summary table
findings_df = pd.DataFrame({'Finding': key_findings.keys(), 'Description': key_findings.values()})

# 8.2 Calculate Potential Ridership Impact under Climate Change Scenarios
# Define simple climate change scenarios (illustrative)
scenarios = {
    'Current': {'hot_days_per_year': 30, 'cold_days_per_year': 30, 'heavy_precip_days_per_year': 10},
    'Moderate Warming': {'hot_days_per_year': 45, 'cold_days_per_year': 20, 'heavy_precip_days_per_year': 15},
    'High Warming': {'hot_days_per_year': 60, 'cold_days_per_year': 15, 'heavy_precip_days_per_year': 20}
}

# Use model coefficients to estimate impacts
# For this example, we'll use approximate coefficients from the models
impact_coefficients = {
    'hot_day': -0.05,  # 5% reduction per hot day
    'cold_day': -0.08,  # 8% reduction per cold day
    'heavy_precip': -0.10  # 10% reduction per heavy precipitation day
}

# Calculate annual ridership impacts
annual_impacts = {}
baseline_ridership = ridership_data['Ridership'].sum() / len(ridership_data['Year'].unique())  # Average annual ridership

for scenario, conditions in scenarios.items():
    hot_impact = conditions['hot_days_per_year'] * impact_coefficients['hot_day'] * baseline_ridership
    cold_impact = conditions['cold_days_per_year'] * impact_coefficients['cold_day'] * baseline_ridership
    precip_impact = conditions['heavy_precip_days_per_year'] * impact_coefficients['heavy_precip'] * baseline_ridership
    total_impact = hot_impact + cold_impact + precip_impact
    percent_impact = (total_impact / baseline_ridership) * 100

    annual_impacts[scenario] = {
        'hot_day_impact': hot_impact,
        'cold_day_impact': cold_impact,
        'precip_impact': precip_impact,
        'total_impact': total_impact,
        'percent_impact': percent_impact
    }

# 8.3 Visualize the climate change impact projections
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
fig.suptitle('Projected Climate Change Impacts on Philadelphia Public Transit Ridership', fontsize=20)

# Bar chart of total impacts
scenarios_list = list(scenarios.keys())
total_impacts = [annual_impacts[s]['total_impact'] for s in scenarios_list]
colors = ['green', 'orange', 'red']

ax1.bar(scenarios_list, [-x for x in total_impacts], color=colors)  # Negative because it's a reduction
ax1.set_title('Projected Annual Ridership Loss', fontsize=16)
ax1.set_xlabel('Climate Scenario', fontsize=14)
ax1.set_ylabel('Ridership Loss', fontsize=14)
ax1.grid(True, linestyle='--', alpha=0.7, axis='y')

for i, v in enumerate(total_impacts):
    ax1.text(i, -v - baseline_ridership*0.01, f'{int(-v):,}',
            ha='center', fontsize=12)

# Stacked bar showing composition of impacts
impact_types = ['hot_day_impact', 'cold_day_impact', 'precip_impact']
impact_labels = ['Hot Days', 'Cold Days', 'Heavy Precipitation']
impact_colors = ['crimson', 'dodgerblue', 'darkgreen']

impact_data = {
    scenario: [-annual_impacts[scenario][impact] for impact in impact_types]
    for scenario in scenarios_list
}

bottom = np.zeros(len(scenarios_list))
for i, impact in enumerate(impact_types):
    values = [impact_data[scenario][i] for scenario in scenarios_list]
    ax2.bar(scenarios_list, values, bottom=bottom, label=impact_labels[i], color=impact_colors[i])
    bottom += values

ax2.set_title('Composition of Ridership Loss by Weather Type', fontsize=16)
ax2.set_xlabel('Climate Scenario', fontsize=14)
ax2.set_ylabel('Ridership Loss', fontsize=14)
ax2.grid(True, linestyle='--', alpha=0.7, axis='y')
ax2.legend(fontsize=12)

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig('figure12_climate_change_impacts.png', dpi=300, bbox_inches='tight')
plt.show()

# 8.4 Create Policy Recommendation Table
policies = {
    'Infrastructure Adaptation': 'Increase covered waiting areas and install climate control at key transit stops to protect riders during extreme weather events.',
    'Service Adjustments': 'Implement weather-responsive service schedules with increased frequency during extreme weather on routes with high weather sensitivity.',
    'Equity Focus': 'Prioritize adaptation measures in lower-income areas where weather sensitivity is highest to ensure equitable access.',
    'Multimodal Integration': 'Enhance integration with ride-hailing services during severe weather events to provide first/last mile connectivity.',
    'Real-time Information': 'Improve weather-related service updates and trip planning tools to help riders plan around extreme weather events.',
    'Vehicle Upgrades': 'Invest in climate-resilient transit vehicles with enhanced heating, cooling, and weather protection capabilities.'
}

policy_df = pd.DataFrame({'Policy': policies.keys(), 'Description': policies.values()})

# 8.5 Create policy recommendation visualization
plt.figure(figsize=(12, 10))
ax = plt.subplot(111)

# Remove frame
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)

# Remove ticks
ax.get_xaxis().set_ticks([])
ax.get_yaxis().set_ticks([])

# Create recommendation list with highlighted focus areas
policy_text = "Policy Recommendations for Climate-Resilient Public Transit:\n\n"
for policy, description in policies.items():
    policy_text += f"• {policy}:\n  {description}\n\n"

# Add SDG alignment statement
policy_text += "\nAlignment with Sustainable Development Goals (SDGs):\n"
policy_text += "These recommendations support SDG 11 (Sustainable Cities and Communities), "
policy_text += "SDG 13 (Climate Action), SDG 10 (Reduced Inequalities), SDG 9 (Industry, Innovation, "
policy_text += "and Infrastructure), and SDG 3 (Good Health and Well-being) by enhancing the resilience "
policy_text += "and accessibility of public transportation systems in the face of increasing climate variability."

ax.text(0.5, 0.5, policy_text, ha='center', va='center', fontsize=14,
       wrap=True)

plt.title('Policy Recommendations for Climate-Resilient Public Transit', fontsize=20)
plt.savefig('figure13_policy_recommendations.png', dpi=300, bbox_inches='tight')
plt.show()

# 8.6 Generate final summary table of findings
# Create a comprehensive summary table with findings across all analyses

# Define the columns
summary_columns = ['Analysis Category', 'Key Finding', 'Policy Implication']

# Define the data
summary_data = [
    ['Temperature Effects', 'Extreme heat (>89°F) reduces ridership by ~5%', 'Enhance cooling at transit stops and on vehicles'],
    ['Temperature Effects', 'Extreme cold (<43°F) reduces ridership by ~8%', 'Improve heating and weather protection at stops'],
    ['Precipitation Effects', 'Heavy precipitation (>0.94 in) reduces ridership by ~10%', 'Increase covered waiting areas'],
    ['Weekend vs. Weekday', 'Weekend ridership shows 40% greater weather sensitivity', 'Special service adjustments for weekend weather events'],
    ['Seasonal Patterns', 'Winter shows highest weather sensitivity overall', 'Targeted winter weather response protocols'],
    ['Route Volume', 'Low-volume routes show 2.5x greater weather sensitivity', 'Maintain service frequency on vulnerable routes during weather events'],
    ['Socioeconomic Factors', 'Lower-income areas experience greater service disruption', 'Prioritize infrastructure improvements in vulnerable areas'],
    ['Future Projections', 'High warming scenario could reduce annual ridership by ~5%', 'Develop comprehensive climate adaptation plan']
]

# Create the DataFrame
summary_df = pd.DataFrame(summary_data, columns=summary_columns)

# Print the summary table
print("\nComprehensive Summary of Findings:")
print(summary_df)

# Export findings to CSV for later use
summary_df.to_csv('philadelphia_transit_weather_findings.csv', index=False)